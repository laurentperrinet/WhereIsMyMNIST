{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces the problem addressed in this paper:\n",
    "\n",
    " - localizating an object in a large image\n",
    " - foveation\n",
    " - action (saccade)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig_width_pt = 525  # Get this from LaTeX using \\showthe\\columnwidth\n",
    "fig_width_pt = 618  # Get this from LaTeX using \\showthe\\columnwidth\n",
    "fig_width_pt = 1024  # Get this from LaTeX using \\showthe\\columnwidth\n",
    "ppi = 72.27 # (constant) definition of the ppi = points per inch\n",
    "inches_per_pt = 1.0/ppi  # Convert pt to inches\n",
    "#inches_per_cm = 1./2.54\n",
    "figwidth = fig_width_pt*inches_per_pt  # width in inches\n",
    "phi = (np.sqrt(5) + 1. ) /2 # golden ratio is good for your eyes\n",
    "dpi_export = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T10:34:13.258190Z",
     "start_time": "2018-07-03T10:34:13.251661Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figname = '../figures/fig_result'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Fixation Map training (2 layers)\n",
    "with clutter / whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../figures')\n",
    "from retina import MotionCloudNoise, vectorization, get_data_loader, minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_theta = 6\n",
    "N_azimuth = 16\n",
    "N_eccentricity = 10\n",
    "N_phase = 2\n",
    "\n",
    "N_pic = 128\n",
    "N_X = N_pic\n",
    "N_Y = N_pic\n",
    "rho = 1.41\n",
    "verbose = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retina_transform = vectorization(N_theta, N_azimuth, N_eccentricity, N_phase, N_X, N_Y, rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retina_vector = retina.reshape((N_theta*N_azimuth*N_eccentricity*N_phase, N_X*N_Y))\n",
    "# retina_inverse = np.linalg.pinv(retina_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = get_data_loader(batch_size=100, train = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/MNIST_accuracy.npy\"\n",
    "import os\n",
    "if os.path.isfile(path):\n",
    "    accuracy_map =  np.load(path)\n",
    "    if verbose:\n",
    "        print('Loading accuracy... min, max=', accuracy_map.min(), accuracy_map.max())\n",
    "else:\n",
    "    print('No accuracy data found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,3))\n",
    "plt.subplot(121)\n",
    "plt.imshow(accuracy_map)\n",
    "plt.subplot(122)\n",
    "_ = plt.plot(accuracy_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retina import do_offset, accuracy_fullfield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colliculus = (retina_transform**2).sum(axis=(0, 3))\n",
    "#colliculus = colliculus**.5\n",
    "colliculus /= colliculus.sum(axis=-1)[:, :, None]\n",
    "print(colliculus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colliculus_vector = colliculus.reshape((N_azimuth*N_eccentricity, N_X*N_Y))\n",
    "print(colliculus_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colliculus_inverse = np.linalg.pinv(colliculus_vector)\n",
    "print(colliculus_inverse.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From MNIST encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retina import place_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_size = 100  # quantity of examples that'll be processed\n",
    "lr = 1e-4 #1e-3  #0.05\n",
    "\n",
    "OFFSET_STD = 15 #\n",
    "OFFSET_MAX = 30 #\n",
    "NOISE = 1 #0 #\n",
    "CONTRAST = 0.5 #1 #\n",
    "sf_0 = 0.2\n",
    "B_sf = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retina import retina, retina_inverse\n",
    "retina_inverse_transform = retina_inverse(retina_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = next(iter(loader))\n",
    "fig, axs = plt.subplots(1, 2, figsize = (figwidth, figwidth/2))\n",
    "i = 4\n",
    "offset_std=OFFSET_STD\n",
    "offset_max=OFFSET_MAX\n",
    "i_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "j_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "\n",
    "data_fullfield = place_object(data[i, 0, :, :].numpy(), i_offset, j_offset, \n",
    "                                CONTRAST=CONTRAST, NOISE=NOISE,\n",
    "                                sf_0=sf_0, B_sf=B_sf)\n",
    "data_retina, tensor_retina  =  retina(data_fullfield, retina_transform)\n",
    "\n",
    "axs[0].imshow(data_fullfield, cmap=plt.gray(), vmin=0, vmax=1)\n",
    "axs[1].imshow((retina_inverse_transform @ data_retina).reshape(N_pic, N_pic), cmap=plt.viridis())# vmin=0, vmax=1, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orientation invariant power encoding (colliculus??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_fullfield_map = do_offset(accuracy_map, i_offset, j_offset, N_pic=N_pic, min=0.1)\n",
    "# accuracy_colliculus = colliculus_vector @ accuracy_fullfield_map.ravel()\n",
    "accuracy_colliculus, accuracy_fullfield_map = accuracy_fullfield(accuracy_map, i_offset, j_offset, N_pic, colliculus_vector)\n",
    "im = colliculus_inverse @ accuracy_colliculus\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize = (figwidth, figwidth/2))\n",
    "axs[0].imshow(accuracy_fullfield_map, vmin=0, vmax=1, cmap=plt.viridis())\n",
    "axs[1].imshow(im.reshape(N_pic, N_pic), vmin=0, vmax=1, cmap=plt.viridis())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Torch stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "do_cuda = False # torch.cuda.is_available()\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True} if do_cuda else {}\n",
    "device = torch.device(\"cuda\" if do_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_data_loader(batch_size=minibatch_size, train = True)\n",
    "test_loader = get_data_loader(batch_size=1000, train = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIC_NAME = \"2019-02-15-anywhere-additive-noise-white-1000-Necc-10.npy\"\n",
    "# FIC_NAME = \"../data/2019-03-02-anywhere-background-noise-white-1000.npy\"\n",
    "# FIC_NAME = \"../data/2019-03-07_CNS.npy\"\n",
    "# FIC_NAME = \"../data/2019-03-08_CNS.npy\"\n",
    "FIC_NAME = \"../data/2019-03-11_CNS.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BIAS_CONV = True\n",
    "BIAS_DECONV = True #True\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        #self.bn1= torch.nn.Linear(N_theta*N_azimuth*N_eccentricity*N_phase, 200, bias = BIAS_DECONV)\n",
    "        self.bn1= torch.nn.Linear(N_theta*N_azimuth*N_eccentricity*N_phase, 1000, bias = BIAS_DECONV)\n",
    "        #self.bn2 = torch.nn.Linear(200, 80, bias = BIAS_DECONV)\n",
    "        self.bn2 = torch.nn.Linear(1000, 1000, bias = BIAS_DECONV)\n",
    "        #self.bn3 = torch.nn.Linear(80, N_azimuth*N_eccentricity, bias = BIAS_DECONV)\n",
    "        self.bn3 = torch.nn.Linear(1000, N_azimuth*N_eccentricity, bias = BIAS_DECONV)\n",
    "                \n",
    "    def forward(self, image):\n",
    "       \n",
    "        h_bn1 = F.relu(self.bn1(image))               \n",
    "        h_bn2 = F.relu(self.bn2(h_bn1))\n",
    "        h_bn2_drop = F.dropout(h_bn2, p = .5) \n",
    "        u = self.bn3(h_bn2_drop)\n",
    "        \n",
    "        return u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.BCEWithLogitsLoss() #torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, minibatch_size,\n",
    "          optimizer=optimizer,\n",
    "          vsize = N_theta * N_azimuth * N_eccentricity * N_phase,\n",
    "          asize = 1,\n",
    "          offset_std=OFFSET_STD,\n",
    "          offset_max=OFFSET_MAX,\n",
    "          verbose=1,\n",
    "          CONTRAST=CONTRAST,\n",
    "          NOISE=NOISE,\n",
    "          sf_0=sf_0, \n",
    "          B_sf=B_sf):\n",
    "    \n",
    "    t_start = time.time()\n",
    "    \n",
    "    if verbose: print('Starting training...')\n",
    "    \n",
    "    for batch_idx, (data, label) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        retina_data = np.zeros((minibatch_size, N_phase * N_theta * N_azimuth * N_eccentricity))\n",
    "        fixmap_data = np.zeros((minibatch_size, N_azimuth * N_eccentricity))\n",
    "\n",
    "        for i in range(minibatch_size):\n",
    "            i_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "            j_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "            \n",
    "            data_fullfield = place_object(data[i, 0, :, :].numpy(), i_offset, j_offset, \n",
    "                                            CONTRAST=CONTRAST, NOISE=NOISE,\n",
    "                                            sf_0=sf_0, B_sf=B_sf)\n",
    "            retina_data[i, :], _  =  retina(data_fullfield, retina_transform)\n",
    "\n",
    "            fixmap_data[i,:], _ = accuracy_fullfield(accuracy_map, i_offset, j_offset, N_pic, colliculus_vector)\n",
    "            \n",
    "        retina_data = Variable(torch.FloatTensor(retina_data))\n",
    "        fixmap_data = Variable(torch.FloatTensor(fixmap_data))\n",
    "        \n",
    "        prediction = net(retina_data)\n",
    "        loss = loss_func(prediction, fixmap_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if verbose and batch_idx % 10 == 0:\n",
    "            acc, _ = accuracy_gain(prediction, fixmap_data, minibatch_size)\n",
    "            print('[%d/%d] Loss: %.3f Acc : %.3f'%(batch_idx*minibatch_size, len(train_loader.dataset),loss.data.numpy(), acc))\n",
    "            f = open(FIC_NAME.replace('npy', 'txt'), 'a')\n",
    "            f.write('%.5f\\t%.5f'%(loss, acc))    \n",
    "            f.close()\n",
    "    return net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, optimizer=optimizer,\n",
    "         vsize=N_theta*N_azimuth*N_eccentricity*N_phase,\n",
    "         asize=N_azimuth*N_eccentricity, offset_std=OFFSET_STD, offset_max=OFFSET_MAX, \n",
    "         CONTRAST=CONTRAST, NOISE=NOISE,\n",
    "         sf_0=sf_0, \n",
    "         B_sf=B_sf):\n",
    "    \n",
    "    #for batch_idx, (data, label) in enumerate(test_loader):\n",
    "    data, label = next(iter(test_loader))\n",
    "    batch_size = label.shape[0]\n",
    "\n",
    "    retina_data = np.zeros((batch_size, N_phase * N_theta * N_azimuth * N_eccentricity))\n",
    "    fixmap_data = np.zeros((batch_size, N_azimuth * N_eccentricity))\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        i_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "        j_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "        data_fullfield = place_object(data[i, 0, :, :].numpy(), i_offset, j_offset, \n",
    "                                        CONTRAST=CONTRAST, NOISE=NOISE,\n",
    "                                        sf_0=sf_0, B_sf=B_sf)\n",
    "        retina_data[i, :], _  =  retina(data_fullfield, retina_transform)\n",
    "\n",
    "        #accuracy_fullfield = do_offset(accuracy_map, i_offset, j_offset, N_pic=128, min=0.1)\n",
    "        fixmap_data[i,:], _ = accuracy_fullfield(accuracy_map, i_offset, j_offset, N_pic, colliculus_vector)\n",
    "        #colliculus_vector @ accuracy_fullfield.ravel()\n",
    "\n",
    "    retina_data = Variable(torch.FloatTensor(retina_data))\n",
    "    fixmap_data = Variable(torch.FloatTensor(fixmap_data))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = net(retina_data) #.data.numpy()\n",
    "        #indices_max = np.zeros(batch_size, dtype = 'int')\n",
    "        #for i in range(batch_size):\n",
    "        #    indices_max[i] = np.where(output[i,:] == max(output[i,:]))[0][0]\n",
    "        #acc = np.mean(fixmap_data.data.numpy()[:,indices_max])\n",
    "        #acc = 0.1 + (acc - 0.1) * 2.5\n",
    "        acc, _ = accuracy_gain(output, fixmap_data, batch_size)\n",
    "\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anywhere target, with noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additive noise + whitening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile(FIC_NAME):\n",
    "    for epoch in range(40):\n",
    "        train(net, minibatch_size)\n",
    "        loss = test(net)\n",
    "        print('Test set: Final Loss: %.3f'%loss) \n",
    "    torch.save(net, FIC_NAME)\n",
    "else:\n",
    "    net = torch.load(FIC_NAME)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsize = N_theta * N_azimuth * N_eccentricity * N_phase\n",
    "asize = N_azimuth * N_eccentricity\n",
    "offset_std=OFFSET_STD\n",
    "offset_max=OFFSET_MAX\n",
    "\n",
    "test_batch_size = 50\n",
    "test_loader = get_data_loader(batch_size=test_batch_size, train = False)\n",
    "\n",
    "data, label = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_n = np.zeros((test_batch_size, 1, vsize))\n",
    "a_data_n = np.zeros((test_batch_size, 1, asize))\n",
    "full_data = np.zeros((test_batch_size, 128, 128))\n",
    "full_fixmap_n = np.zeros((test_batch_size, 128, 128))\n",
    "        # target = np.zeros((minibatch_size, asize))\n",
    "\n",
    "for idx in range(test_batch_size):\n",
    "    i_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "    j_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "    \n",
    "    data_fullfield = place_object(data[idx, 0, :, :].numpy(), i_offset, j_offset, \n",
    "                                    CONTRAST=CONTRAST, NOISE=NOISE,\n",
    "                                    sf_0=sf_0, B_sf=B_sf)\n",
    "    input_n[idx, 0, :], _  =  retina(data_fullfield, retina_transform)\n",
    "\n",
    "    a_data_n[idx, 0, :], _ = accuracy_fullfield(accuracy_map, i_offset, j_offset, N_pic, colliculus_vector)\n",
    "    #full_fixmap_n[idx, :, :] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "delta = 1/N_azimuth\n",
    "log_r, theta = np.meshgrid(np.linspace(0, 1, N_eccentricity + 1), np.linspace(-np.pi*(.5 + delta), np.pi*(1.5 - delta), N_azimuth + 1))\n",
    "#for idx in range(test_batch_size):\n",
    "for idx in range(30, 35):\n",
    "    plt.figure(figsize = (15, 8))\n",
    "    plt.subplot(141)\n",
    "    plt.imshow(data[idx, 0, :, :].numpy())\n",
    "\n",
    "    plt.subplot(142)\n",
    "    im = retina_inverse_transform @ input_n[idx,0,:]\n",
    "    #plt.plot(input_n[idx,0,:])\n",
    "    #plt.subplot(162)\n",
    "    plt.imshow(im.reshape(128, 128))\n",
    "    plt.plot(63.5, 63.5, 'r+')\n",
    "    plt.title(idx)\n",
    "    #plt.subplot(132)\n",
    "    #plt.plot(a_data_n[idx,0,:])    \n",
    "    col = colliculus_inverse @ a_data_n[idx,0,:]\n",
    "    ax = plt.subplot(143, projection='polar')\n",
    "    vec_t = Variable(torch.FloatTensor(a_data_n[idx,0,:]))\n",
    "    vec_t = vec_t.reshape((1,N_azimuth * N_eccentricity))\n",
    "    ax.pcolor(theta, log_r, vec_t.reshape((N_azimuth, N_eccentricity)))\n",
    "    #plt.imshow(col.reshape(128, 128))\n",
    "    in_t = Variable(torch.FloatTensor(input_n[idx,0,:]))\n",
    "    out_t = net(in_t)\n",
    "    out_sig = F.sigmoid(out_t).detach().numpy()\n",
    "    out_t = out_t.reshape((1,N_azimuth * N_eccentricity))\n",
    "    #acc, _ = accuracy_gain(out_t.reshape(1,N_azimuth * N_eccentricity), vec_t.reshape(1,N_azimuth * N_eccentricity), 1)\n",
    "    acc, _ = accuracy_gain(out_t, vec_t, 1, full_fixmap = full_fixmap_n[idx, :].reshape((1, -1)))\n",
    "    #plt.subplot(165)\n",
    "    #plt.plot(out_sig)    \n",
    "    #plt.title(acc)\n",
    "    view = colliculus_inverse @ out_sig.flatten()\n",
    "    ax = plt.subplot(144, projection='polar')\n",
    "    ax.pcolor(theta, log_r, out_sig.reshape((N_azimuth, N_eccentricity)))\n",
    "    #plt.imshow(view.reshape(128, 128))\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    i = 0\n",
    "    offset_std=OFFSET_STD\n",
    "    offset_max=OFFSET_MAX\n",
    "    i_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "    j_offset = minmax(np.random.randn() * offset_std, offset_max)\n",
    "            \n",
    "    data_fullfield = place_object(data[i, 0, :, :].numpy(), i_offset, j_offset, \n",
    "                                    CONTRAST=CONTRAST, NOISE=NOISE,\n",
    "                                    sf_0=sf_0, B_sf=B_sf)\n",
    "    input_vector, _  =  retina(data_fullfield, retina_transform)\n",
    "\n",
    "    coll_fixmap, _ = accuracy_fullfield(accuracy_map, i_offset, j_offset, N_pic, colliculus_vector)\n",
    "\n",
    "    #plt.imshow(input_test)\n",
    "    in_ = Variable(torch.FloatTensor(input_vector))\n",
    "    out = net(in_)\n",
    "    \n",
    "    plt.figure(figsize = (20,6))\n",
    "\n",
    "    plt.subplot(151)\n",
    "    plt.imshow(image)\n",
    "\n",
    "    plt.subplot(152)\n",
    "    f = plt.plot(coll_fixmap)\n",
    "    f = plt.plot(F.sigmoid(out.data))\n",
    "\n",
    "    plt.subplot(153)\n",
    "    im = colliculus_inverse @ coll_fixmap\n",
    "    plt.imshow(im.reshape(128, 128))\n",
    "    print(max(coll_fixmap))\n",
    "    print(max(im))\n",
    "\n",
    "    plt.subplot(154)\n",
    "    im_pred = colliculus_inverse @ F.sigmoid(out).data.numpy().flatten()\n",
    "    plt.imshow(im_pred.reshape(128, 128))\n",
    "    ind_pred = np.where(im_pred == max(im_pred))\n",
    "    print(im[ind_pred])\n",
    "\n",
    "    plt.subplot(155)\n",
    "    test = F.sigmoid(out).data.numpy().reshape((N_azimuth, N_eccentricity))\n",
    "    indices_ij = np.where(test == max(test.flatten()))\n",
    "    azimuth = indices_ij[0][0]\n",
    "    eccentricity = indices_ij[1][0]\n",
    "    full_masque = colliculus[azimuth,eccentricity,:].reshape(128, 128)\n",
    "    plt.imshow(im_pred.reshape(128, 128) * full_masque)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_gain(prediction, fixmap_data, batch_size, full_fixmap=None):\n",
    "    \"\"\"\n",
    "    Actuate the predictions of the ``where'' pathway to compute final accuracy using the ``what'' pathway\n",
    "    \n",
    "    \"\"\"\n",
    "    acc = []\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        fixmap_coll =  fixmap_data[i, :].data.numpy()\n",
    "        pred_coll = F.sigmoid(prediction[i, :]).data.numpy()\n",
    "        \n",
    "        indice_max_coll = np.where(pred_coll == max(pred_coll))[0][0]\n",
    "        acc_coll = fixmap_coll[indice_max_coll]\n",
    "                \n",
    "        test = pred_coll.reshape((N_azimuth, N_eccentricity))\n",
    "        indices_ij = np.where(test == max(test.flatten()))\n",
    "        azimuth = indices_ij[0][0]\n",
    "        eccentricity = indices_ij[1][0]\n",
    "        full_masque = colliculus[azimuth,eccentricity,:] #> 0.0003\n",
    "        \n",
    "        if full_fixmap is not None:\n",
    "            full_ref = full_fixmap[i,:]\n",
    "            #print('OK')\n",
    "        else:\n",
    "            full_ref = colliculus_inverse @ fixmap_coll.flatten()\n",
    "            \n",
    "        full_pred = colliculus_inverse @ pred_coll.flatten()\n",
    "        #full_masque = colliculus_inverse @ masque.flatten()\n",
    "        #masque[np.where(masque < 0.11)] = 0\n",
    "#        full_pred *= full_masque\n",
    "        full_pred = full_masque\n",
    "        #full_pred = colliculus_inverse @ pred_coll_test.flatten()\n",
    "        \n",
    "        indice_max_full = np.where(full_pred == max(full_pred))[0][0]\n",
    "        #print(indice_max_full)\n",
    "        acc_full = full_ref[indice_max_full] \n",
    "                \n",
    "        #acc[i] = max(acc_full, acc_coll)\n",
    "        if acc_full > acc_coll:\n",
    "            acc += [acc_full]\n",
    "            \n",
    "        #acc[i] = 0.1 + (acc[i] - 0.1) * 2.25\n",
    "    #print(indices_max)\n",
    "    if len(acc) > 0:\n",
    "        acc_mean = np.mean(acc) #fixmap_data.data.numpy()[:,indices_max])\n",
    "    else:\n",
    "        acc_mean = acc_coll\n",
    "    #acc = np.mean(fixmap_data[:,indices_max])\n",
    "    return acc_mean, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vsize = N_theta * N_azimuth * N_eccentricity * N_phase\n",
    "asize = N_azimuth * N_eccentricity\n",
    "offset_std=OFFSET_STD\n",
    "offset_max=OFFSET_MAX\n",
    "\n",
    "N_pic_mnist = 28\n",
    "N_class_mnist = 10\n",
    "\n",
    "test_batch_size = 1000\n",
    "N_eccentricities = 9\n",
    "mem_acc_log = []\n",
    "mem_acc_data_log = []\n",
    "mem_ref_log = [] \n",
    "mem_ref_data_log = []\n",
    "\n",
    "ecc_max=.8\n",
    "r_pix = []\n",
    "\n",
    "eccentricities = range(N_eccentricities)\n",
    "for i_eccentricity in eccentricities:\n",
    "    \n",
    "    eccentricity = ecc_max * (1/rho)**(N_eccentricity - i_eccentricity)\n",
    "    \n",
    "    r = np.sqrt(N_X**2+N_Y**2) / 2 * eccentricity\n",
    "    print('at scale ', i_eccentricity, ' r=', r)\n",
    "    r_pix.append(r)\n",
    "\n",
    "    test_loader_2 = get_data_loader(batch_size=test_batch_size, train = False)\n",
    "\n",
    "    data, label = next(iter(test_loader_2))\n",
    "    input_n = np.zeros((test_batch_size, 1, vsize))\n",
    "    a_data = np.zeros((test_batch_size, asize))\n",
    "    full_fixmap_n = np.zeros((test_batch_size, 128 * 128))\n",
    "        \n",
    "    ref_data = np.zeros(test_batch_size)\n",
    "\n",
    "    for idx in range(test_batch_size):\n",
    "        theta = np.random.rand() * 2 * np.pi\n",
    "        i_offset = int(r * np.cos(theta))\n",
    "        j_offset = int(r * np.sin(theta))\n",
    "            \n",
    "        # changed\n",
    "        data_fullfield = place_object(data[idx, 0, :, :].numpy(), i_offset, j_offset, \n",
    "                                        CONTRAST=CONTRAST, NOISE=NOISE,\n",
    "                                        sf_0=sf_0, B_sf=B_sf)\n",
    "        input_n[idx, 0, :], _  =  retina(data_fullfield, retina_transform)\n",
    "\n",
    "        a_data[idx, :], accuracy_fullfield_map = accuracy_fullfield(accuracy_map, i_offset, j_offset, N_pic, colliculus_vector)\n",
    "        full_fixmap_n[idx,:] = accuracy_fullfield_map.flatten()\n",
    "        \n",
    "        # when we do not do a saccade, the reference accurracy data is pre-computed \n",
    "        if r <= N_pic_mnist:\n",
    "            ref_data[idx] = accuracy_map[N_pic_mnist - 1 + i_offset, N_pic_mnist - 1 + j_offset]\n",
    "        else:\n",
    "            ref_data[idx] = 1 / N_class_mnist      \n",
    "        \n",
    "        \n",
    "    in_t = Variable(torch.FloatTensor(input_n))\n",
    "    out_t = net(in_t)\n",
    "    a_data_t = Variable(torch.FloatTensor(a_data))\n",
    "    acc, acc_data = accuracy_gain(out_t, a_data_t, test_batch_size, full_fixmap=full_fixmap_n)\n",
    "    mem_acc_log += [acc]\n",
    "    mem_acc_data_log += [acc_data]\n",
    "    \n",
    "    mem_ref_log += [np.mean(ref_data)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(acc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "theta, log_r, vec_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx = 30\n",
    "w = 28\n",
    "log_r, theta = np.meshgrid(np.linspace(0, 1, N_eccentricity + 1), np.linspace(-np.pi*(.5 + delta), np.pi*(1.5 - delta), N_azimuth + 1))\n",
    "\n",
    "fig = plt.figure(figsize = (figwidth, figwidth/2.5))#1.618))#, constrained_layout=True)\n",
    "ax_A = plt.subplot(1, 4, 1)\n",
    "im = retina_inverse_transform @ input_n[idx, 0, :]\n",
    "ax_A.imshow(im.reshape(128, 128))\n",
    "ax_A.plot(64.5, 64.5, 'r+', markersize = 14, mew=3)\n",
    "ax_A.axis('off')\n",
    "#ax_A.set_title('Input', fontsize = 14)\n",
    "\n",
    "ax_B = plt.subplot(2, 4, 2, projection='polar', autoscale_on=False)\n",
    "vec_t = Variable(torch.FloatTensor(a_data_n[idx, 0, :]))\n",
    "vec_t = vec_t.reshape((1,N_azimuth * N_eccentricity))\n",
    "ax_B.pcolor(theta, log_r, vec_t.reshape((N_azimuth, N_eccentricity)))\n",
    "ax_B.grid('off')\n",
    "#ax.set_rgrids('off')\n",
    "plt.title('True', fontsize = 14)\n",
    "ax_B.set_yticklabels([])\n",
    "ax_B.set_xticklabels([])\n",
    "\n",
    "ax_Bb = plt.subplot(2, 4, 6, projection='polar')\n",
    "in_t = Variable(torch.FloatTensor(input_n[idx,0,:]))\n",
    "out_t = net(in_t)\n",
    "out_sig = F.sigmoid(out_t).detach().numpy()\n",
    "ax_Bb.pcolor(theta, log_r, out_sig.reshape((N_azimuth, N_eccentricity)))\n",
    "ax_Bb.set_title('Predicted', fontsize = 14)\n",
    "ax_Bb.set_yticklabels([])\n",
    "ax_Bb.set_xticklabels([])\n",
    "\n",
    "test = out_sig.reshape((N_azimuth, N_eccentricity))\n",
    "indices_ij = np.where(test == max(test.flatten()))\n",
    "azimuth = indices_ij[0][0]\n",
    "eccentricity = indices_ij[1][0]\n",
    "full_masque = colliculus[azimuth,eccentricity,:]\n",
    "indice_move = np.where(full_masque == max(full_masque))\n",
    "i_move = indice_move[0][0] // 128 - 64\n",
    "j_move = indice_move[0][0] % 128 - 64\n",
    "print(i_move, j_move)\n",
    "\n",
    "ax_C = plt.subplot(1, 4, 3)\n",
    "data_fullfield = place_object(data[idx, 0, :, :].numpy(), 0, 0, \n",
    "                                CONTRAST=CONTRAST, NOISE=NOISE,\n",
    "                                sf_0=sf_0, B_sf=B_sf)\n",
    "input_vector, _  =  retina(data_fullfield, retina_transform)\n",
    "im = retina_inverse_transform @ input_vector # input_n[idx,0,:]\n",
    "ax_C.imshow(im.reshape(128, 128))\n",
    "ax_C.plot(64.5, 64.5, 'r+', markersize = 14, mew=3)\n",
    "ax_A.arrow(64.5, 64.5, j_move, i_move, width=.3, color='r', head_width=4., length_includes_head=True, edgecolor='k')\n",
    "for ax in [ax_A, ax_C]:\n",
    "    ax.plot([N_pic//2-w/2, N_pic//2+w/2, N_pic//2+w/2, N_pic//2-w/2, N_pic//2-w/2], \n",
    "            [N_pic//2-w/2, N_pic//2-w/2, N_pic//2+w/2, N_pic//2+w/2, N_pic//2-w/2], '--', color='r', lw=.75, markeredgewidth=1)\n",
    "plt.axis('off')\n",
    "vec_t = vec_t.reshape((1,N_azimuth * N_eccentricity))\n",
    "out_t = out_t.reshape((1,N_azimuth * N_eccentricity))\n",
    "acc, _ = accuracy_gain(out_t, vec_t, 1, full_fixmap = full_fixmap_n[idx, :].reshape((1, -1)))\n",
    "#ax_C.set_title('Final accuracy : ' + str(acc), fontsize = 14)\n",
    "\n",
    "ax_D = plt.subplot(1, 4, 4)\n",
    "r_ref = r_pix\n",
    "r_ref = range(9)\n",
    "\n",
    "ax_D.bar(r_ref, mem_acc_log, alpha = .5, label = 'One saccade')\n",
    "ax_D.bar(r_ref, mem_ref_log, alpha = .5, label = 'No saccade') #accuracy_map[27,27:55])\n",
    "ax_D.plot(np.arange(10)-.5, [0.1]*10, ':', c='k', label = 'Baseline')\n",
    "plt.legend(loc='best')\n",
    "ax_D.set_title('Class accuracy', fontsize = 14)\n",
    "ax_D.set_xlabel('Target eccentricity (pixels)', fontsize = 12)\n",
    "ax_D.set_xticks(range(9))\n",
    "ax_D.set_xticklabels(['%.1f' % d for  d in r_pix])\n",
    "\n",
    "ax_D.set_ylim([0,1])\n",
    "\n",
    "for ax, text in [[ax_A, 'DIS'], [ax_C, 'SAC']]:\n",
    "    ax.text(4, 15, text, fontsize=24,\n",
    "          bbox={'facecolor':'white','alpha':1,'edgecolor':'none','pad':1},\n",
    "          ha='left', va='center') \n",
    "\n",
    "offset = -.015\n",
    "# y_offset = 1.2\n",
    "for ax, text, x_offset, y_offset in [[ax_A, 'A', offset, 1.15], [ax_B, 'B', -.25, 1.225], [ax_C, 'C', offset, 1.15], [ax_D, 'D', offset, 1.15]]:\n",
    "    ax.text(x_offset, y_offset, '(' + text + ')', fontsize=24,\n",
    "              bbox={'facecolor':'white','alpha':1,'edgecolor':'none','pad':1},\n",
    "              ha='left', va='center', transform=ax.transAxes) \n",
    "\n",
    "# pos : [left, bottom, width, height] =    The new position of the in `.Figure` coordinates.    \n",
    "plt.tight_layout()\n",
    "ax_A.set_position([0.025, 0.1, .3, .45])\n",
    "ax_B.set_position( [0.24, 0.375, .2, 0.2])\n",
    "ax_Bb.set_position([0.24, 0.1, .2, 0.2])\n",
    "ax_C.set_position([0.35, .1, .3, .45])\n",
    "ax_D.set_position([0.65, .1, .3, .45])\n",
    "fig.savefig(figname + '.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fig.savefig?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:43:27.591507Z",
     "start_time": "2018-10-08T14:43:24.722160Z"
    }
   },
   "outputs": [],
   "source": [
    "!convert  -density {dpi_export} {figname}.pdf {figname}.jpg\n",
    "!convert  -density {dpi_export} {figname}.pdf {figname}.png\n",
    "#!convert  -density {dpi_export} -resize 5400  -units pixelsperinch -flatten  -compress lzw  -depth 8 {fname}.pdf {fname}.tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T10:36:00.981927Z",
     "start_time": "2018-07-03T10:36:00.949864Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('{figname}.png'.format(figname=figname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T10:36:00.939193Z",
     "start_time": "2018-07-03T10:36:00.766218Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls  -l {figname}*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:53:30.186131Z",
     "start_time": "2018-10-08T14:43:18.414Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, shl_scripts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
