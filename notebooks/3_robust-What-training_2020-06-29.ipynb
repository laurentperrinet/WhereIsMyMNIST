{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../figures\")\n",
    "\n",
    "from what import WhatShift, WhatBackground, WhatNet, WhatTrainer, What, train, test, MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w': 28,\n",
       " 'minibatch_size': 100,\n",
       " 'train_batch_size': 50000,\n",
       " 'test_batch_size': 10000,\n",
       " 'noise_batch_size': 1000,\n",
       " 'mean': 0.1307,\n",
       " 'std': 0.3081,\n",
       " 'N_pic': 128,\n",
       " 'offset_std': 30,\n",
       " 'offset_max': 34,\n",
       " 'noise': 1.0,\n",
       " 'contrast': None,\n",
       " 'sf_0': 0.1,\n",
       " 'B_sf': 0.1,\n",
       " 'N_theta': 6,\n",
       " 'N_azimuth': 24,\n",
       " 'N_eccentricity': 10,\n",
       " 'N_phase': 2,\n",
       " 'rho': 1.41,\n",
       " 'bias_deconv': True,\n",
       " 'p_dropout': 0.0,\n",
       " 'dim1': 1000,\n",
       " 'dim2': 1000,\n",
       " 'lr': 0.005,\n",
       " 'do_adam': True,\n",
       " 'bn1_bn_momentum': 0.5,\n",
       " 'bn2_bn_momentum': 0.5,\n",
       " 'momentum': 0.3,\n",
       " 'epochs': 60,\n",
       " 'num_processes': 1,\n",
       " 'no_cuda': True,\n",
       " 'log_interval': 100,\n",
       " 'verbose': 1,\n",
       " 'filename': '../data/2019-06-05',\n",
       " 'seed': 2019,\n",
       " 'N_cv': 10,\n",
       " 'do_compute': True,\n",
       " 'what_offset_std': 0,\n",
       " 'what_offset_max': 25}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from main import init\n",
    "args = init(filename='../data/2019-06-12') # pas de drop out!\n",
    "args.what_offset_std = 0\n",
    "args.what_offset_max = 25\n",
    "args.contrast = None\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_offset = None\n",
    "j_offset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "                               WhatShift(args,i_offset=i_offset, j_offset=j_offset),\n",
    "                               WhatBackground(contrast = args.contrast,\n",
    "                                              noise=args.noise, \n",
    "                                              sf_0=args.sf_0, \n",
    "                                              B_sf=args.B_sf),\n",
    "                               transforms.ToTensor(),\n",
    "                               #transforms.Normalize((args.mean,), (args.std,))\n",
    "                           ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = MNIST('../data',\n",
    "                        train=True,\n",
    "                        download=True,\n",
    "                        transform=transform,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset_train,\n",
    "                                         batch_size=args.minibatch_size,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = MNIST('../data',\n",
    "                        train=False,\n",
    "                        download=True,\n",
    "                        transform=transform,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset_test,\n",
    "                                         batch_size=args.minibatch_size,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAasUlEQVR4nO3da4ycV3kH8P8z99mbvesbtmNyIxTSQANYURERUHEphFZJKpGSVigVqKYUVECAStMP5FMb2gJFbUVrSkRo04RIECWlCZCGSim0QJwoJAGTxBjf1muv7d313uf69MNOYGP2/M96Z3dmm/P/SSuv55nzzpl33mfe2Xnec465O0TkhS/T7Q6ISGco2UUSoWQXSYSSXSQRSnaRRCjZRRKhZP9/zswOmdmbl3lfN7OXrPBxVtxW1gclu6w5M3u5mX3bzM6a2QEzu77bfUqRkl3WlJnlANwL4OsAhgDsAfCvZvbSrnYsQUr2FxAzu8rM/tfMJsxsxMz+3swK59ztGjM7aGanzeyvzSyzqP17zGy/mY2b2TfN7MJV6NbLAOwA8Fl3b7j7twF8F8C7V2Hbch6U7C8sDQAfAbAZwGsBvAnAH59zn+sB7AbwagDXAngPAJjZtQBuBvA7ALYA+G8Ady7nQc3sE2b29fPopwG44jzuL6tAyf4C4u6Puvv33L3u7ocA/BOAN5xzt0+5+5i7HwHwtwBubN3+RwD+0t33u3sdwF8AuHI5Z3d3v9XdfysQfhrAKICPm1nezN7a6lPPeT9BaYuS/QXEzF5qZl83sxNmNomFhN18zt2OLvr9MBY+YgPAhQA+1/oTYALAGBbOwDvb6ZO71wBcB+AdAE4A+CiAuwEca2e7cv6U7C8snwfwEwCXufsAFj6W2zn32bXo9xcDON76/SiA97n7xkU/ZXf/n3Y75e5PuPsb3H2Tu/8mgEsA/KDd7cr5UbK/sPQDmAQwbWYvA/D+Je7zcTMbNLNdAD4E4Cut2/8RwJ+Z2a8CgJltMLN3rkanzOyVZlYysx4z+xiA7QC+tBrbluVTsr+wfAzA7wGYAvAF/CKRF7sXwKMAHgfwHwC+CADufg+ATwG4q/UnwFMA3r6cBzWzm83sAXKXdwMYwcLf7m8C8BZ3ryxn27J6TJNXiKRBZ3aRRCjZRRKhZBdJhJJdJBG5Tj5YtrfXc4ND4Tvk2/iysBmLn1tufr5MnTe3SJy2jTwti/TdmnwDjUL4uTXKvG0mzx+8mGvjiQNoePh8EvtumL9iQDbD+95ohh+7WuOHfmaeP3puLtL5SLiZC2/fs5FNk1N07ewY6nMzS268rWQ3s7cB+ByALIB/dvdb2f1zg0O44E8+Eow3tq+8GuOz/KlkZ/mHmNIpHi+OhV+9WDJn5yPxKt9AYbpB42cvygdjE1fwZO3ZOkPjl24+Q+M5430br4Sviq01+FGdiyTzxuIcjU9UysHY4WPnXlj4fD3Pnjt+6Pk2P8X3a6bGX9O5TeHnXu3nbzSNcjh+4I7PhPtEt0qYWRbAP2ChFns5gBvN7PKVbk9E1lY7f7NfBeCAux909yqAu7AwikpE1qF2kn0nnj+o4hiWGDRhZnvMbJ+Z7WvO8I+MIrJ21vzbeHff6+673X13prd3rR9ORALaSfZhPH8E1QWt20RkHWon2R8BcJmZXdya+uhdAO5bnW6JyGpbcenN3etm9kEA38RC6e02d/8RbVRwNHaEy2tbN0+utDsYm+QTn9SsROP1af6+l+0NlzsyVdoU1uBlmNIELzFl53g8PxPefm6Kl7fmeoo0fsB5iaoyHy77AYCT6xtyBV6+qs3w8tfxnhqN58n2M5P80C9EDkVWJweWcW1EMdx+fhPfdnUofDw0ycvRVp3d3e8HcH872xCRztDlsiKJULKLJELJLpIIJbtIIpTsIolQsoskoqPj2c2c1lbLeV43LWbDbSuR8cnTZGwzAFTLvOZbqYXb2zyvZZeP83jxLK+rNnP8uTVIqTy39NDmX7Sd5nXyucg8ALmTvBaeI+PCm7nI9Qc1/tj1Xt73eTI/Qu9Rfjz0jfChu/mpyPEyyF+zme3h51bZwq+raJZIPBN+zjqziyRCyS6SCCW7SCKU7CKJULKLJELJLpKIjpbevGmozYZLNXMDvJSyqRSe1sr7IiWiLC9nWGSKWHdSKqlHhpHObqTx8Zfy9rUB3jc2wWt0iuxIecsrvG/ZSmSoJ6mmZsg+BYBGKTJMtDcyBzdpPr85MsV25DUtn4oMQ43MEFvrDz++k/IZAGTZsGVSKtWZXSQRSnaRRCjZRRKhZBdJhJJdJBFKdpFEKNlFEtHROjvqhux4+CFnBvlwycKGcEGZ1eABYLLKp0zuK/D5oC8bOBWMna7wlW4eGe2j8Tovw6N/6zSN18jw3up85CWOrYscGb5bG4itNx0OeTZybUMPH2bas5Gv4squregv8RWDR05voPHZI3xq8tws37HFiXAsf5Tvc7Zkc5YcxjqziyRCyS6SCCW7SCKU7CKJULKLJELJLpIIJbtIIjo7lXQDyJ8Nv79MT5Rp+9mhcB3+dZsO0LaX94/QeE9k3eWhXLjWvQ8X07YDkTr59DSv2ZbyfFD6joHw+sInp/pp22pk3HYlw+cYaEROF5lCuFbuZHpuAOgfnKXxlwydpvEd5fB+yWV4Df9gmS9V/bPeIRqfOc73+8DT4f0++Cw/Fus94f2WqZLlu+lWI8zsEIApAA0AdXff3c72RGTtrMaZ/Tfcnb/FikjX6W92kUS0m+wO4Ftm9qiZ7VnqDma2x8z2mdm+xiy/fl1E1k67H+OvdvdhM9sK4EEz+4m7P7z4Du6+F8BeACjt2MVHPojImmnrzO7uw61/RwHcA+Cq1eiUiKy+FSe7mfWaWf9zvwN4K4CnVqtjIrK62vkYvw3APWb23Hb+zd2/wRpk6kCJfW+f4WPOnx0I1z7f+aJ9tO31vbzOXnFey/7m7M5g7MjsIG07O8uflzf42OdMZE77SiP8MjYic7NnI/PpF8gS2wBgRb7M9qWbzwRjT+5/MW07F9lv4709NL6hMB+MDWX490elLH9e+Syv03ue71fPhuvs1X5+7YPRTYdf7xUnu7sfBPBrK20vIp2l0ptIIpTsIolQsoskQskukgglu0giOjrENdMAymPhukGmzstEEwPhYYNPXLKLtv39/nAJCABO1/mwwkemw8NYf3RkO21b+CkfumtFXlo72eBzTZf6w9MiNyJlPbaENgDc8Cpe0oy55+lXBmPFk/zwa47xEtShOd5+YnN4v+dzvHR2anSAxjPjfOhvaYKfR7Nz4de8MhBpS4axsmmmdWYXSYSSXSQRSnaRRCjZRRKhZBdJhJJdJBFKdpFEdHgqaUdhKlzfLIRn/gUA1HvDtc3vn7qItr2v7xkaP1C5hMa/feylwVhpP6+jbzgYWdY4Ynonr4XP7gi/jNk5Xme/9u2PrKhPy1WbDvd92zN8v9RLvO8zFb5fzubCQ2ALZT6E1WZ4ahQm+XmyOE7D8Gz4uXkuspQ1ux6FhHRmF0mEkl0kEUp2kUQo2UUSoWQXSYSSXSQRSnaRRHS2zl5zlEbD0/s2c/y9p+9YOH7k6W207d9l30TjGfDa5sTpvmBs4wRtip4TfKy81Xm9OT/D68nF8fC47/LvnuBtM3yq6Ha9/NLjwVj1jhfRtpVBPma83sPHu1cHw/utEZnqOTMUniMAAOaz/DVBk6cWq8PnZvmx2HMyfI0AW7JZZ3aRRCjZRRKhZBdJhJJdJBFKdpFEKNlFEqFkF0lER+vsnjNUB8PL8HomsnQxKQn3H+Q11wNFXtMtD83ROCvD18MleABArZ/v5kyN11Wbeb5f5raE46/ffJi27abpHZFadURxIrLfjoTPZTNeom0LF/AlnQtbZml8vt7L20+Fj9fSOJ/TPjsfjpu3UWc3s9vMbNTMnlp025CZPWhmz7b+5QuUi0jXLedj/JcAvO2c2z4B4CF3vwzAQ63/i8g6Fk12d38YwNg5N18L4PbW77cDuG6V+yUiq2ylX9Btc/eR1u8nAAQvTDezPWa2z8z21ar87yARWTttfxvv7g7y9ZW773X33e6+O1/gX1qIyNpZabKfNLPtAND6d3T1uiQia2GlyX4fgJtav98E4N7V6Y6IrJVond3M7gTwRgCbzewYgE8CuBXA3Wb2XgCHAdywnAfzrGF+MPyQ1QFeT66Xw/EMnwYchVH+VOdLvOabmQ63z/Dh6qiX+Xtqgy8Fjlof3y9vvuEHwVgu096c9e3afyi8dv2GIb5fSuO8733DfMcXyGtWL/PrMrCL1/DNIvFG5JoR0vXcHK+zN0rhvruFHzea7O5+YyDEZ4MQkXVFl8uKJELJLpIIJbtIIpTsIolQsoskoqNDXAGAVSyq/bxcUdkUblwc421LZ3jcs+GhtwBQOhVuP/gMr/vlZnkpJTZlcumm7k4H3Y7ikfB+LZ7l5avSGN9vxRG+xnduNryU9txmfjXn2Ake9wIvC5ZP8fNo/3D4NSuM8svK6wPh4bnW1FTSIslTsoskQskukgglu0gilOwiiVCyiyRCyS6SiM4u2dxwFCfC9cXZrSufWjiyQi7yUzzef4jHBw6Ha+nl7z3DG2/ZRMOVoS28fRfd/fhraPyGKx9d8bZjdfTyMf6i2XxkKey+cD265xR/bH+SD4Gd28zjPSci1xCMhpeEthk+rTk71K0Rrv/rzC6SCCW7SCKU7CKJULKLJELJLpIIJbtIIpTsIonoeJ09NxWuVw8cikwtfCYcZ+N4V0Oe9BvZyLTEGf68CuTaAwCYvCs8HTMATL0/PN79u8MX07a5BzbSeJksBw0AuJKHX/yN8Njs3ARf9tiPHOcbH+in4XpfeJ6Aah9/TfIz/HjKT/N4NjK1eW0gfE2JNflrYpXwNQJs2XOd2UUSoWQXSYSSXSQRSnaRRCjZRRKhZBdJhJJdJBGdnTc+Y2gWwzXp8jCfL7vvLIk3IuOTe8JjmwGguo3XbJuF8Pti9RUX0baNIn9PtUZk+d/IqssPf/XVwVjpFN/20E/42Omjb+nhDx6ROzgSjFmJz9VvkXkAGpv4aza9M1zLntsSu/aB77fYePhmgV+fMLslnHq1Xt633Fz4gPCfhttGz+xmdpuZjZrZU4tuu8XMhs3s8dbPNbHtiEh3Ledj/JcAvG2J2z/r7le2fu5f3W6JyGqLJru7PwxgrAN9EZE11M4XdB80sydaH/MHQ3cysz1mts/M9lWr/G9yEVk7K032zwO4FAvDIEYAfDp0R3ff6+673X13ocAXyxORtbOiZHf3k+7ecPcmgC8AuGp1uyUiq21FyW5mi8dcXg/gqdB9RWR9iNbZzexOAG8EsNnMjgH4JIA3mtmVABzAIQDvW86DNbOGylB4jDGLAUB+MlwrLx09yx98ZJSGi+N8re/axS8KxmZ38Bp+I1Jz9chw+CbfLSidCdeE+0b4WPn8yASN2xW8/Vg18qdZNTywu7GDz5ffIGO+AaDaz3dMrSe832Pj0YuT/OKGZj7ymkamAWCvabV/5V+lsfHs0WR39xuXuPmLK+6NiHSFLpcVSYSSXSQRSnaRRCjZRRKhZBdJREeHuHqGl0NmdvD3nno5XKPqO8rLOJueLNN49kxkeWAPl2o8y+ss9TKPx0prmci0xKWJcJmodGqeP3Y/3y+/fSm/hOLobPBKaQDA/GsuCcYqg+0dfrH9DhaOzDzezPFtZ2ttTl1OmmfqkWmqq+E4m1JdZ3aRRCjZRRKhZBdJhJJdJBFKdpFEKNlFEqFkF0lEZ+vsWaDaR+rsF0Smg+4PD7esl/lwyHqJTzvcf5zXm0ujlWAsP8P7XennuznHZ3NGfoYPt8xPhx+/WeDjZ2ub+PDcdp25IjxddD0yS3UhMmq5MMnr0XRocaREnw2/3MtqX9nA7zBHlsLOT/O2uTlyzYeWbBYRJbtIIpTsIolQsoskQskukgglu0gilOwiiehonb2ZB2YuCMe9l9ers8VwvL6FD/qerfNB47l5Xo8unwjXNksneaE8N8uvAWBjkAHAqrzOnpuYDQcbkSmRCxtovF1sLH7s+gI2bns5nBzdsTkEPHIarJd4LbyykcdrA+Hn1uArWQMWPlYb5FDTmV0kEUp2kUQo2UUSoWQXSYSSXSQRSnaRRCjZRRKxnCWbdwH4MoBtWJjteq+7f87MhgB8BcBFWFi2+QZ3H2fb8ixQ7yXzWp/l3cmcDBdHY+9axXFe98zP8no04zn+6LXeyPOqRcarR+I2Xw3G6oeO0LaFsSEabxerV+dmI9cX8NWio+PhmWykxh+buz0/ExtLz4+JTC18PMaW8K6RVbLZ/l7Omb0O4KPufjmAXwfwATO7HMAnADzk7pcBeKj1fxFZp6LJ7u4j7v5Y6/cpAPsB7ARwLYDbW3e7HcB1a9VJEWnfef3NbmYXAXgVgO8D2ObuI63QCSx8zBeRdWrZyW5mfQC+CuDD7j65OObujsDqVWa2x8z2mdm+xvRMW50VkZVbVrKbWR4LiX6Hu3+tdfNJM9veim8HMLpUW3ff6+673X13to98syAiayqa7GZmAL4IYL+7f2ZR6D4AN7V+vwnAvavfPRFZLcsZ4vo6AO8G8KSZPd667WYAtwK428zeC+AwgBtiG8rUgPLJ8PtLLvIpv/dEeIhrho+ORXGcD4EtHJugcSNDRSsX8vLV9A5eS2nm+ctQPsPjPWS66GI9smNykToPzkTi3NxWMjT4DC+HGh8ZjGpkdG6GlO56z/DSWfk032/FU2RYMYDSWGxq8/B+b+b5OZgdT3RIMd0qAHf/DsKzZL8p1l5E1gddQSeSCCW7SCKU7CKJULKLJELJLpIIJbtIIjo6lXSmBvQOr3x64PKpcBHRnG83NzFP441nD66oTwCQ2cYLvhZ5yjW+mnS07lrtDc89XNxK5u4GYI3IUE5b+X4BgAZZETo2ZXKDr6KN+e382gmrsWs6+PUFvWTqcADInp6kcWPjUAFgILxjsnORa0KmwjX83Hz4ehCd2UUSoWQXSYSSXSQRSnaRRCjZRRKhZBdJhJJdJBEdrbPHNCO9aebC45+zpL4IAM0yX6M308+L3T4Xnns4M1WhbfuG+djmbIU/8VpkyuTKUHi/VDbxMeO5ab7t+w5dQeNX7/wZjZdPhR8/x4eER5dVhvPn5vnwMTG/mdfZp6f4gzeK22l8ZivffqMY7nvfSGTp8kr4eXk2vF2d2UUSoWQXSYSSXSQRSnaRRCjZRRKhZBdJhJJdJBEdr7PTWjovm6JRDtcuWQwAar38fa244VdoPDcTnoS83sdrsrk5XjftPc6vEZjZwev085vCsWZk7nW2xC8AlP59I433f5DPE8CWVe4/zJ93+RQNo/8wf82rG8IH1HxkpeqpC/nBePYlkeNtMLLMNlmyOXYs95wIt22qzi4iSnaRRCjZRRKhZBdJhJJdJBFKdpFEKNlFEhGts5vZLgBfBrANgAPY6+6fM7NbAPwhgOeqoTe7+/10W02gME3WOR9Y+brU9TKvi1Z5uRgeWQy8cDYcL07wOcb7jvPHzk9W+WNP8ZcpNx/eL3P9vG/Rudm38Pb3PPBaGn/zOx4Lxn744ytp295hXsPPVPn1CzO7wkX+ZmRd+ti0707mw1+4Aw8XxsPHes8JXqMvTYSfd4asA7Cci2rqAD7q7o+ZWT+AR83swVbss+7+N8vYhoh0WTTZ3X0EwEjr9ykz2w9g51p3TERW13n9zW5mFwF4FYDvt276oJk9YWa3mdlgoM0eM9tnZvtqlcgcSCKyZpad7GbWB+CrAD7s7pMAPg/gUgBXYuHM/+ml2rn7Xnff7e6788W+VeiyiKzEspLdzPJYSPQ73P1rAODuJ9294e5NAF8AcNXadVNE2hVNdjMzAF8EsN/dP7Po9sXTa14P4KnV756IrJblfBv/OgDvBvCkmT3euu1mADea2ZVYKDIcAvC+2IY8A9TL4feX6kZePmPlkHoPr3U4r7SgWYwMSSQbyM/wbTdK/HllK7xzseWoM6Ry1yzxtraVl7d2bRmn8ZgHHntFMNZ7CT/XzA1F6oIRtYHwfq9HSmdZPjs4eocjpd5+/poWx8OvS/9h/powbAnu5Xwb/x0sPdKc1tRFZH3RFXQiiVCyiyRCyS6SCCW7SCKU7CKJULKLJKKjU0k388Dsi8j0vpsitXLy1uRZ3jZbidS6q/x9L0tKn2wpaQCokWsLAKCZja1NzLGljZslfv3AzqFJGt+96Qh/7MiyybVGuN48uoFfPt3M8b7nc3yI69xsMbzt8XAMAMrDvE7eN8wfux65toLFqxv5cGu23HMzHz7WdGYXSYSSXSQRSnaRRCjZRRKhZBdJhJJdJBFKdpFEmEfGSq/qg5mdAnB40U2bAZzuWAfOz3rt23rtF6C+rdRq9u1Cd9+yVKCjyf5LD262z913d60DxHrt23rtF6C+rVSn+qaP8SKJULKLJKLbyb63y4/PrNe+rdd+AerbSnWkb139m11EOqfbZ3YR6RAlu0giupLsZvY2M3vazA6Y2Se60YcQMztkZk+a2eNmtq/LfbnNzEbN7KlFtw2Z2YNm9mzr3yXX2OtS324xs+HWvnvczK7pUt92mdl/mdmPzexHZvah1u1d3XekXx3Zbx3/m93MsgCeAfAWAMcAPALgRnf/cUc7EmBmhwDsdveuX4BhZq8HMA3gy+5+Reu2vwIw5u63tt4oB939T9dJ324BMN3tZbxbqxVtX7zMOIDrAPwBurjvSL9uQAf2WzfO7FcBOODuB929CuAuANd2oR/rnrs/DGDsnJuvBXB76/fbsXCwdFygb+uCu4+4+2Ot36cAPLfMeFf3HelXR3Qj2XcCOLro/8ewvtZ7dwDfMrNHzWxPtzuzhG3uPtL6/QSAbd3szBKiy3h30jnLjK+bfbeS5c/bpS/oftnV7v5qAG8H8IHWx9V1yRf+BltPtdNlLePdKUssM/5z3dx3K13+vF3dSPZhALsW/f+C1m3rgrsPt/4dBXAP1t9S1CefW0G39e9ol/vzc+tpGe+llhnHOth33Vz+vBvJ/giAy8zsYjMrAHgXgPu60I9fYma9rS9OYGa9AN6K9bcU9X0Abmr9fhOAe7vYl+dZL8t4h5YZR5f3XdeXP3f3jv8AuAYL38j/FMCfd6MPgX5dAuCHrZ8fdbtvAO7Ewse6Gha+23gvgE0AHgLwLID/BDC0jvr2LwCeBPAEFhJre5f6djUWPqI/AeDx1s813d53pF8d2W+6XFYkEfqCTiQRSnaRRCjZRRKhZBdJhJJdJBFKdpFEKNlFEvF/CiwsvYD1A9EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAPiElEQVR4nO3df6xfd13H8eeLjR+Kg7Ht0jTrRqcUZiXC8GZCMCAbkLkiKz+yjAgpptpAEDFgpIqJBDV2moAzLiZ1m1QCjFklq6LoLF0WCENuXdnYBozNLnRs6wW2ABoZw7d/fE+zy+1t77n3fr/f+/2sz0fS3HPO99z7fe309rXP/ZwfN1WFJKk9T1jtAJKk5bHAJalRFrgkNcoCl6RGWeCS1KiTx/lmZ5xxRq1fv36cbylJzdu/f/83q2pq/vaxFvj69euZmZkZ51tKUvOS3LvQdqdQJKlRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpUWO9E1OjsX77J3vtd3DHphEnkTROjsAlqVEWuCQ1ygKXpEZZ4JLUKAtckhrVq8CTnJpkd5IvJ7kzyYuTnJbkhiR3dR+fMeqwkqTH9B2BXwF8qqrOBZ4P3AlsB/ZW1QZgb7cuSRqTRQs8ydOBlwJXA1TVI1X1MHAJsKvbbReweVQhJUlH6zMCPweYBf4myS1JrkryVGBNVd3f7fMAsGZUISVJR+tT4CcDLwT+qqrOA/6bedMlVVVALfTJSbYlmUkyMzs7u9K8kqROnwI/BByqqs9367sZFPqDSdYCdB8PL/TJVbWzqqaranpq6qhfqixJWqZFC7yqHgC+nuS53aYLgTuAPcCWbtsW4PqRJJQkLajvw6zeAXwkyZOAe4BfZVD+1yXZCtwLXDqaiJpUfR+iBT5ISxqFXgVeVQeA6QVeunC4cSRJfXknpiQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1Ki+D7PS40Dfh0/54CmpDY7AJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKApekRlngktSoXg+zSnIQ+C7wQ+DRqppOchrwcWA9cBC4tKoeGk1MSdJ8SxmBv7yqXlBV0936dmBvVW0A9nbrkqQxWckUyiXArm55F7B55XEkSX31LfAC/i3J/iTbum1rqur+bvkBYM1Cn5hkW5KZJDOzs7MrjCtJOqLvL3T4haq6L8kzgRuSfHnui1VVSWqhT6yqncBOgOnp6QX3kSQtXa8ReFXd1308DHwCOB94MMlagO7j4VGFlCQdbdECT/LUJKccWQZeBXwJ2ANs6XbbAlw/qpCSpKP1mUJZA3wiyZH9P1pVn0ryBeC6JFuBe4FLRxdT49T3d2dKWl2LFnhV3QM8f4Ht3wIuHEUoSdLivBNTkhplgUtSoyxwSWqUBS5Jjep7I48kHddSrl46uGPTCJOcOByBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZ5GaHGou8lZl5eJvXnCFySGmWBS1KjnEJZBU4nSBoGR+CS1CgLXJIa5RSKmuQ0lOQIXJKaZYFLUqMscElqlHPgE2wpD8iXdOJxBC5JjbLAJalRvadQkpwEzAD3VdWrk5wDXAucDuwH3lxVj4wmpk4UThtJ/S1lBP5O4M4565cDH6yqZwMPAVuHGUySdHy9CjzJOmATcFW3HuACYHe3yy5g8ygCSpIW1ncE/ufA7wD/162fDjxcVY9264eAMxf6xCTbkswkmZmdnV1RWEnSYxYt8CSvBg5X1f7lvEFV7ayq6aqanpqaWs6XkCQtoM9JzJcAr0lyMfAU4GnAFcCpSU7uRuHrgPtGF1OSNN+iI/Cq+t2qWldV64HLgE9X1a8A+4A3dLttAa4fWUpJ0lFWch34e4B3Jfkagznxq4cTSZLUx5Jupa+qG4Ebu+V7gPOHH0mS1Id3YkpSoyxwSWqUBS5JjbLAJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGmWBS1KjlvQbeaTHq/XbP9lrv4M7No04idSfI3BJapQFLkmNssAlqVHOgUsj4ry6Rs0RuCQ1ygKXpEYtOoWS5CnATcCTu/13V9UfJDkHuBY4HdgPvLmqHhllWGmp+k5jSC3qMwL/PnBBVT0feAFwUZIXAZcDH6yqZwMPAVtHF1OSNN+iBV4D3+tWn9j9KeACYHe3fReweSQJJUkL6jUHnuSkJAeAw8ANwN3Aw1X1aLfLIeDMY3zutiQzSWZmZ2eHkVmSRM8Cr6ofVtULgHXA+cC5fd+gqnZW1XRVTU9NTS0zpiRpviVdhVJVDwP7gBcDpyY5chJ0HXDfkLNJko6jz1UoU8APqurhJD8GvJLBCcx9wBsYXImyBbh+lEGlSeBVLZokfe7EXAvsSnISgxH7dVX1T0nuAK5N8kfALcDVI8wpSZpn0QKvqluB8xbYfg+D+XBJ0irwTkxJapQFLkmNssAlqVEWuCQ1yueBS6vM54ZruRyBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEZZ4JLUKAtckhplgUtSoyxwSWqUBS5JjbLAJalRPsxqiPx9iZoEPhzrxOEIXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDVq0QJPclaSfUnuSHJ7knd2209LckOSu7qPzxh9XEnSEX1G4I8C766qjcCLgLcn2QhsB/ZW1QZgb7cuSRqTRQu8qu6vqv/slr8L3AmcCVwC7Op22wVsHlVISdLRlnQnZpL1wHnA54E1VXV/99IDwJpjfM42YBvA2Wefvdyc0gnPO301X++TmEl+Avh74Leq6jtzX6uqAmqhz6uqnVU1XVXTU1NTKworSXpMrwJP8kQG5f2RqvqHbvODSdZ2r68FDo8moiRpIX2uQglwNXBnVX1gzkt7gC3d8hbg+uHHkyQdS5858JcAbwZuS3Kg2/Z7wA7guiRbgXuBS0cTUZK0kEULvKo+A+QYL1843DiSpL68E1OSGmWBS1KjLHBJapQFLkmNssAlqVEWuCQ1ygKXpEYt6WFWJyIfICRpUjkCl6RGWeCS1CinUKQTVN/pwYM7No04iZbLEbgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKOzElHZcPdJtcjsAlqVEWuCQ1ygKXpEYtOgee5Brg1cDhqnpet+004OPAeuAgcGlVPTS6mMPnvJ6k1vUZgX8IuGjetu3A3qraAOzt1iVJY7RogVfVTcC3522+BNjVLe8CNg85lyRpEcudA19TVfd3yw8Aa461Y5JtSWaSzMzOzi7z7SRJ8634JGZVFVDHeX1nVU1X1fTU1NRK306S1FlugT+YZC1A9/Hw8CJJkvpYboHvAbZ0y1uA64cTR5LU16IFnuRjwOeA5yY5lGQrsAN4ZZK7gFd065KkMVr0OvCqeuMxXrpwyFkkSUvgnZiS1KjH3dMIvcNS0onCEbgkNcoCl6RGWeCS1CgLXJIaZYFLUqMscElqlAUuSY2ywCWpURa4JDXKApekRlngktQoC1ySGtXMw6x8SJX0+NH33/PBHZtGnKRtjsAlqVEWuCQ1qpkpFEknnkmfalntfI7AJalRFrgkNcoCl6RGWeCS1CgLXJIaZYFLUqNWdBlhkouAK4CTgKuqasdQUknSEgz7cr5W7vxe9gg8yUnAlcAvARuBNybZOKxgkqTjW8kUyvnA16rqnqp6BLgWuGQ4sSRJi1nJFMqZwNfnrB8Cfn7+Tkm2Adu61e8l+coK3nOuM4BvDulrDdMk5prETDCZuSYxE0xmrknMBMfJlcvHnOSx913psXrWQhtHfit9Ve0Edg776yaZqarpYX/dlZrEXJOYCSYz1yRmgsnMNYmZYDJzjSrTSqZQ7gPOmrO+rtsmSRqDlRT4F4ANSc5J8iTgMmDPcGJJkhaz7CmUqno0yW8A/8rgMsJrqur2oSVb3NCnZYZkEnNNYiaYzFyTmAkmM9ckZoLJzDWSTKmqUXxdSdKIeSemJDXKApekRk18gSe5KMlXknwtyfYFXn9XkjuS3Jpkb5IFr5dchVxvTXJbkgNJPjOOu1QXyzRnv9cnqSRjudSqx7F6S5LZ7lgdSPJrq52p2+fS7nvr9iQfHXWmPrmSfHDOcfpqkocnINPZSfYluaX7d3jxqDP1zPWsrhNuTXJjknVjyHRNksNJvnSM15PkL7rMtyZ54YresKom9g+Dk6N3Az8JPAn4IrBx3j4vB368W34b8PEJyfW0OcuvAT612pm6/U4BbgJuBqYn5Fi9BfjLCfu+2gDcAjyjW3/mJOSat/87GFw8sNrHaifwtm55I3BwEo4V8HfAlm75AuDDY8j1UuCFwJeO8frFwL8AAV4EfH4l7zfpI/BFb9evqn1V9T/d6s0MrkefhFzfmbP6VGDUZ4v7PtrgD4HLgf8dcZ6l5hqnPpl+Hbiyqh4CqKrDE5JrrjcCH5uATAU8rVt+OvCNEWfqm2sj8Olued8Crw9dVd0EfPs4u1wC/G0N3AycmmTtct9v0gt8odv1zzzO/lsZ/N9t1HrlSvL2JHcDfwr85mpn6n5cO6uqxvmotb5/h6/vfqTcneSsBV4fd6bnAM9J8tkkN3dP3hy13t/v3VThOTxWUKuZ6X3Am5IcAv6ZwU8Go9Yn1xeB13XLrwVOSXL6GLIdz1I77bgmvcB7S/ImYBr4s9XOckRVXVlVPwW8B/j91cyS5AnAB4B3r2aOY/hHYH1V/SxwA7BrlfPA4B6JDcAvMhjp/nWSU1c10Y+6DNhdVT9c7SAMjs+HqmodgymCD3ffb6vtt4GXJbkFeBmDO8Un4XgNzSQc5OPpdbt+klcA7wVeU1Xfn5Rcc1wLbB5posUznQI8D7gxyUEG8297xnAic9FjVVXfmvP3dhXwc6udicHIaE9V/aCq/gv4KoNCX+1cR1zG6KdPoF+mrcB1AFX1OeApDB4otaq5quobVfW6qjqPQT9QVSM/6buI4T6CZNST+is8IXAycA+DHxWPnKj4mXn7nMfgZMaGCcu1Yc7yLwMzq51p3v43Mp6TmH2O1do5y68Fbp6ATBcBu7rlMxj82Hv6aufq9jsXOEh3I95qZ2IwbfmWbvmnGcyBjzRbz1xnAE/olv8YeP+oj1f3Xus59knMTfzoScz/WNF7jeM/aIUH42IGo5+7gfd2297PYLQN8O/Ag8CB7s+eCcl1BXB7l2nf8cp0XJnm7TuWAu95rP6kO1Zf7I7VuROQKQymnO4AbgMum4Rj1a2/D9gxjjw9j9VG4LPd398B4FUTkusNwF3dPlcBTx5Dpo8B9wM/YPBT3FbgrcBb53xfXdllvm2l/wa9lV6SGjXpc+CSpGOwwCWpURa4JDXKApekRlngktQoC1ySGmWBS1Kj/h+qWRz1pJJ5lwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 3\n",
    "plt.imshow(data[i,:,:].detach().numpy().reshape((28, 28)))\n",
    "plt.title('label : '+str(label[i].item()))\n",
    "plt.show()\n",
    "h = plt.hist(data[i,:,:].detach().numpy().flatten(), 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "model = WhatNet().to(device)\n",
    "loss_func = F.nll_loss\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script d'entra√Ænement de what_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_max = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En cours : std = 0\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 0.619433\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 0.381339\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 0.564936\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 0.406193\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 0.214297\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 0.234865\n",
      "\n",
      "Test set: Average loss: 0.0028, Accuracy: 9134/10000 (91%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 0.282950\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 0.200974\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 0.257482\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 0.214048\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 0.550301\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 0.295753\n",
      "\n",
      "Test set: Average loss: 0.0026, Accuracy: 9203/10000 (92%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 0.243362\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 0.280988\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 0.227574\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 0.344100\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 0.095080\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 0.354646\n",
      "\n",
      "Test set: Average loss: 0.0031, Accuracy: 9027/10000 (90%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 0.180177\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 0.110539\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 0.103937\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 0.241730\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 0.105927\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 0.249986\n",
      "\n",
      "Test set: Average loss: 0.0026, Accuracy: 9181/10000 (92%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 0.121979\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 0.217790\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 0.146776\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 0.127038\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 0.286165\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 0.373616\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 9321/10000 (93%)\n",
      "\n",
      "../data/MNIST_cnn_0.1_0.1_1.0_None_0.pt\n",
      "\n",
      "\n",
      "En cours : std = 1\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 0.184283\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 0.270024\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 0.313966\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 0.311474\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 0.326852\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 0.198095\n",
      "\n",
      "Test set: Average loss: 0.0033, Accuracy: 9014/10000 (90%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 0.224226\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 0.162226\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 0.182602\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 0.204376\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 0.208987\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 0.145091\n",
      "\n",
      "Test set: Average loss: 0.0026, Accuracy: 9236/10000 (92%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 0.091215\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 0.237749\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 0.364700\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 0.138577\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 0.449205\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 0.192287\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 9292/10000 (93%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 0.222020\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 0.124094\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 0.169274\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 0.263642\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 0.140107\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 0.282064\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 9284/10000 (93%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 0.271822\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 0.217536\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 0.124625\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 0.141359\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 0.231589\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 0.254171\n",
      "\n",
      "Test set: Average loss: 0.0024, Accuracy: 9284/10000 (93%)\n",
      "\n",
      "../data/MNIST_cnn_0.1_0.1_1.0_None_1.pt\n",
      "\n",
      "\n",
      "En cours : std = 2\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 0.667698\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 0.240531\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 0.481389\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 0.328678\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 0.333260\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 0.553667\n",
      "\n",
      "Test set: Average loss: 0.0036, Accuracy: 8915/10000 (89%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 0.198488\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 0.123093\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 0.290518\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 0.367650\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 0.401160\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 0.337879\n",
      "\n",
      "Test set: Average loss: 0.0041, Accuracy: 8702/10000 (87%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 0.404885\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 0.170011\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 0.338217\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 0.270995\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 0.332332\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 0.370837\n",
      "\n",
      "Test set: Average loss: 0.0035, Accuracy: 8963/10000 (90%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 0.286033\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 0.304601\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 0.192296\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 0.307934\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 0.281414\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 0.320460\n",
      "\n",
      "Test set: Average loss: 0.0033, Accuracy: 9008/10000 (90%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 0.148827\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 0.302112\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 0.167977\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 0.265828\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 0.361088\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 0.332106\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 8894/10000 (89%)\n",
      "\n",
      "../data/MNIST_cnn_0.1_0.1_1.0_None_2.pt\n",
      "\n",
      "\n",
      "En cours : std = 3\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 0.417038\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 0.469253\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 0.610380\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 0.458692\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 0.555359\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 0.658950\n",
      "\n",
      "Test set: Average loss: 0.0051, Accuracy: 8403/10000 (84%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 0.541656\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 0.276494\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 0.461186\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 0.428331\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 0.809395\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 0.405481\n",
      "\n",
      "Test set: Average loss: 0.0045, Accuracy: 8545/10000 (85%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 0.362906\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 0.361399\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 0.482739\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 0.310726\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 0.414706\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 0.471095\n",
      "\n",
      "Test set: Average loss: 0.0048, Accuracy: 8504/10000 (85%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 0.407630\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 0.472213\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 0.392649\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 0.463775\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 0.334724\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 0.370964\n",
      "\n",
      "Test set: Average loss: 0.0045, Accuracy: 8587/10000 (86%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 0.313053\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 0.503456\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 0.365980\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 0.317929\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 0.389968\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 0.364125\n",
      "\n",
      "Test set: Average loss: 0.0045, Accuracy: 8609/10000 (86%)\n",
      "\n",
      "../data/MNIST_cnn_0.1_0.1_1.0_None_3.pt\n",
      "\n",
      "\n",
      "En cours : std = 4\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 0.717045\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 0.656060\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 0.613048\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 0.431321\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 0.595757\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 0.638024\n",
      "\n",
      "Test set: Average loss: 0.0067, Accuracy: 7830/10000 (78%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 0.645207\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 0.541214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 0.537777\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 0.559570\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 0.682554\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 0.748502\n",
      "\n",
      "Test set: Average loss: 0.0057, Accuracy: 8179/10000 (82%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 0.676433\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 0.463492\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 0.661109\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 0.637852\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 0.434014\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 0.382277\n",
      "\n",
      "Test set: Average loss: 0.0062, Accuracy: 8028/10000 (80%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 0.508236\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 0.482197\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 0.450577\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 0.542299\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 0.639929\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 0.477086\n",
      "\n",
      "Test set: Average loss: 0.0066, Accuracy: 7939/10000 (79%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 0.452406\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 0.473288\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 0.607230\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 0.592771\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 0.402526\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 0.501271\n",
      "\n",
      "Test set: Average loss: 0.0056, Accuracy: 8243/10000 (82%)\n",
      "\n",
      "../data/MNIST_cnn_0.1_0.1_1.0_None_4.pt\n",
      "\n",
      "\n",
      "En cours : std = 5\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 0.921601\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 0.637555\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.022404\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 0.870354\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 0.734162\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 0.712022\n",
      "\n",
      "Test set: Average loss: 0.0074, Accuracy: 7544/10000 (75%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 0.713208\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 0.550404\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 0.660472\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 0.947262\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 0.753829\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 0.870009\n",
      "\n",
      "Test set: Average loss: 0.0070, Accuracy: 7680/10000 (77%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 0.741489\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 0.455156\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 0.672036\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 0.680496\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 0.624148\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 0.725003\n",
      "\n",
      "Test set: Average loss: 0.0071, Accuracy: 7716/10000 (77%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 0.512035\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 0.780239\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 0.643061\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 0.802341\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 0.616674\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 0.814300\n",
      "\n",
      "Test set: Average loss: 0.0070, Accuracy: 7697/10000 (77%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 0.515633\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 0.606738\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 0.532095\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 0.645853\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 0.717829\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 0.727180\n",
      "\n",
      "Test set: Average loss: 0.0081, Accuracy: 7419/10000 (74%)\n",
      "\n",
      "../data/MNIST_cnn_0.1_0.1_1.0_None_5.pt\n",
      "\n",
      "\n",
      "En cours : std = 6\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.075534\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 0.945472\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 0.787167\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 0.752746\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 0.845843\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.133669\n",
      "\n",
      "Test set: Average loss: 0.0086, Accuracy: 7086/10000 (71%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 0.881632\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 0.907486\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 0.850494\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 0.644245\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 0.847561\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 1.017324\n",
      "\n",
      "Test set: Average loss: 0.0085, Accuracy: 7104/10000 (71%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 0.797355\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 0.877048\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 0.959224\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 0.902511\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 1.011778\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 1.093526\n",
      "\n",
      "Test set: Average loss: 0.0088, Accuracy: 7055/10000 (71%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 0.769617\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 0.662782\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.053852\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 0.778634\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 0.745986\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 0.519799\n",
      "\n",
      "Test set: Average loss: 0.0102, Accuracy: 6592/10000 (66%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 1.200656\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 0.988671\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 0.722772\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 0.706062\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 0.799914\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 0.948512\n",
      "\n",
      "Test set: Average loss: 0.0087, Accuracy: 7100/10000 (71%)\n",
      "\n",
      "../data/MNIST_cnn_0.1_0.1_1.0_None_6.pt\n",
      "\n",
      "\n",
      "En cours : std = 7\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.077639\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 0.997567\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.040486\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 0.967681\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 0.923319\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 0.920934\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 6506/10000 (65%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 1.181636\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 0.923858\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 0.916621\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 0.935429\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 1.092260\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 0.972635\n",
      "\n",
      "Test set: Average loss: 0.0101, Accuracy: 6538/10000 (65%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 0.878702\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 0.955153\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 0.954274\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.090120\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 0.856235\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 1.086102\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 6560/10000 (66%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.055312\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 1.030838\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.122537\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 0.792060\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.031709\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 1.177137\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 6586/10000 (66%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 0.747485\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 0.753661\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 0.796222\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 1.088476\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 0.786750\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 0.981177\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 6576/10000 (66%)\n",
      "\n",
      "../data/MNIST_cnn_0.1_0.1_1.0_None_7.pt\n",
      "\n",
      "\n",
      "En cours : std = 8\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.262204\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 1.060315\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.166893\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 1.123975\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 1.052237\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.173322\n",
      "\n",
      "Test set: Average loss: 0.0114, Accuracy: 6060/10000 (61%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 0.889161\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 1.111645\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 1.111076\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 1.110489\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 1.339950\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 1.171485\n",
      "\n",
      "Test set: Average loss: 0.0111, Accuracy: 6148/10000 (61%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 1.088220\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 1.027491\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 1.210119\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.190398\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 1.298830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 0.776488\n",
      "\n",
      "Test set: Average loss: 0.0121, Accuracy: 5891/10000 (59%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.221649\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 1.085753\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.035958\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 1.024786\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.081265\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 1.031641\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 5961/10000 (60%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 1.008255\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 1.052898\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 1.024505\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 1.078439\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 1.227739\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 1.267537\n",
      "\n",
      "Test set: Average loss: 0.0121, Accuracy: 5871/10000 (59%)\n",
      "\n",
      "../data/MNIST_cnn_0.1_0.1_1.0_None_8.pt\n",
      "\n",
      "\n",
      "En cours : std = 9\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.415508\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 1.289716\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.241047\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 1.215713\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 1.426675\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.374903\n",
      "\n",
      "Test set: Average loss: 0.0130, Accuracy: 5434/10000 (54%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 1.270623\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 1.356284\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 1.331443\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 1.277868\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 1.398599\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 1.236549\n",
      "\n",
      "Test set: Average loss: 0.0126, Accuracy: 5562/10000 (56%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 1.268167\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 1.116014\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 1.381122\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.184374\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 1.119248\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 1.323160\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 5438/10000 (54%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.129136\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 1.088983\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.240979\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 1.118592\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.176336\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 1.333068\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 5502/10000 (55%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 1.023829\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 1.263495\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 1.063056\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 1.081219\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 1.132286\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 1.292541\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 5550/10000 (56%)\n",
      "\n",
      "../data/MNIST_cnn_0.1_0.1_1.0_None_9.pt\n",
      "\n",
      "\n",
      "En cours : std = 10\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.233950\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 1.527763\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.416634\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 1.532409\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 1.284052\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.579676\n",
      "\n",
      "Test set: Average loss: 0.0140, Accuracy: 4978/10000 (50%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 1.267141\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 1.455621\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 1.195631\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 1.428169\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 1.287256\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 1.395248\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 5088/10000 (51%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 1.389947\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 1.536945\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 1.332909\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.422975\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 1.332051\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 1.198049\n",
      "\n",
      "Test set: Average loss: 0.0141, Accuracy: 5101/10000 (51%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.280764\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 1.150730\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.413411\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 1.296719\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.201472\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 1.327020\n",
      "\n",
      "Test set: Average loss: 0.0137, Accuracy: 5205/10000 (52%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 1.204959\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 1.225490\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 1.034603\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 1.138641\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 1.502894\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 1.219054\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 5250/10000 (52%)\n",
      "\n",
      "../data/MNIST_cnn_0.1_0.1_1.0_None_10.pt\n",
      "\n",
      "\n",
      "En cours : std = 11\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.377701\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 1.467087\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.452584\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 1.486493\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 1.629428\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.330063\n",
      "\n",
      "Test set: Average loss: 0.0147, Accuracy: 4762/10000 (48%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 1.494918\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 1.413442\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 1.425229\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 1.466150\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 1.334441\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 1.368276\n",
      "\n",
      "Test set: Average loss: 0.0147, Accuracy: 4716/10000 (47%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 1.663647\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 1.269233\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 1.302204\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.429190\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 1.402798\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 1.555793\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 4699/10000 (47%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.275594\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 1.400762\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.347413\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 1.261350\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.198623\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 1.407404\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 4748/10000 (47%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 1.445182\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 1.572302\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 1.363594\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 1.462498\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 1.478049\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 1.430362\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 4661/10000 (47%)\n",
      "\n",
      "../data/MNIST_cnn_0.1_0.1_1.0_None_11.pt\n",
      "\n",
      "\n",
      "En cours : std = 12\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.398799\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 1.506663\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.572751\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 1.630286\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 1.442026\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.477742\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4189/10000 (42%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 1.550189\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 1.584222\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 1.603534\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 1.698499\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 1.774132\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 1.459002\n",
      "\n",
      "Test set: Average loss: 0.0156, Accuracy: 4385/10000 (44%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 1.422429\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 1.453740\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 1.657910\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.498290\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 1.397656\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 1.762382\n",
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 4313/10000 (43%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.377417\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 1.432526\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.483181\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 1.818833\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.558401\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 1.504967\n",
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 4348/10000 (43%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 1.488301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 1.386885\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 1.558897\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 1.316144\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 1.571039\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 1.443762\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 4076/10000 (41%)\n",
      "\n",
      "../data/MNIST_cnn_0.1_0.1_1.0_None_12.pt\n",
      "\n",
      "\n",
      "En cours : std = 13\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.570230\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 1.731643\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.784244\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 1.630866\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 1.641684\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.733833\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 3862/10000 (39%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 1.798005\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 1.499866\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 1.589043\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 1.779945\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 1.648127\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 1.627636\n",
      "\n",
      "Test set: Average loss: 0.0165, Accuracy: 4029/10000 (40%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 1.662085\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 1.496429\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 1.714036\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.595043\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 1.657910\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 1.716953\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 4064/10000 (41%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.600607\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 1.620783\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.624042\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 1.754078\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.328112\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 1.605963\n",
      "\n",
      "Test set: Average loss: 0.0165, Accuracy: 4046/10000 (40%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 1.605822\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 1.681831\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 1.537413\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 1.549309\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 1.766575\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 1.559793\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 4002/10000 (40%)\n",
      "\n",
      "../data/MNIST_cnn_0.1_0.1_1.0_None_13.pt\n",
      "\n",
      "\n",
      "En cours : std = 14\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 1.659511\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 1.864184\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.737254\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 1.676760\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 1.715523\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.749351\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 3689/10000 (37%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 1.655712\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 1.736496\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 1.674299\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 1.582909\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 1.655428\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 1.796912\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 3648/10000 (36%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 1.868762\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 1.684929\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 1.743545\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.723096\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 1.773466\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 1.507861\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 3733/10000 (37%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.401185\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 1.556825\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.643464\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 1.607061\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.564232\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 1.563475\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 3752/10000 (38%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 1.695003\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 1.526741\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 1.545017\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 1.474797\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 1.731401\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 1.862702\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 3735/10000 (37%)\n",
      "\n",
      "../data/MNIST_cnn_0.1_0.1_1.0_None_14.pt\n",
      "\n",
      "\n",
      "En cours : std = 15\n",
      "\n",
      "Training the What model\n",
      "Train Epoch: 1/5 [0/60000 (0%)]\tLoss: 2.030101\n",
      "Train Epoch: 1/5 [10000/60000 (17%)]\tLoss: 1.841701\n",
      "Train Epoch: 1/5 [20000/60000 (33%)]\tLoss: 1.793143\n",
      "Train Epoch: 1/5 [30000/60000 (50%)]\tLoss: 1.753308\n",
      "Train Epoch: 1/5 [40000/60000 (67%)]\tLoss: 1.673910\n",
      "Train Epoch: 1/5 [50000/60000 (83%)]\tLoss: 1.848945\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3348/10000 (33%)\n",
      "\n",
      "Train Epoch: 2/5 [0/60000 (0%)]\tLoss: 1.804011\n",
      "Train Epoch: 2/5 [10000/60000 (17%)]\tLoss: 1.719619\n",
      "Train Epoch: 2/5 [20000/60000 (33%)]\tLoss: 1.765524\n",
      "Train Epoch: 2/5 [30000/60000 (50%)]\tLoss: 1.664553\n",
      "Train Epoch: 2/5 [40000/60000 (67%)]\tLoss: 1.658891\n",
      "Train Epoch: 2/5 [50000/60000 (83%)]\tLoss: 1.669330\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 3291/10000 (33%)\n",
      "\n",
      "Train Epoch: 3/5 [0/60000 (0%)]\tLoss: 1.755439\n",
      "Train Epoch: 3/5 [10000/60000 (17%)]\tLoss: 1.619816\n",
      "Train Epoch: 3/5 [20000/60000 (33%)]\tLoss: 1.641502\n",
      "Train Epoch: 3/5 [30000/60000 (50%)]\tLoss: 1.446647\n",
      "Train Epoch: 3/5 [40000/60000 (67%)]\tLoss: 1.760187\n",
      "Train Epoch: 3/5 [50000/60000 (83%)]\tLoss: 1.736571\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 3410/10000 (34%)\n",
      "\n",
      "Train Epoch: 4/5 [0/60000 (0%)]\tLoss: 1.562411\n",
      "Train Epoch: 4/5 [10000/60000 (17%)]\tLoss: 1.547135\n",
      "Train Epoch: 4/5 [20000/60000 (33%)]\tLoss: 1.772041\n",
      "Train Epoch: 4/5 [30000/60000 (50%)]\tLoss: 1.597069\n",
      "Train Epoch: 4/5 [40000/60000 (67%)]\tLoss: 1.706707\n",
      "Train Epoch: 4/5 [50000/60000 (83%)]\tLoss: 1.859578\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3400/10000 (34%)\n",
      "\n",
      "Train Epoch: 5/5 [0/60000 (0%)]\tLoss: 1.662753\n",
      "Train Epoch: 5/5 [10000/60000 (17%)]\tLoss: 1.665372\n",
      "Train Epoch: 5/5 [20000/60000 (33%)]\tLoss: 1.717803\n",
      "Train Epoch: 5/5 [30000/60000 (50%)]\tLoss: 1.849183\n",
      "Train Epoch: 5/5 [40000/60000 (67%)]\tLoss: 1.582501\n",
      "Train Epoch: 5/5 [50000/60000 (83%)]\tLoss: 1.732849\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 3450/10000 (34%)\n",
      "\n",
      "../data/MNIST_cnn_0.1_0.1_1.0_None_15.pt\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Duree d'execution : 1:42:23.040010\n"
     ]
    }
   ],
   "source": [
    "suffix = \"robust_{}_{}_{}_{}_{}\".format(args.sf_0, args.B_sf, args.noise, args.contrast, std_max)\n",
    "what_model_path = \"../data/MNIST_cnn_{}.pt\".format(suffix)\n",
    "\n",
    "if not os.path.isfile(what_model_path):\n",
    "\n",
    "    debut = datetime.datetime.now()\n",
    "    date = str(debut)  \n",
    "    \n",
    "    args.epochs = 5  # 10 plus tard\n",
    "    args.save_model = True    \n",
    "    args.what_offset_max = 25\n",
    "    args.do_adam = True #'adam'\n",
    "    \n",
    "    seed = 0\n",
    "    for std in range(std_max+1):\n",
    "        print(\"En cours : std = \" + str(std) + \"\\n\")\n",
    "        args.what_offset_std = std\n",
    "        what_model = what.model\n",
    "        what = What(args, model=what_model, force=True, seed=seed)\n",
    "        seed += 1\n",
    "        print(\"\\n\")\n",
    "\n",
    "    torch.save(what_model, what_model_path)\n",
    "\n",
    "    fin = datetime.datetime.now()\n",
    "    print(\"\\n\\nDuree d'execution : \" + str(fin - debut))\n",
    "else:\n",
    "    what_model = torch.load(what_model_path)\n",
    "    what = What(args, model=what_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 3450/10000 (34%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = what.trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0063, Accuracy: 8389/10000 (84%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args.what_offset_std = 0\n",
    "what = What(args, model=what_model)\n",
    "acc = what.trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy map calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -20 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0281, Accuracy: 1020/10000 (10%)\n",
      "\n",
      "-27 -19 0.102\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -18 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 -17 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -16 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -15 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 -14 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1011/10000 (10%)\n",
      "\n",
      "-27 -13 0.1011\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 -12 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 -11 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -10 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 -9 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-27 -8 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -7 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 -6 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -5 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 -4 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 -3 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 -2 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 -1 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 0 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 1 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 2 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-27 3 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 4 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 5 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 6 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "-27 7 0.101\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 8 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 9 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-27 10 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-27 11 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 12 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-27 13 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 14 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 15 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 16 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 17 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 18 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 19 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 20 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-27 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 -23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 -22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 -21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 -20 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-26 -19 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 -18 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-26 -17 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0238, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-26 -16 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-26 -15 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-26 -14 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0238, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "-26 -13 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-26 -12 0.114\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-26 -11 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "-26 -10 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "-26 -9 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1008/10000 (10%)\n",
      "\n",
      "-26 -8 0.1008\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "-26 -7 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-26 -6 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "-26 -5 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "-26 -4 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-26 -3 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1146/10000 (11%)\n",
      "\n",
      "-26 -2 0.1146\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-26 -1 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "-26 0 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1146/10000 (11%)\n",
      "\n",
      "-26 1 0.1146\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-26 2 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "-26 3 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "-26 4 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "-26 5 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "-26 6 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "-26 7 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-26 8 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-26 9 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-26 10 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-26 11 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-26 12 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-26 13 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-26 14 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-26 15 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-26 16 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-26 17 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 18 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 19 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 20 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0239, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-26 27 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 958/10000 (10%)\n",
      "\n",
      "-25 -27 0.0958\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 -23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 -22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 -21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 -20 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 -19 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-25 -18 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-25 -17 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-25 -16 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "-25 -15 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 504/10000 (5%)\n",
      "\n",
      "-25 -14 0.0504\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "-25 -13 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1148/10000 (11%)\n",
      "\n",
      "-25 -12 0.1148\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1164/10000 (12%)\n",
      "\n",
      "-25 -11 0.1164\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1161/10000 (12%)\n",
      "\n",
      "-25 -10 0.1161\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "-25 -9 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1154/10000 (12%)\n",
      "\n",
      "-25 -8 0.1154\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "-25 -7 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "-25 -6 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1159/10000 (12%)\n",
      "\n",
      "-25 -5 0.1159\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1163/10000 (12%)\n",
      "\n",
      "-25 -4 0.1163\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1160/10000 (12%)\n",
      "\n",
      "-25 -3 0.116\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1159/10000 (12%)\n",
      "\n",
      "-25 -2 0.1159\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1159/10000 (12%)\n",
      "\n",
      "-25 -1 0.1159\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1164/10000 (12%)\n",
      "\n",
      "-25 0 0.1164\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1154/10000 (12%)\n",
      "\n",
      "-25 1 0.1154\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1161/10000 (12%)\n",
      "\n",
      "-25 2 0.1161\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1165/10000 (12%)\n",
      "\n",
      "-25 3 0.1165\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "-25 4 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1162/10000 (12%)\n",
      "\n",
      "-25 5 0.1162\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "-25 6 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1151/10000 (12%)\n",
      "\n",
      "-25 7 0.1151\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1151/10000 (12%)\n",
      "\n",
      "-25 8 0.1151\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1146/10000 (11%)\n",
      "\n",
      "-25 9 0.1146\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "-25 10 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "-25 11 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "-25 12 0.115\n",
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 173/10000 (2%)\n",
      "\n",
      "-25 13 0.0173\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-25 14 0.114\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "-25 15 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-25 16 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-25 17 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-25 18 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-25 19 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-25 20 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-25 21 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-25 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-24 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-24 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-24 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-24 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-24 -23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-24 -22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-24 -21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-24 -20 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-24 -19 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-24 -18 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 896/10000 (9%)\n",
      "\n",
      "-24 -17 0.0896\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "-24 -16 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-24 -15 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 878/10000 (9%)\n",
      "\n",
      "-24 -14 0.0878\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1161/10000 (12%)\n",
      "\n",
      "-24 -13 0.1161\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1160/10000 (12%)\n",
      "\n",
      "-24 -12 0.116\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "-24 -11 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "-24 -10 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1169/10000 (12%)\n",
      "\n",
      "-24 -9 0.1169\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1162/10000 (12%)\n",
      "\n",
      "-24 -8 0.1162\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1173/10000 (12%)\n",
      "\n",
      "-24 -7 0.1173\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1191/10000 (12%)\n",
      "\n",
      "-24 -6 0.1191\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1168/10000 (12%)\n",
      "\n",
      "-24 -5 0.1168\n",
      "\n",
      "Test set: Average loss: 0.0239, Accuracy: 1177/10000 (12%)\n",
      "\n",
      "-24 -4 0.1177\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 998/10000 (10%)\n",
      "\n",
      "-24 -3 0.0998\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1204/10000 (12%)\n",
      "\n",
      "-24 -2 0.1204\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1182/10000 (12%)\n",
      "\n",
      "-24 -1 0.1182\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1185/10000 (12%)\n",
      "\n",
      "-24 0 0.1185\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1191/10000 (12%)\n",
      "\n",
      "-24 1 0.1191\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1185/10000 (12%)\n",
      "\n",
      "-24 2 0.1185\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1212/10000 (12%)\n",
      "\n",
      "-24 3 0.1212\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1198/10000 (12%)\n",
      "\n",
      "-24 4 0.1198\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1176/10000 (12%)\n",
      "\n",
      "-24 5 0.1176\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1190/10000 (12%)\n",
      "\n",
      "-24 6 0.119\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1405/10000 (14%)\n",
      "\n",
      "-24 7 0.1405\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1185/10000 (12%)\n",
      "\n",
      "-24 8 0.1185\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1181/10000 (12%)\n",
      "\n",
      "-24 9 0.1181\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1171/10000 (12%)\n",
      "\n",
      "-24 10 0.1171\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1153/10000 (12%)\n",
      "\n",
      "-24 11 0.1153\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1171/10000 (12%)\n",
      "\n",
      "-24 12 0.1171\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "-24 13 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1154/10000 (12%)\n",
      "\n",
      "-24 14 0.1154\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "-24 15 0.115\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "-24 16 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1148/10000 (11%)\n",
      "\n",
      "-24 17 0.1148\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "-24 18 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-24 19 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-24 20 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-24 21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-24 22 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-24 23 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-24 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-24 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-24 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-24 27 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-23 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0239, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-23 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-23 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-23 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1134/10000 (11%)\n",
      "\n",
      "-23 -23 0.1134\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-23 -22 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-23 -21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-23 -20 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "-23 -19 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1146/10000 (11%)\n",
      "\n",
      "-23 -18 0.1146\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "-23 -17 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "-23 -16 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1159/10000 (12%)\n",
      "\n",
      "-23 -15 0.1159\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "-23 -14 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1184/10000 (12%)\n",
      "\n",
      "-23 -13 0.1184\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1203/10000 (12%)\n",
      "\n",
      "-23 -12 0.1203\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1207/10000 (12%)\n",
      "\n",
      "-23 -11 0.1207\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1222/10000 (12%)\n",
      "\n",
      "-23 -10 0.1222\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1247/10000 (12%)\n",
      "\n",
      "-23 -9 0.1247\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1263/10000 (13%)\n",
      "\n",
      "-23 -8 0.1263\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1252/10000 (13%)\n",
      "\n",
      "-23 -7 0.1252\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1242/10000 (12%)\n",
      "\n",
      "-23 -6 0.1242\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1249/10000 (12%)\n",
      "\n",
      "-23 -5 0.1249\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1276/10000 (13%)\n",
      "\n",
      "-23 -4 0.1276\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1269/10000 (13%)\n",
      "\n",
      "-23 -3 0.1269\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1284/10000 (13%)\n",
      "\n",
      "-23 -2 0.1284\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1254/10000 (13%)\n",
      "\n",
      "-23 -1 0.1254\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1273/10000 (13%)\n",
      "\n",
      "-23 0 0.1273\n",
      "\n",
      "Test set: Average loss: 0.0238, Accuracy: 1277/10000 (13%)\n",
      "\n",
      "-23 1 0.1277\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1290/10000 (13%)\n",
      "\n",
      "-23 2 0.129\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1295/10000 (13%)\n",
      "\n",
      "-23 3 0.1295\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1265/10000 (13%)\n",
      "\n",
      "-23 4 0.1265\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1295/10000 (13%)\n",
      "\n",
      "-23 5 0.1295\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1274/10000 (13%)\n",
      "\n",
      "-23 6 0.1274\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1274/10000 (13%)\n",
      "\n",
      "-23 7 0.1274\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1277/10000 (13%)\n",
      "\n",
      "-23 8 0.1277\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1263/10000 (13%)\n",
      "\n",
      "-23 9 0.1263\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1215/10000 (12%)\n",
      "\n",
      "-23 10 0.1215\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1211/10000 (12%)\n",
      "\n",
      "-23 11 0.1211\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1208/10000 (12%)\n",
      "\n",
      "-23 12 0.1208\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1186/10000 (12%)\n",
      "\n",
      "-23 13 0.1186\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1182/10000 (12%)\n",
      "\n",
      "-23 14 0.1182\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1159/10000 (12%)\n",
      "\n",
      "-23 15 0.1159\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1160/10000 (12%)\n",
      "\n",
      "-23 16 0.116\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1160/10000 (12%)\n",
      "\n",
      "-23 17 0.116\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1148/10000 (11%)\n",
      "\n",
      "-23 18 0.1148\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "-23 19 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 919/10000 (9%)\n",
      "\n",
      "-23 20 0.0919\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "-23 21 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-23 22 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 943/10000 (9%)\n",
      "\n",
      "-23 23 0.0943\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-23 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-23 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-23 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-23 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-22 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-22 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-22 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-22 -24 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-22 -23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-22 -22 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-22 -21 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 843/10000 (8%)\n",
      "\n",
      "-22 -20 0.0843\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "-22 -19 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1156/10000 (12%)\n",
      "\n",
      "-22 -18 0.1156\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1174/10000 (12%)\n",
      "\n",
      "-22 -17 0.1174\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1179/10000 (12%)\n",
      "\n",
      "-22 -16 0.1179\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1198/10000 (12%)\n",
      "\n",
      "-22 -15 0.1198\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1218/10000 (12%)\n",
      "\n",
      "-22 -14 0.1218\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1268/10000 (13%)\n",
      "\n",
      "-22 -13 0.1268\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1288/10000 (13%)\n",
      "\n",
      "-22 -12 0.1288\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1342/10000 (13%)\n",
      "\n",
      "-22 -11 0.1342\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1381/10000 (14%)\n",
      "\n",
      "-22 -10 0.1381\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1392/10000 (14%)\n",
      "\n",
      "-22 -9 0.1392\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1432/10000 (14%)\n",
      "\n",
      "-22 -8 0.1432\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1468/10000 (15%)\n",
      "\n",
      "-22 -7 0.1468\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1449/10000 (14%)\n",
      "\n",
      "-22 -6 0.1449\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1457/10000 (15%)\n",
      "\n",
      "-22 -5 0.1457\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1405/10000 (14%)\n",
      "\n",
      "-22 -4 0.1405\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1485/10000 (15%)\n",
      "\n",
      "-22 -3 0.1485\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1439/10000 (14%)\n",
      "\n",
      "-22 -2 0.1439\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1473/10000 (15%)\n",
      "\n",
      "-22 -1 0.1473\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1470/10000 (15%)\n",
      "\n",
      "-22 0 0.147\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1469/10000 (15%)\n",
      "\n",
      "-22 1 0.1469\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1429/10000 (14%)\n",
      "\n",
      "-22 2 0.1429\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1449/10000 (14%)\n",
      "\n",
      "-22 3 0.1449\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1436/10000 (14%)\n",
      "\n",
      "-22 4 0.1436\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1472/10000 (15%)\n",
      "\n",
      "-22 5 0.1472\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1408/10000 (14%)\n",
      "\n",
      "-22 6 0.1408\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1387/10000 (14%)\n",
      "\n",
      "-22 7 0.1387\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1401/10000 (14%)\n",
      "\n",
      "-22 8 0.1401\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1381/10000 (14%)\n",
      "\n",
      "-22 9 0.1381\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1346/10000 (13%)\n",
      "\n",
      "-22 10 0.1346\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1341/10000 (13%)\n",
      "\n",
      "-22 11 0.1341\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1307/10000 (13%)\n",
      "\n",
      "-22 12 0.1307\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1273/10000 (13%)\n",
      "\n",
      "-22 13 0.1273\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1247/10000 (12%)\n",
      "\n",
      "-22 14 0.1247\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1211/10000 (12%)\n",
      "\n",
      "-22 15 0.1211\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1182/10000 (12%)\n",
      "\n",
      "-22 16 0.1182\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1180/10000 (12%)\n",
      "\n",
      "-22 17 0.118\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1175/10000 (12%)\n",
      "\n",
      "-22 18 0.1175\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1157/10000 (12%)\n",
      "\n",
      "-22 19 0.1157\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "-22 20 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "-22 21 0.115\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-22 22 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 883/10000 (9%)\n",
      "\n",
      "-22 23 0.0883\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-22 24 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-22 25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-22 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "-22 27 0.101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-21 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-21 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-21 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-21 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-21 -23 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-21 -22 0.114\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 864/10000 (9%)\n",
      "\n",
      "-21 -21 0.0864\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 893/10000 (9%)\n",
      "\n",
      "-21 -20 0.0893\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1157/10000 (12%)\n",
      "\n",
      "-21 -19 0.1157\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1180/10000 (12%)\n",
      "\n",
      "-21 -18 0.118\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1199/10000 (12%)\n",
      "\n",
      "-21 -17 0.1199\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 470/10000 (5%)\n",
      "\n",
      "-21 -16 0.047\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1243/10000 (12%)\n",
      "\n",
      "-21 -15 0.1243\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1354/10000 (14%)\n",
      "\n",
      "-21 -14 0.1354\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1369/10000 (14%)\n",
      "\n",
      "-21 -13 0.1369\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1520/10000 (15%)\n",
      "\n",
      "-21 -12 0.152\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1571/10000 (16%)\n",
      "\n",
      "-21 -11 0.1571\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1619/10000 (16%)\n",
      "\n",
      "-21 -10 0.1619\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1656/10000 (17%)\n",
      "\n",
      "-21 -9 0.1656\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1671/10000 (17%)\n",
      "\n",
      "-21 -8 0.1671\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1668/10000 (17%)\n",
      "\n",
      "-21 -7 0.1668\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1705/10000 (17%)\n",
      "\n",
      "-21 -6 0.1705\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1673/10000 (17%)\n",
      "\n",
      "-21 -5 0.1673\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1772/10000 (18%)\n",
      "\n",
      "-21 -4 0.1772\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 1714/10000 (17%)\n",
      "\n",
      "-21 -3 0.1714\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 1709/10000 (17%)\n",
      "\n",
      "-21 -2 0.1709\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 1729/10000 (17%)\n",
      "\n",
      "-21 -1 0.1729\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1688/10000 (17%)\n",
      "\n",
      "-21 0 0.1688\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1677/10000 (17%)\n",
      "\n",
      "-21 1 0.1677\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1680/10000 (17%)\n",
      "\n",
      "-21 2 0.168\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1642/10000 (16%)\n",
      "\n",
      "-21 3 0.1642\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1669/10000 (17%)\n",
      "\n",
      "-21 4 0.1669\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1610/10000 (16%)\n",
      "\n",
      "-21 5 0.161\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1577/10000 (16%)\n",
      "\n",
      "-21 6 0.1577\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1566/10000 (16%)\n",
      "\n",
      "-21 7 0.1566\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1518/10000 (15%)\n",
      "\n",
      "-21 8 0.1518\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1474/10000 (15%)\n",
      "\n",
      "-21 9 0.1474\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1467/10000 (15%)\n",
      "\n",
      "-21 10 0.1467\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1391/10000 (14%)\n",
      "\n",
      "-21 11 0.1391\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1391/10000 (14%)\n",
      "\n",
      "-21 12 0.1391\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1345/10000 (13%)\n",
      "\n",
      "-21 13 0.1345\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1288/10000 (13%)\n",
      "\n",
      "-21 14 0.1288\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1257/10000 (13%)\n",
      "\n",
      "-21 15 0.1257\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1251/10000 (13%)\n",
      "\n",
      "-21 16 0.1251\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1211/10000 (12%)\n",
      "\n",
      "-21 17 0.1211\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1195/10000 (12%)\n",
      "\n",
      "-21 18 0.1195\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1175/10000 (12%)\n",
      "\n",
      "-21 19 0.1175\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1168/10000 (12%)\n",
      "\n",
      "-21 20 0.1168\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "-21 21 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "-21 22 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-21 23 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-21 24 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-21 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-21 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "-21 27 0.101\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-20 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-20 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-20 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-20 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 988/10000 (10%)\n",
      "\n",
      "-20 -23 0.0988\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-20 -22 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "-20 -21 0.115\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "-20 -20 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1172/10000 (12%)\n",
      "\n",
      "-20 -19 0.1172\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1198/10000 (12%)\n",
      "\n",
      "-20 -18 0.1198\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1235/10000 (12%)\n",
      "\n",
      "-20 -17 0.1235\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1298/10000 (13%)\n",
      "\n",
      "-20 -16 0.1298\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1374/10000 (14%)\n",
      "\n",
      "-20 -15 0.1374\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1479/10000 (15%)\n",
      "\n",
      "-20 -14 0.1479\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1563/10000 (16%)\n",
      "\n",
      "-20 -13 0.1563\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1650/10000 (16%)\n",
      "\n",
      "-20 -12 0.165\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1759/10000 (18%)\n",
      "\n",
      "-20 -11 0.1759\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1818/10000 (18%)\n",
      "\n",
      "-20 -10 0.1818\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 1910/10000 (19%)\n",
      "\n",
      "-20 -9 0.191\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 1833/10000 (18%)\n",
      "\n",
      "-20 -8 0.1833\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 1884/10000 (19%)\n",
      "\n",
      "-20 -7 0.1884\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 1916/10000 (19%)\n",
      "\n",
      "-20 -6 0.1916\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 1931/10000 (19%)\n",
      "\n",
      "-20 -5 0.1931\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 1879/10000 (19%)\n",
      "\n",
      "-20 -4 0.1879\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 1952/10000 (20%)\n",
      "\n",
      "-20 -3 0.1952\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 1995/10000 (20%)\n",
      "\n",
      "-20 -2 0.1995\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 1938/10000 (19%)\n",
      "\n",
      "-20 -1 0.1938\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 1920/10000 (19%)\n",
      "\n",
      "-20 0 0.192\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 1883/10000 (19%)\n",
      "\n",
      "-20 1 0.1883\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 1854/10000 (19%)\n",
      "\n",
      "-20 2 0.1854\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 1794/10000 (18%)\n",
      "\n",
      "-20 3 0.1794\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 1767/10000 (18%)\n",
      "\n",
      "-20 4 0.1767\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 1763/10000 (18%)\n",
      "\n",
      "-20 5 0.1763\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 1800/10000 (18%)\n",
      "\n",
      "-20 6 0.18\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 1792/10000 (18%)\n",
      "\n",
      "-20 7 0.1792\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 1753/10000 (18%)\n",
      "\n",
      "-20 8 0.1753\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 1741/10000 (17%)\n",
      "\n",
      "-20 9 0.1741\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1618/10000 (16%)\n",
      "\n",
      "-20 10 0.1618\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1540/10000 (15%)\n",
      "\n",
      "-20 11 0.154\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1483/10000 (15%)\n",
      "\n",
      "-20 12 0.1483\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1405/10000 (14%)\n",
      "\n",
      "-20 13 0.1405\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1324/10000 (13%)\n",
      "\n",
      "-20 14 0.1324\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1307/10000 (13%)\n",
      "\n",
      "-20 15 0.1307\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1323/10000 (13%)\n",
      "\n",
      "-20 16 0.1323\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1263/10000 (13%)\n",
      "\n",
      "-20 17 0.1263\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1231/10000 (12%)\n",
      "\n",
      "-20 18 0.1231\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1192/10000 (12%)\n",
      "\n",
      "-20 19 0.1192\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1181/10000 (12%)\n",
      "\n",
      "-20 20 0.1181\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1159/10000 (12%)\n",
      "\n",
      "-20 21 0.1159\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1153/10000 (12%)\n",
      "\n",
      "-20 22 0.1153\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-20 23 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-20 24 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-20 25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-20 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-20 27 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-19 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-19 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-19 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-19 -24 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-19 -23 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "-19 -22 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1157/10000 (12%)\n",
      "\n",
      "-19 -21 0.1157\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1169/10000 (12%)\n",
      "\n",
      "-19 -20 0.1169\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1201/10000 (12%)\n",
      "\n",
      "-19 -19 0.1201\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1218/10000 (12%)\n",
      "\n",
      "-19 -18 0.1218\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 873/10000 (9%)\n",
      "\n",
      "-19 -17 0.0873\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1347/10000 (13%)\n",
      "\n",
      "-19 -16 0.1347\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1442/10000 (14%)\n",
      "\n",
      "-19 -15 0.1442\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1540/10000 (15%)\n",
      "\n",
      "-19 -14 0.154\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1650/10000 (16%)\n",
      "\n",
      "-19 -13 0.165\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1782/10000 (18%)\n",
      "\n",
      "-19 -12 0.1782\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 1865/10000 (19%)\n",
      "\n",
      "-19 -11 0.1865\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 1954/10000 (20%)\n",
      "\n",
      "-19 -10 0.1954\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2003/10000 (20%)\n",
      "\n",
      "-19 -9 0.2003\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 1983/10000 (20%)\n",
      "\n",
      "-19 -8 0.1983\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2053/10000 (21%)\n",
      "\n",
      "-19 -7 0.2053\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2064/10000 (21%)\n",
      "\n",
      "-19 -6 0.2064\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2113/10000 (21%)\n",
      "\n",
      "-19 -5 0.2113\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2087/10000 (21%)\n",
      "\n",
      "-19 -4 0.2087\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2081/10000 (21%)\n",
      "\n",
      "-19 -3 0.2081\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2141/10000 (21%)\n",
      "\n",
      "-19 -2 0.2141\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 2226/10000 (22%)\n",
      "\n",
      "-19 -1 0.2226\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2201/10000 (22%)\n",
      "\n",
      "-19 0 0.2201\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2081/10000 (21%)\n",
      "\n",
      "-19 1 0.2081\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2055/10000 (21%)\n",
      "\n",
      "-19 2 0.2055\n",
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 1982/10000 (20%)\n",
      "\n",
      "-19 3 0.1982\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2019/10000 (20%)\n",
      "\n",
      "-19 4 0.2019\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2003/10000 (20%)\n",
      "\n",
      "-19 5 0.2003\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 1974/10000 (20%)\n",
      "\n",
      "-19 6 0.1974\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 1962/10000 (20%)\n",
      "\n",
      "-19 7 0.1962\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 1983/10000 (20%)\n",
      "\n",
      "-19 8 0.1983\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 1869/10000 (19%)\n",
      "\n",
      "-19 9 0.1869\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 1793/10000 (18%)\n",
      "\n",
      "-19 10 0.1793\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1665/10000 (17%)\n",
      "\n",
      "-19 11 0.1665\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1558/10000 (16%)\n",
      "\n",
      "-19 12 0.1558\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1513/10000 (15%)\n",
      "\n",
      "-19 13 0.1513\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1400/10000 (14%)\n",
      "\n",
      "-19 14 0.14\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1400/10000 (14%)\n",
      "\n",
      "-19 15 0.14\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1322/10000 (13%)\n",
      "\n",
      "-19 16 0.1322\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1312/10000 (13%)\n",
      "\n",
      "-19 17 0.1312\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1246/10000 (12%)\n",
      "\n",
      "-19 18 0.1246\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1200/10000 (12%)\n",
      "\n",
      "-19 19 0.12\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1191/10000 (12%)\n",
      "\n",
      "-19 20 0.1191\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1166/10000 (12%)\n",
      "\n",
      "-19 21 0.1166\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1157/10000 (12%)\n",
      "\n",
      "-19 22 0.1157\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1146/10000 (11%)\n",
      "\n",
      "-19 23 0.1146\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-19 24 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-19 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-19 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-19 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-18 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-18 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-18 -25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-18 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-18 -23 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "-18 -22 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1163/10000 (12%)\n",
      "\n",
      "-18 -21 0.1163\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1173/10000 (12%)\n",
      "\n",
      "-18 -20 0.1173\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1211/10000 (12%)\n",
      "\n",
      "-18 -19 0.1211\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1258/10000 (13%)\n",
      "\n",
      "-18 -18 0.1258\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1337/10000 (13%)\n",
      "\n",
      "-18 -17 0.1337\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1393/10000 (14%)\n",
      "\n",
      "-18 -16 0.1393\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1528/10000 (15%)\n",
      "\n",
      "-18 -15 0.1528\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1619/10000 (16%)\n",
      "\n",
      "-18 -14 0.1619\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1759/10000 (18%)\n",
      "\n",
      "-18 -13 0.1759\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 1918/10000 (19%)\n",
      "\n",
      "-18 -12 0.1918\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2006/10000 (20%)\n",
      "\n",
      "-18 -11 0.2006\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2049/10000 (20%)\n",
      "\n",
      "-18 -10 0.2049\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2185/10000 (22%)\n",
      "\n",
      "-18 -9 0.2185\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2160/10000 (22%)\n",
      "\n",
      "-18 -8 0.216\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2190/10000 (22%)\n",
      "\n",
      "-18 -7 0.219\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 2248/10000 (22%)\n",
      "\n",
      "-18 -6 0.2248\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2300/10000 (23%)\n",
      "\n",
      "-18 -5 0.23\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2310/10000 (23%)\n",
      "\n",
      "-18 -4 0.231\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 2367/10000 (24%)\n",
      "\n",
      "-18 -3 0.2367\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 2300/10000 (23%)\n",
      "\n",
      "-18 -2 0.23\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2320/10000 (23%)\n",
      "\n",
      "-18 -1 0.232\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 2396/10000 (24%)\n",
      "\n",
      "-18 0 0.2396\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2395/10000 (24%)\n",
      "\n",
      "-18 1 0.2395\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 2278/10000 (23%)\n",
      "\n",
      "-18 2 0.2278\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2167/10000 (22%)\n",
      "\n",
      "-18 3 0.2167\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2114/10000 (21%)\n",
      "\n",
      "-18 4 0.2114\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2091/10000 (21%)\n",
      "\n",
      "-18 5 0.2091\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2133/10000 (21%)\n",
      "\n",
      "-18 6 0.2133\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2067/10000 (21%)\n",
      "\n",
      "-18 7 0.2067\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2062/10000 (21%)\n",
      "\n",
      "-18 8 0.2062\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 1959/10000 (20%)\n",
      "\n",
      "-18 9 0.1959\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 1928/10000 (19%)\n",
      "\n",
      "-18 10 0.1928\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 1788/10000 (18%)\n",
      "\n",
      "-18 11 0.1788\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1681/10000 (17%)\n",
      "\n",
      "-18 12 0.1681\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1622/10000 (16%)\n",
      "\n",
      "-18 13 0.1622\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1526/10000 (15%)\n",
      "\n",
      "-18 14 0.1526\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1449/10000 (14%)\n",
      "\n",
      "-18 15 0.1449\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1390/10000 (14%)\n",
      "\n",
      "-18 16 0.139\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1338/10000 (13%)\n",
      "\n",
      "-18 17 0.1338\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1266/10000 (13%)\n",
      "\n",
      "-18 18 0.1266\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1241/10000 (12%)\n",
      "\n",
      "-18 19 0.1241\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1207/10000 (12%)\n",
      "\n",
      "-18 20 0.1207\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 635/10000 (6%)\n",
      "\n",
      "-18 21 0.0635\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1159/10000 (12%)\n",
      "\n",
      "-18 22 0.1159\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1156/10000 (12%)\n",
      "\n",
      "-18 23 0.1156\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "-18 24 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-18 25 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-18 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-18 27 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-17 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-17 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1134/10000 (11%)\n",
      "\n",
      "-17 -25 0.1134\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-17 -24 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-17 -23 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "-17 -22 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1175/10000 (12%)\n",
      "\n",
      "-17 -21 0.1175\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1209/10000 (12%)\n",
      "\n",
      "-17 -20 0.1209\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1227/10000 (12%)\n",
      "\n",
      "-17 -19 0.1227\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1250/10000 (12%)\n",
      "\n",
      "-17 -18 0.125\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1356/10000 (14%)\n",
      "\n",
      "-17 -17 0.1356\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1404/10000 (14%)\n",
      "\n",
      "-17 -16 0.1404\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1551/10000 (16%)\n",
      "\n",
      "-17 -15 0.1551\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1700/10000 (17%)\n",
      "\n",
      "-17 -14 0.17\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1863/10000 (19%)\n",
      "\n",
      "-17 -13 0.1863\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 1987/10000 (20%)\n",
      "\n",
      "-17 -12 0.1987\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2169/10000 (22%)\n",
      "\n",
      "-17 -11 0.2169\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2288/10000 (23%)\n",
      "\n",
      "-17 -10 0.2288\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2277/10000 (23%)\n",
      "\n",
      "-17 -9 0.2277\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 2272/10000 (23%)\n",
      "\n",
      "-17 -8 0.2272\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 2390/10000 (24%)\n",
      "\n",
      "-17 -7 0.239\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2372/10000 (24%)\n",
      "\n",
      "-17 -6 0.2372\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 2527/10000 (25%)\n",
      "\n",
      "-17 -5 0.2527\n",
      "\n",
      "Test set: Average loss: 0.0189, Accuracy: 2500/10000 (25%)\n",
      "\n",
      "-17 -4 0.25\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 2583/10000 (26%)\n",
      "\n",
      "-17 -3 0.2583\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 2676/10000 (27%)\n",
      "\n",
      "-17 -2 0.2676\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 2699/10000 (27%)\n",
      "\n",
      "-17 -1 0.2699\n",
      "\n",
      "Test set: Average loss: 0.0187, Accuracy: 2731/10000 (27%)\n",
      "\n",
      "-17 0 0.2731\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 2617/10000 (26%)\n",
      "\n",
      "-17 1 0.2617\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2534/10000 (25%)\n",
      "\n",
      "-17 2 0.2534\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 2393/10000 (24%)\n",
      "\n",
      "-17 3 0.2393\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 2333/10000 (23%)\n",
      "\n",
      "-17 4 0.2333\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 2234/10000 (22%)\n",
      "\n",
      "-17 5 0.2234\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 2321/10000 (23%)\n",
      "\n",
      "-17 6 0.2321\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2233/10000 (22%)\n",
      "\n",
      "-17 7 0.2233\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2292/10000 (23%)\n",
      "\n",
      "-17 8 0.2292\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2084/10000 (21%)\n",
      "\n",
      "-17 9 0.2084\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2080/10000 (21%)\n",
      "\n",
      "-17 10 0.208\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 1936/10000 (19%)\n",
      "\n",
      "-17 11 0.1936\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1811/10000 (18%)\n",
      "\n",
      "-17 12 0.1811\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1690/10000 (17%)\n",
      "\n",
      "-17 13 0.169\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1631/10000 (16%)\n",
      "\n",
      "-17 14 0.1631\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1482/10000 (15%)\n",
      "\n",
      "-17 15 0.1482\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1427/10000 (14%)\n",
      "\n",
      "-17 16 0.1427\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1341/10000 (13%)\n",
      "\n",
      "-17 17 0.1341\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1289/10000 (13%)\n",
      "\n",
      "-17 18 0.1289\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1251/10000 (13%)\n",
      "\n",
      "-17 19 0.1251\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1212/10000 (12%)\n",
      "\n",
      "-17 20 0.1212\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1176/10000 (12%)\n",
      "\n",
      "-17 21 0.1176\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1161/10000 (12%)\n",
      "\n",
      "-17 22 0.1161\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1151/10000 (12%)\n",
      "\n",
      "-17 23 0.1151\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-17 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-17 25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-17 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-17 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-16 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-16 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-16 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-16 -24 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "-16 -23 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1160/10000 (12%)\n",
      "\n",
      "-16 -22 0.116\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1166/10000 (12%)\n",
      "\n",
      "-16 -21 0.1166\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1203/10000 (12%)\n",
      "\n",
      "-16 -20 0.1203\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1236/10000 (12%)\n",
      "\n",
      "-16 -19 0.1236\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1268/10000 (13%)\n",
      "\n",
      "-16 -18 0.1268\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1372/10000 (14%)\n",
      "\n",
      "-16 -17 0.1372\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1424/10000 (14%)\n",
      "\n",
      "-16 -16 0.1424\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1551/10000 (16%)\n",
      "\n",
      "-16 -15 0.1551\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1706/10000 (17%)\n",
      "\n",
      "-16 -14 0.1706\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1923/10000 (19%)\n",
      "\n",
      "-16 -13 0.1923\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2068/10000 (21%)\n",
      "\n",
      "-16 -12 0.2068\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2297/10000 (23%)\n",
      "\n",
      "-16 -11 0.2297\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2404/10000 (24%)\n",
      "\n",
      "-16 -10 0.2404\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2365/10000 (24%)\n",
      "\n",
      "-16 -9 0.2365\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 2371/10000 (24%)\n",
      "\n",
      "-16 -8 0.2371\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 2457/10000 (25%)\n",
      "\n",
      "-16 -7 0.2457\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 2608/10000 (26%)\n",
      "\n",
      "-16 -6 0.2608\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 2687/10000 (27%)\n",
      "\n",
      "-16 -5 0.2687\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 2781/10000 (28%)\n",
      "\n",
      "-16 -4 0.2781\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 2779/10000 (28%)\n",
      "\n",
      "-16 -3 0.2779\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 2926/10000 (29%)\n",
      "\n",
      "-16 -2 0.2926\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3008/10000 (30%)\n",
      "\n",
      "-16 -1 0.3008\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 3089/10000 (31%)\n",
      "\n",
      "-16 0 0.3089\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 3091/10000 (31%)\n",
      "\n",
      "-16 1 0.3091\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 2906/10000 (29%)\n",
      "\n",
      "-16 2 0.2906\n",
      "\n",
      "Test set: Average loss: 0.0187, Accuracy: 2751/10000 (28%)\n",
      "\n",
      "-16 3 0.2751\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 2740/10000 (27%)\n",
      "\n",
      "-16 4 0.274\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 2642/10000 (26%)\n",
      "\n",
      "-16 5 0.2642\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 2589/10000 (26%)\n",
      "\n",
      "-16 6 0.2589\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2631/10000 (26%)\n",
      "\n",
      "-16 7 0.2631\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 2492/10000 (25%)\n",
      "\n",
      "-16 8 0.2492\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 2403/10000 (24%)\n",
      "\n",
      "-16 9 0.2403\n",
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 2276/10000 (23%)\n",
      "\n",
      "-16 10 0.2276\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2168/10000 (22%)\n",
      "\n",
      "-16 11 0.2168\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 1944/10000 (19%)\n",
      "\n",
      "-16 12 0.1944\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1765/10000 (18%)\n",
      "\n",
      "-16 13 0.1765\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1671/10000 (17%)\n",
      "\n",
      "-16 14 0.1671\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1492/10000 (15%)\n",
      "\n",
      "-16 15 0.1492\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1438/10000 (14%)\n",
      "\n",
      "-16 16 0.1438\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1338/10000 (13%)\n",
      "\n",
      "-16 17 0.1338\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1293/10000 (13%)\n",
      "\n",
      "-16 18 0.1293\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1253/10000 (13%)\n",
      "\n",
      "-16 19 0.1253\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1204/10000 (12%)\n",
      "\n",
      "-16 20 0.1204\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1030/10000 (10%)\n",
      "\n",
      "-16 21 0.103\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1167/10000 (12%)\n",
      "\n",
      "-16 22 0.1167\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "-16 23 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "-16 24 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-16 25 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-16 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-16 27 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-15 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-15 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1134/10000 (11%)\n",
      "\n",
      "-15 -25 0.1134\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-15 -24 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "-15 -23 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1157/10000 (12%)\n",
      "\n",
      "-15 -22 0.1157\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1179/10000 (12%)\n",
      "\n",
      "-15 -21 0.1179\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1195/10000 (12%)\n",
      "\n",
      "-15 -20 0.1195\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1250/10000 (12%)\n",
      "\n",
      "-15 -19 0.125\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1307/10000 (13%)\n",
      "\n",
      "-15 -18 0.1307\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1358/10000 (14%)\n",
      "\n",
      "-15 -17 0.1358\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1514/10000 (15%)\n",
      "\n",
      "-15 -16 0.1514\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1623/10000 (16%)\n",
      "\n",
      "-15 -15 0.1623\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1805/10000 (18%)\n",
      "\n",
      "-15 -14 0.1805\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 2033/10000 (20%)\n",
      "\n",
      "-15 -13 0.2033\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2198/10000 (22%)\n",
      "\n",
      "-15 -12 0.2198\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2424/10000 (24%)\n",
      "\n",
      "-15 -11 0.2424\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 2477/10000 (25%)\n",
      "\n",
      "-15 -10 0.2477\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2476/10000 (25%)\n",
      "\n",
      "-15 -9 0.2476\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 2512/10000 (25%)\n",
      "\n",
      "-15 -8 0.2512\n",
      "\n",
      "Test set: Average loss: 0.0187, Accuracy: 2636/10000 (26%)\n",
      "\n",
      "-15 -7 0.2636\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 2765/10000 (28%)\n",
      "\n",
      "-15 -6 0.2765\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 2966/10000 (30%)\n",
      "\n",
      "-15 -5 0.2966\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3070/10000 (31%)\n",
      "\n",
      "-15 -4 0.307\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 3309/10000 (33%)\n",
      "\n",
      "-15 -3 0.3309\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 3347/10000 (33%)\n",
      "\n",
      "-15 -2 0.3347\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 3494/10000 (35%)\n",
      "\n",
      "-15 -1 0.3494\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 3586/10000 (36%)\n",
      "\n",
      "-15 0 0.3586\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 3474/10000 (35%)\n",
      "\n",
      "-15 1 0.3474\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 3503/10000 (35%)\n",
      "\n",
      "-15 2 0.3503\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 3482/10000 (35%)\n",
      "\n",
      "-15 3 0.3482\n",
      "\n",
      "Test set: Average loss: 0.0177, Accuracy: 3358/10000 (34%)\n",
      "\n",
      "-15 4 0.3358\n",
      "\n",
      "Test set: Average loss: 0.0177, Accuracy: 3285/10000 (33%)\n",
      "\n",
      "-15 5 0.3285\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 3131/10000 (31%)\n",
      "\n",
      "-15 6 0.3131\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 3120/10000 (31%)\n",
      "\n",
      "-15 7 0.312\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 2926/10000 (29%)\n",
      "\n",
      "-15 8 0.2926\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 2711/10000 (27%)\n",
      "\n",
      "-15 9 0.2711\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2495/10000 (25%)\n",
      "\n",
      "-15 10 0.2495\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2314/10000 (23%)\n",
      "\n",
      "-15 11 0.2314\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 2006/10000 (20%)\n",
      "\n",
      "-15 12 0.2006\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1756/10000 (18%)\n",
      "\n",
      "-15 13 0.1756\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1671/10000 (17%)\n",
      "\n",
      "-15 14 0.1671\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1526/10000 (15%)\n",
      "\n",
      "-15 15 0.1526\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1448/10000 (14%)\n",
      "\n",
      "-15 16 0.1448\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1340/10000 (13%)\n",
      "\n",
      "-15 17 0.134\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1268/10000 (13%)\n",
      "\n",
      "-15 18 0.1268\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1250/10000 (12%)\n",
      "\n",
      "-15 19 0.125\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1219/10000 (12%)\n",
      "\n",
      "-15 20 0.1219\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1200/10000 (12%)\n",
      "\n",
      "-15 21 0.12\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1173/10000 (12%)\n",
      "\n",
      "-15 22 0.1173\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1157/10000 (12%)\n",
      "\n",
      "-15 23 0.1157\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "-15 24 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-15 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-15 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-15 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-14 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-14 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0321, Accuracy: 1134/10000 (11%)\n",
      "\n",
      "-14 -25 0.1134\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-14 -24 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "-14 -23 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1161/10000 (12%)\n",
      "\n",
      "-14 -22 0.1161\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1178/10000 (12%)\n",
      "\n",
      "-14 -21 0.1178\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1227/10000 (12%)\n",
      "\n",
      "-14 -20 0.1227\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1262/10000 (13%)\n",
      "\n",
      "-14 -19 0.1262\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1325/10000 (13%)\n",
      "\n",
      "-14 -18 0.1325\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1399/10000 (14%)\n",
      "\n",
      "-14 -17 0.1399\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1520/10000 (15%)\n",
      "\n",
      "-14 -16 0.152\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1731/10000 (17%)\n",
      "\n",
      "-14 -15 0.1731\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1897/10000 (19%)\n",
      "\n",
      "-14 -14 0.1897\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 2147/10000 (21%)\n",
      "\n",
      "-14 -13 0.2147\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2473/10000 (25%)\n",
      "\n",
      "-14 -12 0.2473\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2719/10000 (27%)\n",
      "\n",
      "-14 -11 0.2719\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 2819/10000 (28%)\n",
      "\n",
      "-14 -10 0.2819\n",
      "\n",
      "Test set: Average loss: 0.0187, Accuracy: 2863/10000 (29%)\n",
      "\n",
      "-14 -9 0.2863\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 2825/10000 (28%)\n",
      "\n",
      "-14 -8 0.2825\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 2926/10000 (29%)\n",
      "\n",
      "-14 -7 0.2926\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 3091/10000 (31%)\n",
      "\n",
      "-14 -6 0.3091\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 3292/10000 (33%)\n",
      "\n",
      "-14 -5 0.3292\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 3483/10000 (35%)\n",
      "\n",
      "-14 -4 0.3483\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 3559/10000 (36%)\n",
      "\n",
      "-14 -3 0.3559\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 3721/10000 (37%)\n",
      "\n",
      "-14 -2 0.3721\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 3885/10000 (39%)\n",
      "\n",
      "-14 -1 0.3885\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 4018/10000 (40%)\n",
      "\n",
      "-14 0 0.4018\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4054/10000 (41%)\n",
      "\n",
      "-14 1 0.4054\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4078/10000 (41%)\n",
      "\n",
      "-14 2 0.4078\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4025/10000 (40%)\n",
      "\n",
      "-14 3 0.4025\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 3963/10000 (40%)\n",
      "\n",
      "-14 4 0.3963\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 3873/10000 (39%)\n",
      "\n",
      "-14 5 0.3873\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 3869/10000 (39%)\n",
      "\n",
      "-14 6 0.3869\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 3601/10000 (36%)\n",
      "\n",
      "-14 7 0.3601\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 3341/10000 (33%)\n",
      "\n",
      "-14 8 0.3341\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 3065/10000 (31%)\n",
      "\n",
      "-14 9 0.3065\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 2728/10000 (27%)\n",
      "\n",
      "-14 10 0.2728\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2501/10000 (25%)\n",
      "\n",
      "-14 11 0.2501\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2132/10000 (21%)\n",
      "\n",
      "-14 12 0.2132\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1964/10000 (20%)\n",
      "\n",
      "-14 13 0.1964\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1696/10000 (17%)\n",
      "\n",
      "-14 14 0.1696\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1572/10000 (16%)\n",
      "\n",
      "-14 15 0.1572\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1447/10000 (14%)\n",
      "\n",
      "-14 16 0.1447\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1321/10000 (13%)\n",
      "\n",
      "-14 17 0.1321\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1285/10000 (13%)\n",
      "\n",
      "-14 18 0.1285\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 501/10000 (5%)\n",
      "\n",
      "-14 19 0.0501\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1211/10000 (12%)\n",
      "\n",
      "-14 20 0.1211\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1178/10000 (12%)\n",
      "\n",
      "-14 21 0.1178\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1164/10000 (12%)\n",
      "\n",
      "-14 22 0.1164\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1151/10000 (12%)\n",
      "\n",
      "-14 23 0.1151\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "-14 24 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-14 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-14 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "-14 27 0.101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-13 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-13 -26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-13 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-13 -24 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1151/10000 (12%)\n",
      "\n",
      "-13 -23 0.1151\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1164/10000 (12%)\n",
      "\n",
      "-13 -22 0.1164\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1175/10000 (12%)\n",
      "\n",
      "-13 -21 0.1175\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1230/10000 (12%)\n",
      "\n",
      "-13 -20 0.123\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1284/10000 (13%)\n",
      "\n",
      "-13 -19 0.1284\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1343/10000 (13%)\n",
      "\n",
      "-13 -18 0.1343\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1421/10000 (14%)\n",
      "\n",
      "-13 -17 0.1421\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1598/10000 (16%)\n",
      "\n",
      "-13 -16 0.1598\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1819/10000 (18%)\n",
      "\n",
      "-13 -15 0.1819\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 2122/10000 (21%)\n",
      "\n",
      "-13 -14 0.2122\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2476/10000 (25%)\n",
      "\n",
      "-13 -13 0.2476\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 2784/10000 (28%)\n",
      "\n",
      "-13 -12 0.2784\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 2985/10000 (30%)\n",
      "\n",
      "-13 -11 0.2985\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 3144/10000 (31%)\n",
      "\n",
      "-13 -10 0.3144\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 3157/10000 (32%)\n",
      "\n",
      "-13 -9 0.3157\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3179/10000 (32%)\n",
      "\n",
      "-13 -8 0.3179\n",
      "\n",
      "Test set: Average loss: 0.0177, Accuracy: 3338/10000 (33%)\n",
      "\n",
      "-13 -7 0.3338\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 3625/10000 (36%)\n",
      "\n",
      "-13 -6 0.3625\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 3783/10000 (38%)\n",
      "\n",
      "-13 -5 0.3783\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 3951/10000 (40%)\n",
      "\n",
      "-13 -4 0.3951\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4060/10000 (41%)\n",
      "\n",
      "-13 -3 0.406\n",
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 4214/10000 (42%)\n",
      "\n",
      "-13 -2 0.4214\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 4390/10000 (44%)\n",
      "\n",
      "-13 -1 0.439\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 4514/10000 (45%)\n",
      "\n",
      "-13 0 0.4514\n",
      "\n",
      "Test set: Average loss: 0.0147, Accuracy: 4661/10000 (47%)\n",
      "\n",
      "-13 1 0.4661\n",
      "\n",
      "Test set: Average loss: 0.0146, Accuracy: 4613/10000 (46%)\n",
      "\n",
      "-13 2 0.4613\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 4589/10000 (46%)\n",
      "\n",
      "-13 3 0.4589\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4397/10000 (44%)\n",
      "\n",
      "-13 4 0.4397\n",
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 4351/10000 (44%)\n",
      "\n",
      "-13 5 0.4351\n",
      "\n",
      "Test set: Average loss: 0.0157, Accuracy: 4221/10000 (42%)\n",
      "\n",
      "-13 6 0.4221\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 3910/10000 (39%)\n",
      "\n",
      "-13 7 0.391\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 3606/10000 (36%)\n",
      "\n",
      "-13 8 0.3606\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3241/10000 (32%)\n",
      "\n",
      "-13 9 0.3241\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 2976/10000 (30%)\n",
      "\n",
      "-13 10 0.2976\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2663/10000 (27%)\n",
      "\n",
      "-13 11 0.2663\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2333/10000 (23%)\n",
      "\n",
      "-13 12 0.2333\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2065/10000 (21%)\n",
      "\n",
      "-13 13 0.2065\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1813/10000 (18%)\n",
      "\n",
      "-13 14 0.1813\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1626/10000 (16%)\n",
      "\n",
      "-13 15 0.1626\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1507/10000 (15%)\n",
      "\n",
      "-13 16 0.1507\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1401/10000 (14%)\n",
      "\n",
      "-13 17 0.1401\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1286/10000 (13%)\n",
      "\n",
      "-13 18 0.1286\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1239/10000 (12%)\n",
      "\n",
      "-13 19 0.1239\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1204/10000 (12%)\n",
      "\n",
      "-13 20 0.1204\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1182/10000 (12%)\n",
      "\n",
      "-13 21 0.1182\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1153/10000 (12%)\n",
      "\n",
      "-13 22 0.1153\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "-13 23 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-13 24 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 980/10000 (10%)\n",
      "\n",
      "-13 25 0.098\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-13 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-13 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-12 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-12 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-12 -25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-12 -24 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1151/10000 (12%)\n",
      "\n",
      "-12 -23 0.1151\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1161/10000 (12%)\n",
      "\n",
      "-12 -22 0.1161\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1189/10000 (12%)\n",
      "\n",
      "-12 -21 0.1189\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1235/10000 (12%)\n",
      "\n",
      "-12 -20 0.1235\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1287/10000 (13%)\n",
      "\n",
      "-12 -19 0.1287\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1350/10000 (14%)\n",
      "\n",
      "-12 -18 0.135\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1513/10000 (15%)\n",
      "\n",
      "-12 -17 0.1513\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1748/10000 (17%)\n",
      "\n",
      "-12 -16 0.1748\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1966/10000 (20%)\n",
      "\n",
      "-12 -15 0.1966\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 2344/10000 (23%)\n",
      "\n",
      "-12 -14 0.2344\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2730/10000 (27%)\n",
      "\n",
      "-12 -13 0.273\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 3030/10000 (30%)\n",
      "\n",
      "-12 -12 0.303\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3230/10000 (32%)\n",
      "\n",
      "-12 -11 0.323\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3417/10000 (34%)\n",
      "\n",
      "-12 -10 0.3417\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 3520/10000 (35%)\n",
      "\n",
      "-12 -9 0.352\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 3580/10000 (36%)\n",
      "\n",
      "-12 -8 0.358\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 3826/10000 (38%)\n",
      "\n",
      "-12 -7 0.3826\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 4043/10000 (40%)\n",
      "\n",
      "-12 -6 0.4043\n",
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 4153/10000 (42%)\n",
      "\n",
      "-12 -5 0.4153\n",
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 4286/10000 (43%)\n",
      "\n",
      "-12 -4 0.4286\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 4456/10000 (45%)\n",
      "\n",
      "-12 -3 0.4456\n",
      "\n",
      "Test set: Average loss: 0.0147, Accuracy: 4642/10000 (46%)\n",
      "\n",
      "-12 -2 0.4642\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 4733/10000 (47%)\n",
      "\n",
      "-12 -1 0.4733\n",
      "\n",
      "Test set: Average loss: 0.0140, Accuracy: 4853/10000 (49%)\n",
      "\n",
      "-12 0 0.4853\n",
      "\n",
      "Test set: Average loss: 0.0141, Accuracy: 4927/10000 (49%)\n",
      "\n",
      "-12 1 0.4927\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 4800/10000 (48%)\n",
      "\n",
      "-12 2 0.48\n",
      "\n",
      "Test set: Average loss: 0.0146, Accuracy: 4767/10000 (48%)\n",
      "\n",
      "-12 3 0.4767\n",
      "\n",
      "Test set: Average loss: 0.0146, Accuracy: 4659/10000 (47%)\n",
      "\n",
      "-12 4 0.4659\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 4542/10000 (45%)\n",
      "\n",
      "-12 5 0.4542\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4379/10000 (44%)\n",
      "\n",
      "-12 6 0.4379\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4096/10000 (41%)\n",
      "\n",
      "-12 7 0.4096\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 3822/10000 (38%)\n",
      "\n",
      "-12 8 0.3822\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3456/10000 (35%)\n",
      "\n",
      "-12 9 0.3456\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3336/10000 (33%)\n",
      "\n",
      "-12 10 0.3336\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 3023/10000 (30%)\n",
      "\n",
      "-12 11 0.3023\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2708/10000 (27%)\n",
      "\n",
      "-12 12 0.2708\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2437/10000 (24%)\n",
      "\n",
      "-12 13 0.2437\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 2094/10000 (21%)\n",
      "\n",
      "-12 14 0.2094\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1789/10000 (18%)\n",
      "\n",
      "-12 15 0.1789\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1583/10000 (16%)\n",
      "\n",
      "-12 16 0.1583\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1435/10000 (14%)\n",
      "\n",
      "-12 17 0.1435\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1334/10000 (13%)\n",
      "\n",
      "-12 18 0.1334\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1235/10000 (12%)\n",
      "\n",
      "-12 19 0.1235\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1205/10000 (12%)\n",
      "\n",
      "-12 20 0.1205\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1162/10000 (12%)\n",
      "\n",
      "-12 21 0.1162\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1148/10000 (11%)\n",
      "\n",
      "-12 22 0.1148\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "-12 23 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-12 24 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-12 25 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-12 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-12 27 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-11 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-11 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-11 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-11 -24 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "-11 -23 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1171/10000 (12%)\n",
      "\n",
      "-11 -22 0.1171\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1205/10000 (12%)\n",
      "\n",
      "-11 -21 0.1205\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1252/10000 (13%)\n",
      "\n",
      "-11 -20 0.1252\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1332/10000 (13%)\n",
      "\n",
      "-11 -19 0.1332\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1430/10000 (14%)\n",
      "\n",
      "-11 -18 0.143\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1619/10000 (16%)\n",
      "\n",
      "-11 -17 0.1619\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1794/10000 (18%)\n",
      "\n",
      "-11 -16 0.1794\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 2185/10000 (22%)\n",
      "\n",
      "-11 -15 0.2185\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2559/10000 (26%)\n",
      "\n",
      "-11 -14 0.2559\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 2968/10000 (30%)\n",
      "\n",
      "-11 -13 0.2968\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 3364/10000 (34%)\n",
      "\n",
      "-11 -12 0.3364\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 3515/10000 (35%)\n",
      "\n",
      "-11 -11 0.3515\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 3585/10000 (36%)\n",
      "\n",
      "-11 -10 0.3585\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 3576/10000 (36%)\n",
      "\n",
      "-11 -9 0.3576\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 3790/10000 (38%)\n",
      "\n",
      "-11 -8 0.379\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 4153/10000 (42%)\n",
      "\n",
      "-11 -7 0.4153\n",
      "\n",
      "Test set: Average loss: 0.0157, Accuracy: 4308/10000 (43%)\n",
      "\n",
      "-11 -6 0.4308\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4355/10000 (44%)\n",
      "\n",
      "-11 -5 0.4355\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 4630/10000 (46%)\n",
      "\n",
      "-11 -4 0.463\n",
      "\n",
      "Test set: Average loss: 0.0144, Accuracy: 4767/10000 (48%)\n",
      "\n",
      "-11 -3 0.4767\n",
      "\n",
      "Test set: Average loss: 0.0141, Accuracy: 4870/10000 (49%)\n",
      "\n",
      "-11 -2 0.487\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 4997/10000 (50%)\n",
      "\n",
      "-11 -1 0.4997\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5027/10000 (50%)\n",
      "\n",
      "-11 0 0.5027\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 5184/10000 (52%)\n",
      "\n",
      "-11 1 0.5184\n",
      "\n",
      "Test set: Average loss: 0.0137, Accuracy: 5071/10000 (51%)\n",
      "\n",
      "-11 2 0.5071\n",
      "\n",
      "Test set: Average loss: 0.0141, Accuracy: 4913/10000 (49%)\n",
      "\n",
      "-11 3 0.4913\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 4794/10000 (48%)\n",
      "\n",
      "-11 4 0.4794\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 4756/10000 (48%)\n",
      "\n",
      "-11 5 0.4756\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 4602/10000 (46%)\n",
      "\n",
      "-11 6 0.4602\n",
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 4285/10000 (43%)\n",
      "\n",
      "-11 7 0.4285\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 4100/10000 (41%)\n",
      "\n",
      "-11 8 0.41\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 3988/10000 (40%)\n",
      "\n",
      "-11 9 0.3988\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 3821/10000 (38%)\n",
      "\n",
      "-11 10 0.3821\n",
      "\n",
      "Test set: Average loss: 0.0187, Accuracy: 3318/10000 (33%)\n",
      "\n",
      "-11 11 0.3318\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 3032/10000 (30%)\n",
      "\n",
      "-11 12 0.3032\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2657/10000 (27%)\n",
      "\n",
      "-11 13 0.2657\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2295/10000 (23%)\n",
      "\n",
      "-11 14 0.2295\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1971/10000 (20%)\n",
      "\n",
      "-11 15 0.1971\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1727/10000 (17%)\n",
      "\n",
      "-11 16 0.1727\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1528/10000 (15%)\n",
      "\n",
      "-11 17 0.1528\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1372/10000 (14%)\n",
      "\n",
      "-11 18 0.1372\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1262/10000 (13%)\n",
      "\n",
      "-11 19 0.1262\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1209/10000 (12%)\n",
      "\n",
      "-11 20 0.1209\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1184/10000 (12%)\n",
      "\n",
      "-11 21 0.1184\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1164/10000 (12%)\n",
      "\n",
      "-11 22 0.1164\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "-11 23 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 975/10000 (10%)\n",
      "\n",
      "-11 24 0.0975\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-11 25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-11 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 974/10000 (10%)\n",
      "\n",
      "-11 27 0.0974\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-10 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-10 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-10 -25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-10 -24 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "-10 -23 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1183/10000 (12%)\n",
      "\n",
      "-10 -22 0.1183\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1222/10000 (12%)\n",
      "\n",
      "-10 -21 0.1222\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1285/10000 (13%)\n",
      "\n",
      "-10 -20 0.1285\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1361/10000 (14%)\n",
      "\n",
      "-10 -19 0.1361\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1487/10000 (15%)\n",
      "\n",
      "-10 -18 0.1487\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1718/10000 (17%)\n",
      "\n",
      "-10 -17 0.1718\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1974/10000 (20%)\n",
      "\n",
      "-10 -16 0.1974\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2345/10000 (23%)\n",
      "\n",
      "-10 -15 0.2345\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2773/10000 (28%)\n",
      "\n",
      "-10 -14 0.2773\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 3206/10000 (32%)\n",
      "\n",
      "-10 -13 0.3206\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 3496/10000 (35%)\n",
      "\n",
      "-10 -12 0.3496\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 3634/10000 (36%)\n",
      "\n",
      "-10 -11 0.3634\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 3713/10000 (37%)\n",
      "\n",
      "-10 -10 0.3713\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 3890/10000 (39%)\n",
      "\n",
      "-10 -9 0.389\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4184/10000 (42%)\n",
      "\n",
      "-10 -8 0.4184\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4526/10000 (45%)\n",
      "\n",
      "-10 -7 0.4526\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 4718/10000 (47%)\n",
      "\n",
      "-10 -6 0.4718\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 4887/10000 (49%)\n",
      "\n",
      "-10 -5 0.4887\n",
      "\n",
      "Test set: Average loss: 0.0140, Accuracy: 4950/10000 (50%)\n",
      "\n",
      "-10 -4 0.495\n",
      "\n",
      "Test set: Average loss: 0.0141, Accuracy: 5063/10000 (51%)\n",
      "\n",
      "-10 -3 0.5063\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5192/10000 (52%)\n",
      "\n",
      "-10 -2 0.5192\n",
      "\n",
      "Test set: Average loss: 0.0133, Accuracy: 5314/10000 (53%)\n",
      "\n",
      "-10 -1 0.5314\n",
      "\n",
      "Test set: Average loss: 0.0130, Accuracy: 5414/10000 (54%)\n",
      "\n",
      "-10 0 0.5414\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 5395/10000 (54%)\n",
      "\n",
      "-10 1 0.5395\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5167/10000 (52%)\n",
      "\n",
      "-10 2 0.5167\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 5139/10000 (51%)\n",
      "\n",
      "-10 3 0.5139\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 5144/10000 (51%)\n",
      "\n",
      "-10 4 0.5144\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 4976/10000 (50%)\n",
      "\n",
      "-10 5 0.4976\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 4738/10000 (47%)\n",
      "\n",
      "-10 6 0.4738\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 4647/10000 (46%)\n",
      "\n",
      "-10 7 0.4647\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 4555/10000 (46%)\n",
      "\n",
      "-10 8 0.4555\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4317/10000 (43%)\n",
      "\n",
      "-10 9 0.4317\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 4001/10000 (40%)\n",
      "\n",
      "-10 10 0.4001\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3709/10000 (37%)\n",
      "\n",
      "-10 11 0.3709\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 3280/10000 (33%)\n",
      "\n",
      "-10 12 0.328\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2907/10000 (29%)\n",
      "\n",
      "-10 13 0.2907\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2487/10000 (25%)\n",
      "\n",
      "-10 14 0.2487\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 2090/10000 (21%)\n",
      "\n",
      "-10 15 0.209\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1844/10000 (18%)\n",
      "\n",
      "-10 16 0.1844\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1566/10000 (16%)\n",
      "\n",
      "-10 17 0.1566\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 641/10000 (6%)\n",
      "\n",
      "-10 18 0.0641\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1268/10000 (13%)\n",
      "\n",
      "-10 19 0.1268\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1226/10000 (12%)\n",
      "\n",
      "-10 20 0.1226\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1196/10000 (12%)\n",
      "\n",
      "-10 21 0.1196\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1156/10000 (12%)\n",
      "\n",
      "-10 22 0.1156\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1164/10000 (12%)\n",
      "\n",
      "-10 23 0.1164\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "-10 24 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-10 25 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-10 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-10 27 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-9 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-9 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-9 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-9 -24 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1154/10000 (12%)\n",
      "\n",
      "-9 -23 0.1154\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1173/10000 (12%)\n",
      "\n",
      "-9 -22 0.1173\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1213/10000 (12%)\n",
      "\n",
      "-9 -21 0.1213\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1288/10000 (13%)\n",
      "\n",
      "-9 -20 0.1288\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1376/10000 (14%)\n",
      "\n",
      "-9 -19 0.1376\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1531/10000 (15%)\n",
      "\n",
      "-9 -18 0.1531\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1783/10000 (18%)\n",
      "\n",
      "-9 -17 0.1783\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 2073/10000 (21%)\n",
      "\n",
      "-9 -16 0.2073\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2557/10000 (26%)\n",
      "\n",
      "-9 -15 0.2557\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2907/10000 (29%)\n",
      "\n",
      "-9 -14 0.2907\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 3316/10000 (33%)\n",
      "\n",
      "-9 -13 0.3316\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 3705/10000 (37%)\n",
      "\n",
      "-9 -12 0.3705\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 3817/10000 (38%)\n",
      "\n",
      "-9 -11 0.3817\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 3877/10000 (39%)\n",
      "\n",
      "-9 -10 0.3877\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 4171/10000 (42%)\n",
      "\n",
      "-9 -9 0.4171\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 4691/10000 (47%)\n",
      "\n",
      "-9 -8 0.4691\n",
      "\n",
      "Test set: Average loss: 0.0144, Accuracy: 4972/10000 (50%)\n",
      "\n",
      "-9 -7 0.4972\n",
      "\n",
      "Test set: Average loss: 0.0141, Accuracy: 5119/10000 (51%)\n",
      "\n",
      "-9 -6 0.5119\n",
      "\n",
      "Test set: Average loss: 0.0137, Accuracy: 5283/10000 (53%)\n",
      "\n",
      "-9 -5 0.5283\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 5469/10000 (55%)\n",
      "\n",
      "-9 -4 0.5469\n",
      "\n",
      "Test set: Average loss: 0.0128, Accuracy: 5635/10000 (56%)\n",
      "\n",
      "-9 -3 0.5635\n",
      "\n",
      "Test set: Average loss: 0.0126, Accuracy: 5660/10000 (57%)\n",
      "\n",
      "-9 -2 0.566\n",
      "\n",
      "Test set: Average loss: 0.0123, Accuracy: 5710/10000 (57%)\n",
      "\n",
      "-9 -1 0.571\n",
      "\n",
      "Test set: Average loss: 0.0124, Accuracy: 5749/10000 (57%)\n",
      "\n",
      "-9 0 0.5749\n",
      "\n",
      "Test set: Average loss: 0.0123, Accuracy: 5760/10000 (58%)\n",
      "\n",
      "-9 1 0.576\n",
      "\n",
      "Test set: Average loss: 0.0127, Accuracy: 5558/10000 (56%)\n",
      "\n",
      "-9 2 0.5558\n",
      "\n",
      "Test set: Average loss: 0.0130, Accuracy: 5504/10000 (55%)\n",
      "\n",
      "-9 3 0.5504\n",
      "\n",
      "Test set: Average loss: 0.0131, Accuracy: 5400/10000 (54%)\n",
      "\n",
      "-9 4 0.54\n",
      "\n",
      "Test set: Average loss: 0.0133, Accuracy: 5402/10000 (54%)\n",
      "\n",
      "-9 5 0.5402\n",
      "\n",
      "Test set: Average loss: 0.0138, Accuracy: 5090/10000 (51%)\n",
      "\n",
      "-9 6 0.509\n",
      "\n",
      "Test set: Average loss: 0.0140, Accuracy: 4980/10000 (50%)\n",
      "\n",
      "-9 7 0.498\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 4843/10000 (48%)\n",
      "\n",
      "-9 8 0.4843\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4594/10000 (46%)\n",
      "\n",
      "-9 9 0.4594\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 4395/10000 (44%)\n",
      "\n",
      "-9 10 0.4395\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 4000/10000 (40%)\n",
      "\n",
      "-9 11 0.4\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 3511/10000 (35%)\n",
      "\n",
      "-9 12 0.3511\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 3124/10000 (31%)\n",
      "\n",
      "-9 13 0.3124\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2657/10000 (27%)\n",
      "\n",
      "-9 14 0.2657\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 2212/10000 (22%)\n",
      "\n",
      "-9 15 0.2212\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1878/10000 (19%)\n",
      "\n",
      "-9 16 0.1878\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1551/10000 (16%)\n",
      "\n",
      "-9 17 0.1551\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1375/10000 (14%)\n",
      "\n",
      "-9 18 0.1375\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 472/10000 (5%)\n",
      "\n",
      "-9 19 0.0472\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1242/10000 (12%)\n",
      "\n",
      "-9 20 0.1242\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1185/10000 (12%)\n",
      "\n",
      "-9 21 0.1185\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1162/10000 (12%)\n",
      "\n",
      "-9 22 0.1162\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1160/10000 (12%)\n",
      "\n",
      "-9 23 0.116\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "-9 24 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-9 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-9 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-9 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-8 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-8 -26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0240, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-8 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-8 -24 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "-8 -23 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1174/10000 (12%)\n",
      "\n",
      "-8 -22 0.1174\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1227/10000 (12%)\n",
      "\n",
      "-8 -21 0.1227\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1299/10000 (13%)\n",
      "\n",
      "-8 -20 0.1299\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1429/10000 (14%)\n",
      "\n",
      "-8 -19 0.1429\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1550/10000 (16%)\n",
      "\n",
      "-8 -18 0.155\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1822/10000 (18%)\n",
      "\n",
      "-8 -17 0.1822\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 2197/10000 (22%)\n",
      "\n",
      "-8 -16 0.2197\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2560/10000 (26%)\n",
      "\n",
      "-8 -15 0.256\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 3109/10000 (31%)\n",
      "\n",
      "-8 -14 0.3109\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 3487/10000 (35%)\n",
      "\n",
      "-8 -13 0.3487\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 3840/10000 (38%)\n",
      "\n",
      "-8 -12 0.384\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 4010/10000 (40%)\n",
      "\n",
      "-8 -11 0.401\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 4220/10000 (42%)\n",
      "\n",
      "-8 -10 0.422\n",
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 4525/10000 (45%)\n",
      "\n",
      "-8 -9 0.4525\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 4959/10000 (50%)\n",
      "\n",
      "-8 -8 0.4959\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5286/10000 (53%)\n",
      "\n",
      "-8 -7 0.5286\n",
      "\n",
      "Test set: Average loss: 0.0133, Accuracy: 5496/10000 (55%)\n",
      "\n",
      "-8 -6 0.5496\n",
      "\n",
      "Test set: Average loss: 0.0133, Accuracy: 5662/10000 (57%)\n",
      "\n",
      "-8 -5 0.5662\n",
      "\n",
      "Test set: Average loss: 0.0125, Accuracy: 5901/10000 (59%)\n",
      "\n",
      "-8 -4 0.5901\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 6037/10000 (60%)\n",
      "\n",
      "-8 -3 0.6037\n",
      "\n",
      "Test set: Average loss: 0.0116, Accuracy: 6059/10000 (61%)\n",
      "\n",
      "-8 -2 0.6059\n",
      "\n",
      "Test set: Average loss: 0.0112, Accuracy: 6202/10000 (62%)\n",
      "\n",
      "-8 -1 0.6202\n",
      "\n",
      "Test set: Average loss: 0.0112, Accuracy: 6209/10000 (62%)\n",
      "\n",
      "-8 0 0.6209\n",
      "\n",
      "Test set: Average loss: 0.0115, Accuracy: 6163/10000 (62%)\n",
      "\n",
      "-8 1 0.6163\n",
      "\n",
      "Test set: Average loss: 0.0116, Accuracy: 6079/10000 (61%)\n",
      "\n",
      "-8 2 0.6079\n",
      "\n",
      "Test set: Average loss: 0.0115, Accuracy: 6093/10000 (61%)\n",
      "\n",
      "-8 3 0.6093\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 5950/10000 (60%)\n",
      "\n",
      "-8 4 0.595\n",
      "\n",
      "Test set: Average loss: 0.0125, Accuracy: 5737/10000 (57%)\n",
      "\n",
      "-8 5 0.5737\n",
      "\n",
      "Test set: Average loss: 0.0130, Accuracy: 5517/10000 (55%)\n",
      "\n",
      "-8 6 0.5517\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 5333/10000 (53%)\n",
      "\n",
      "-8 7 0.5333\n",
      "\n",
      "Test set: Average loss: 0.0138, Accuracy: 5189/10000 (52%)\n",
      "\n",
      "-8 8 0.5189\n",
      "\n",
      "Test set: Average loss: 0.0146, Accuracy: 4908/10000 (49%)\n",
      "\n",
      "-8 9 0.4908\n",
      "\n",
      "Test set: Average loss: 0.0156, Accuracy: 4682/10000 (47%)\n",
      "\n",
      "-8 10 0.4682\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 4277/10000 (43%)\n",
      "\n",
      "-8 11 0.4277\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3831/10000 (38%)\n",
      "\n",
      "-8 12 0.3831\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 3182/10000 (32%)\n",
      "\n",
      "-8 13 0.3182\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2724/10000 (27%)\n",
      "\n",
      "-8 14 0.2724\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2171/10000 (22%)\n",
      "\n",
      "-8 15 0.2171\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1894/10000 (19%)\n",
      "\n",
      "-8 16 0.1894\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1576/10000 (16%)\n",
      "\n",
      "-8 17 0.1576\n",
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 646/10000 (6%)\n",
      "\n",
      "-8 18 0.0646\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1316/10000 (13%)\n",
      "\n",
      "-8 19 0.1316\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1270/10000 (13%)\n",
      "\n",
      "-8 20 0.127\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1214/10000 (12%)\n",
      "\n",
      "-8 21 0.1214\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1203/10000 (12%)\n",
      "\n",
      "-8 22 0.1203\n",
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 1167/10000 (12%)\n",
      "\n",
      "-8 23 0.1167\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "-8 24 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "-8 25 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-8 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-8 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-7 -27 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-7 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "-7 -25 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "-7 -24 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1159/10000 (12%)\n",
      "\n",
      "-7 -23 0.1159\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1181/10000 (12%)\n",
      "\n",
      "-7 -22 0.1181\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1225/10000 (12%)\n",
      "\n",
      "-7 -21 0.1225\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1348/10000 (13%)\n",
      "\n",
      "-7 -20 0.1348\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1422/10000 (14%)\n",
      "\n",
      "-7 -19 0.1422\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1659/10000 (17%)\n",
      "\n",
      "-7 -18 0.1659\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1909/10000 (19%)\n",
      "\n",
      "-7 -17 0.1909\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 2308/10000 (23%)\n",
      "\n",
      "-7 -16 0.2308\n",
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 2840/10000 (28%)\n",
      "\n",
      "-7 -15 0.284\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 3338/10000 (33%)\n",
      "\n",
      "-7 -14 0.3338\n",
      "\n",
      "Test set: Average loss: 0.0177, Accuracy: 3744/10000 (37%)\n",
      "\n",
      "-7 -13 0.3744\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 4028/10000 (40%)\n",
      "\n",
      "-7 -12 0.4028\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 4197/10000 (42%)\n",
      "\n",
      "-7 -11 0.4197\n",
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 4516/10000 (45%)\n",
      "\n",
      "-7 -10 0.4516\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 4986/10000 (50%)\n",
      "\n",
      "-7 -9 0.4986\n",
      "\n",
      "Test set: Average loss: 0.0137, Accuracy: 5320/10000 (53%)\n",
      "\n",
      "-7 -8 0.532\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 5501/10000 (55%)\n",
      "\n",
      "-7 -7 0.5501\n",
      "\n",
      "Test set: Average loss: 0.0130, Accuracy: 5808/10000 (58%)\n",
      "\n",
      "-7 -6 0.5808\n",
      "\n",
      "Test set: Average loss: 0.0124, Accuracy: 6143/10000 (61%)\n",
      "\n",
      "-7 -5 0.6143\n",
      "\n",
      "Test set: Average loss: 0.0118, Accuracy: 6284/10000 (63%)\n",
      "\n",
      "-7 -4 0.6284\n",
      "\n",
      "Test set: Average loss: 0.0112, Accuracy: 6379/10000 (64%)\n",
      "\n",
      "-7 -3 0.6379\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6581/10000 (66%)\n",
      "\n",
      "-7 -2 0.6581\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 6610/10000 (66%)\n",
      "\n",
      "-7 -1 0.661\n",
      "\n",
      "Test set: Average loss: 0.0101, Accuracy: 6647/10000 (66%)\n",
      "\n",
      "-7 0 0.6647\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 6598/10000 (66%)\n",
      "\n",
      "-7 1 0.6598\n",
      "\n",
      "Test set: Average loss: 0.0105, Accuracy: 6560/10000 (66%)\n",
      "\n",
      "-7 2 0.656\n",
      "\n",
      "Test set: Average loss: 0.0108, Accuracy: 6469/10000 (65%)\n",
      "\n",
      "-7 3 0.6469\n",
      "\n",
      "Test set: Average loss: 0.0114, Accuracy: 6286/10000 (63%)\n",
      "\n",
      "-7 4 0.6286\n",
      "\n",
      "Test set: Average loss: 0.0118, Accuracy: 6062/10000 (61%)\n",
      "\n",
      "-7 5 0.6062\n",
      "\n",
      "Test set: Average loss: 0.0124, Accuracy: 5838/10000 (58%)\n",
      "\n",
      "-7 6 0.5838\n",
      "\n",
      "Test set: Average loss: 0.0128, Accuracy: 5514/10000 (55%)\n",
      "\n",
      "-7 7 0.5514\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 5385/10000 (54%)\n",
      "\n",
      "-7 8 0.5385\n",
      "\n",
      "Test set: Average loss: 0.0141, Accuracy: 5155/10000 (52%)\n",
      "\n",
      "-7 9 0.5155\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 4948/10000 (49%)\n",
      "\n",
      "-7 10 0.4948\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 4527/10000 (45%)\n",
      "\n",
      "-7 11 0.4527\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 4005/10000 (40%)\n",
      "\n",
      "-7 12 0.4005\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 3380/10000 (34%)\n",
      "\n",
      "-7 13 0.338\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2752/10000 (28%)\n",
      "\n",
      "-7 14 0.2752\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2277/10000 (23%)\n",
      "\n",
      "-7 15 0.2277\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1858/10000 (19%)\n",
      "\n",
      "-7 16 0.1858\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1610/10000 (16%)\n",
      "\n",
      "-7 17 0.161\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1437/10000 (14%)\n",
      "\n",
      "-7 18 0.1437\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1357/10000 (14%)\n",
      "\n",
      "-7 19 0.1357\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 513/10000 (5%)\n",
      "\n",
      "-7 20 0.0513\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1236/10000 (12%)\n",
      "\n",
      "-7 21 0.1236\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1194/10000 (12%)\n",
      "\n",
      "-7 22 0.1194\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1177/10000 (12%)\n",
      "\n",
      "-7 23 0.1177\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1162/10000 (12%)\n",
      "\n",
      "-7 24 0.1162\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "-7 25 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-7 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-7 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-6 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-6 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-6 -25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "-6 -24 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1153/10000 (12%)\n",
      "\n",
      "-6 -23 0.1153\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1196/10000 (12%)\n",
      "\n",
      "-6 -22 0.1196\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1253/10000 (13%)\n",
      "\n",
      "-6 -21 0.1253\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1360/10000 (14%)\n",
      "\n",
      "-6 -20 0.136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1464/10000 (15%)\n",
      "\n",
      "-6 -19 0.1464\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1687/10000 (17%)\n",
      "\n",
      "-6 -18 0.1687\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1952/10000 (20%)\n",
      "\n",
      "-6 -17 0.1952\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 2448/10000 (24%)\n",
      "\n",
      "-6 -16 0.2448\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2968/10000 (30%)\n",
      "\n",
      "-6 -15 0.2968\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 3462/10000 (35%)\n",
      "\n",
      "-6 -14 0.3462\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 3937/10000 (39%)\n",
      "\n",
      "-6 -13 0.3937\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 4216/10000 (42%)\n",
      "\n",
      "-6 -12 0.4216\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4445/10000 (44%)\n",
      "\n",
      "-6 -11 0.4445\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 4723/10000 (47%)\n",
      "\n",
      "-6 -10 0.4723\n",
      "\n",
      "Test set: Average loss: 0.0140, Accuracy: 5186/10000 (52%)\n",
      "\n",
      "-6 -9 0.5186\n",
      "\n",
      "Test set: Average loss: 0.0133, Accuracy: 5571/10000 (56%)\n",
      "\n",
      "-6 -8 0.5571\n",
      "\n",
      "Test set: Average loss: 0.0126, Accuracy: 5880/10000 (59%)\n",
      "\n",
      "-6 -7 0.588\n",
      "\n",
      "Test set: Average loss: 0.0121, Accuracy: 6225/10000 (62%)\n",
      "\n",
      "-6 -6 0.6225\n",
      "\n",
      "Test set: Average loss: 0.0114, Accuracy: 6535/10000 (65%)\n",
      "\n",
      "-6 -5 0.6535\n",
      "\n",
      "Test set: Average loss: 0.0109, Accuracy: 6626/10000 (66%)\n",
      "\n",
      "-6 -4 0.6626\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 6711/10000 (67%)\n",
      "\n",
      "-6 -3 0.6711\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 6949/10000 (69%)\n",
      "\n",
      "-6 -2 0.6949\n",
      "\n",
      "Test set: Average loss: 0.0091, Accuracy: 7068/10000 (71%)\n",
      "\n",
      "-6 -1 0.7068\n",
      "\n",
      "Test set: Average loss: 0.0092, Accuracy: 7126/10000 (71%)\n",
      "\n",
      "-6 0 0.7126\n",
      "\n",
      "Test set: Average loss: 0.0094, Accuracy: 7042/10000 (70%)\n",
      "\n",
      "-6 1 0.7042\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 6981/10000 (70%)\n",
      "\n",
      "-6 2 0.6981\n",
      "\n",
      "Test set: Average loss: 0.0101, Accuracy: 6762/10000 (68%)\n",
      "\n",
      "-6 3 0.6762\n",
      "\n",
      "Test set: Average loss: 0.0104, Accuracy: 6655/10000 (67%)\n",
      "\n",
      "-6 4 0.6655\n",
      "\n",
      "Test set: Average loss: 0.0113, Accuracy: 6378/10000 (64%)\n",
      "\n",
      "-6 5 0.6378\n",
      "\n",
      "Test set: Average loss: 0.0118, Accuracy: 6091/10000 (61%)\n",
      "\n",
      "-6 6 0.6091\n",
      "\n",
      "Test set: Average loss: 0.0121, Accuracy: 5907/10000 (59%)\n",
      "\n",
      "-6 7 0.5907\n",
      "\n",
      "Test set: Average loss: 0.0127, Accuracy: 5663/10000 (57%)\n",
      "\n",
      "-6 8 0.5663\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5439/10000 (54%)\n",
      "\n",
      "-6 9 0.5439\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 4995/10000 (50%)\n",
      "\n",
      "-6 10 0.4995\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 4681/10000 (47%)\n",
      "\n",
      "-6 11 0.4681\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 4027/10000 (40%)\n",
      "\n",
      "-6 12 0.4027\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 3528/10000 (35%)\n",
      "\n",
      "-6 13 0.3528\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2818/10000 (28%)\n",
      "\n",
      "-6 14 0.2818\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2313/10000 (23%)\n",
      "\n",
      "-6 15 0.2313\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1894/10000 (19%)\n",
      "\n",
      "-6 16 0.1894\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1097/10000 (11%)\n",
      "\n",
      "-6 17 0.1097\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1483/10000 (15%)\n",
      "\n",
      "-6 18 0.1483\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1428/10000 (14%)\n",
      "\n",
      "-6 19 0.1428\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1334/10000 (13%)\n",
      "\n",
      "-6 20 0.1334\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1286/10000 (13%)\n",
      "\n",
      "-6 21 0.1286\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1219/10000 (12%)\n",
      "\n",
      "-6 22 0.1219\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1205/10000 (12%)\n",
      "\n",
      "-6 23 0.1205\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1167/10000 (12%)\n",
      "\n",
      "-6 24 0.1167\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "-6 25 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-6 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0262, Accuracy: 958/10000 (10%)\n",
      "\n",
      "-6 27 0.0958\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-5 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-5 -26 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-5 -25 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "-5 -24 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1167/10000 (12%)\n",
      "\n",
      "-5 -23 0.1167\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1205/10000 (12%)\n",
      "\n",
      "-5 -22 0.1205\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1288/10000 (13%)\n",
      "\n",
      "-5 -21 0.1288\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1388/10000 (14%)\n",
      "\n",
      "-5 -20 0.1388\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1527/10000 (15%)\n",
      "\n",
      "-5 -19 0.1527\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1801/10000 (18%)\n",
      "\n",
      "-5 -18 0.1801\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 2157/10000 (22%)\n",
      "\n",
      "-5 -17 0.2157\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2642/10000 (26%)\n",
      "\n",
      "-5 -16 0.2642\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 3157/10000 (32%)\n",
      "\n",
      "-5 -15 0.3157\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3725/10000 (37%)\n",
      "\n",
      "-5 -14 0.3725\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 4077/10000 (41%)\n",
      "\n",
      "-5 -13 0.4077\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4378/10000 (44%)\n",
      "\n",
      "-5 -12 0.4378\n",
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 4681/10000 (47%)\n",
      "\n",
      "-5 -11 0.4681\n",
      "\n",
      "Test set: Average loss: 0.0144, Accuracy: 5052/10000 (51%)\n",
      "\n",
      "-5 -10 0.5052\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 5542/10000 (55%)\n",
      "\n",
      "-5 -9 0.5542\n",
      "\n",
      "Test set: Average loss: 0.0121, Accuracy: 6112/10000 (61%)\n",
      "\n",
      "-5 -8 0.6112\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 6278/10000 (63%)\n",
      "\n",
      "-5 -7 0.6278\n",
      "\n",
      "Test set: Average loss: 0.0108, Accuracy: 6704/10000 (67%)\n",
      "\n",
      "-5 -6 0.6704\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 6877/10000 (69%)\n",
      "\n",
      "-5 -5 0.6877\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 7032/10000 (70%)\n",
      "\n",
      "-5 -4 0.7032\n",
      "\n",
      "Test set: Average loss: 0.0094, Accuracy: 7130/10000 (71%)\n",
      "\n",
      "-5 -3 0.713\n",
      "\n",
      "Test set: Average loss: 0.0086, Accuracy: 7371/10000 (74%)\n",
      "\n",
      "-5 -2 0.7371\n",
      "\n",
      "Test set: Average loss: 0.0085, Accuracy: 7511/10000 (75%)\n",
      "\n",
      "-5 -1 0.7511\n",
      "\n",
      "Test set: Average loss: 0.0083, Accuracy: 7500/10000 (75%)\n",
      "\n",
      "-5 0 0.75\n",
      "\n",
      "Test set: Average loss: 0.0086, Accuracy: 7447/10000 (74%)\n",
      "\n",
      "-5 1 0.7447\n",
      "\n",
      "Test set: Average loss: 0.0091, Accuracy: 7252/10000 (73%)\n",
      "\n",
      "-5 2 0.7252\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 7051/10000 (71%)\n",
      "\n",
      "-5 3 0.7051\n",
      "\n",
      "Test set: Average loss: 0.0102, Accuracy: 6778/10000 (68%)\n",
      "\n",
      "-5 4 0.6778\n",
      "\n",
      "Test set: Average loss: 0.0107, Accuracy: 6630/10000 (66%)\n",
      "\n",
      "-5 5 0.663\n",
      "\n",
      "Test set: Average loss: 0.0115, Accuracy: 6326/10000 (63%)\n",
      "\n",
      "-5 6 0.6326\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 6114/10000 (61%)\n",
      "\n",
      "-5 7 0.6114\n",
      "\n",
      "Test set: Average loss: 0.0123, Accuracy: 5899/10000 (59%)\n",
      "\n",
      "-5 8 0.5899\n",
      "\n",
      "Test set: Average loss: 0.0131, Accuracy: 5668/10000 (57%)\n",
      "\n",
      "-5 9 0.5668\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 5198/10000 (52%)\n",
      "\n",
      "-5 10 0.5198\n",
      "\n",
      "Test set: Average loss: 0.0156, Accuracy: 4834/10000 (48%)\n",
      "\n",
      "-5 11 0.4834\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 4172/10000 (42%)\n",
      "\n",
      "-5 12 0.4172\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 3523/10000 (35%)\n",
      "\n",
      "-5 13 0.3523\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2894/10000 (29%)\n",
      "\n",
      "-5 14 0.2894\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 2422/10000 (24%)\n",
      "\n",
      "-5 15 0.2422\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 2023/10000 (20%)\n",
      "\n",
      "-5 16 0.2023\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1755/10000 (18%)\n",
      "\n",
      "-5 17 0.1755\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1582/10000 (16%)\n",
      "\n",
      "-5 18 0.1582\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1469/10000 (15%)\n",
      "\n",
      "-5 19 0.1469\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1396/10000 (14%)\n",
      "\n",
      "-5 20 0.1396\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1302/10000 (13%)\n",
      "\n",
      "-5 21 0.1302\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1265/10000 (13%)\n",
      "\n",
      "-5 22 0.1265\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1028/10000 (10%)\n",
      "\n",
      "-5 23 0.1028\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1172/10000 (12%)\n",
      "\n",
      "-5 24 0.1172\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "-5 25 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-5 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-5 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-4 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-4 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-4 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "-4 -24 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1168/10000 (12%)\n",
      "\n",
      "-4 -23 0.1168\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1209/10000 (12%)\n",
      "\n",
      "-4 -22 0.1209\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1295/10000 (13%)\n",
      "\n",
      "-4 -21 0.1295\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1403/10000 (14%)\n",
      "\n",
      "-4 -20 0.1403\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1637/10000 (16%)\n",
      "\n",
      "-4 -19 0.1637\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1918/10000 (19%)\n",
      "\n",
      "-4 -18 0.1918\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 2310/10000 (23%)\n",
      "\n",
      "-4 -17 0.231\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2819/10000 (28%)\n",
      "\n",
      "-4 -16 0.2819\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 3363/10000 (34%)\n",
      "\n",
      "-4 -15 0.3363\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 3825/10000 (38%)\n",
      "\n",
      "-4 -14 0.3825\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 4144/10000 (41%)\n",
      "\n",
      "-4 -13 0.4144\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4547/10000 (45%)\n",
      "\n",
      "-4 -12 0.4547\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 4835/10000 (48%)\n",
      "\n",
      "-4 -11 0.4835\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 5374/10000 (54%)\n",
      "\n",
      "-4 -10 0.5374\n",
      "\n",
      "Test set: Average loss: 0.0128, Accuracy: 5907/10000 (59%)\n",
      "\n",
      "-4 -9 0.5907\n",
      "\n",
      "Test set: Average loss: 0.0114, Accuracy: 6397/10000 (64%)\n",
      "\n",
      "-4 -8 0.6397\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6773/10000 (68%)\n",
      "\n",
      "-4 -7 0.6773\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 7109/10000 (71%)\n",
      "\n",
      "-4 -6 0.7109\n",
      "\n",
      "Test set: Average loss: 0.0091, Accuracy: 7277/10000 (73%)\n",
      "\n",
      "-4 -5 0.7277\n",
      "\n",
      "Test set: Average loss: 0.0089, Accuracy: 7346/10000 (73%)\n",
      "\n",
      "-4 -4 0.7346\n",
      "\n",
      "Test set: Average loss: 0.0085, Accuracy: 7517/10000 (75%)\n",
      "\n",
      "-4 -3 0.7517\n",
      "\n",
      "Test set: Average loss: 0.0081, Accuracy: 7573/10000 (76%)\n",
      "\n",
      "-4 -2 0.7573\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7662/10000 (77%)\n",
      "\n",
      "-4 -1 0.7662\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7713/10000 (77%)\n",
      "\n",
      "-4 0 0.7713\n",
      "\n",
      "Test set: Average loss: 0.0080, Accuracy: 7696/10000 (77%)\n",
      "\n",
      "-4 1 0.7696\n",
      "\n",
      "Test set: Average loss: 0.0084, Accuracy: 7546/10000 (75%)\n",
      "\n",
      "-4 2 0.7546\n",
      "\n",
      "Test set: Average loss: 0.0088, Accuracy: 7390/10000 (74%)\n",
      "\n",
      "-4 3 0.739\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 7157/10000 (72%)\n",
      "\n",
      "-4 4 0.7157\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 6934/10000 (69%)\n",
      "\n",
      "-4 5 0.6934\n",
      "\n",
      "Test set: Average loss: 0.0105, Accuracy: 6650/10000 (66%)\n",
      "\n",
      "-4 6 0.665\n",
      "\n",
      "Test set: Average loss: 0.0109, Accuracy: 6459/10000 (65%)\n",
      "\n",
      "-4 7 0.6459\n",
      "\n",
      "Test set: Average loss: 0.0116, Accuracy: 6184/10000 (62%)\n",
      "\n",
      "-4 8 0.6184\n",
      "\n",
      "Test set: Average loss: 0.0127, Accuracy: 5836/10000 (58%)\n",
      "\n",
      "-4 9 0.5836\n",
      "\n",
      "Test set: Average loss: 0.0137, Accuracy: 5487/10000 (55%)\n",
      "\n",
      "-4 10 0.5487\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4978/10000 (50%)\n",
      "\n",
      "-4 11 0.4978\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 4345/10000 (43%)\n",
      "\n",
      "-4 12 0.4345\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 3736/10000 (37%)\n",
      "\n",
      "-4 13 0.3736\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 3111/10000 (31%)\n",
      "\n",
      "-4 14 0.3111\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2599/10000 (26%)\n",
      "\n",
      "-4 15 0.2599\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1835/10000 (18%)\n",
      "\n",
      "-4 16 0.1835\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1939/10000 (19%)\n",
      "\n",
      "-4 17 0.1939\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1694/10000 (17%)\n",
      "\n",
      "-4 18 0.1694\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1564/10000 (16%)\n",
      "\n",
      "-4 19 0.1564\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1444/10000 (14%)\n",
      "\n",
      "-4 20 0.1444\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1351/10000 (14%)\n",
      "\n",
      "-4 21 0.1351\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1289/10000 (13%)\n",
      "\n",
      "-4 22 0.1289\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1213/10000 (12%)\n",
      "\n",
      "-4 23 0.1213\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1168/10000 (12%)\n",
      "\n",
      "-4 24 0.1168\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1146/10000 (11%)\n",
      "\n",
      "-4 25 0.1146\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-4 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-4 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-3 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-3 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-3 -25 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1146/10000 (11%)\n",
      "\n",
      "-3 -24 0.1146\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1171/10000 (12%)\n",
      "\n",
      "-3 -23 0.1171\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1218/10000 (12%)\n",
      "\n",
      "-3 -22 0.1218\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1323/10000 (13%)\n",
      "\n",
      "-3 -21 0.1323\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1445/10000 (14%)\n",
      "\n",
      "-3 -20 0.1445\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1713/10000 (17%)\n",
      "\n",
      "-3 -19 0.1713\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1977/10000 (20%)\n",
      "\n",
      "-3 -18 0.1977\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 2458/10000 (25%)\n",
      "\n",
      "-3 -17 0.2458\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2917/10000 (29%)\n",
      "\n",
      "-3 -16 0.2917\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 3560/10000 (36%)\n",
      "\n",
      "-3 -15 0.356\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 3905/10000 (39%)\n",
      "\n",
      "-3 -14 0.3905\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 4245/10000 (42%)\n",
      "\n",
      "-3 -13 0.4245\n",
      "\n",
      "Test set: Average loss: 0.0156, Accuracy: 4622/10000 (46%)\n",
      "\n",
      "-3 -12 0.4622\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 5172/10000 (52%)\n",
      "\n",
      "-3 -11 0.5172\n",
      "\n",
      "Test set: Average loss: 0.0131, Accuracy: 5632/10000 (56%)\n",
      "\n",
      "-3 -10 0.5632\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 6106/10000 (61%)\n",
      "\n",
      "-3 -9 0.6106\n",
      "\n",
      "Test set: Average loss: 0.0109, Accuracy: 6610/10000 (66%)\n",
      "\n",
      "-3 -8 0.661\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 7066/10000 (71%)\n",
      "\n",
      "-3 -7 0.7066\n",
      "\n",
      "Test set: Average loss: 0.0090, Accuracy: 7284/10000 (73%)\n",
      "\n",
      "-3 -6 0.7284\n",
      "\n",
      "Test set: Average loss: 0.0085, Accuracy: 7540/10000 (75%)\n",
      "\n",
      "-3 -5 0.754\n",
      "\n",
      "Test set: Average loss: 0.0082, Accuracy: 7638/10000 (76%)\n",
      "\n",
      "-3 -4 0.7638\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7725/10000 (77%)\n",
      "\n",
      "-3 -3 0.7725\n",
      "\n",
      "Test set: Average loss: 0.0076, Accuracy: 7841/10000 (78%)\n",
      "\n",
      "-3 -2 0.7841\n",
      "\n",
      "Test set: Average loss: 0.0076, Accuracy: 7866/10000 (79%)\n",
      "\n",
      "-3 -1 0.7866\n",
      "\n",
      "Test set: Average loss: 0.0076, Accuracy: 7889/10000 (79%)\n",
      "\n",
      "-3 0 0.7889\n",
      "\n",
      "Test set: Average loss: 0.0071, Accuracy: 7917/10000 (79%)\n",
      "\n",
      "-3 1 0.7917\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7774/10000 (78%)\n",
      "\n",
      "-3 2 0.7774\n",
      "\n",
      "Test set: Average loss: 0.0086, Accuracy: 7597/10000 (76%)\n",
      "\n",
      "-3 3 0.7597\n",
      "\n",
      "Test set: Average loss: 0.0088, Accuracy: 7417/10000 (74%)\n",
      "\n",
      "-3 4 0.7417\n",
      "\n",
      "Test set: Average loss: 0.0092, Accuracy: 7224/10000 (72%)\n",
      "\n",
      "-3 5 0.7224\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 6927/10000 (69%)\n",
      "\n",
      "-3 6 0.6927\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6640/10000 (66%)\n",
      "\n",
      "-3 7 0.664\n",
      "\n",
      "Test set: Average loss: 0.0108, Accuracy: 6496/10000 (65%)\n",
      "\n",
      "-3 8 0.6496\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 6182/10000 (62%)\n",
      "\n",
      "-3 9 0.6182\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 5782/10000 (58%)\n",
      "\n",
      "-3 10 0.5782\n",
      "\n",
      "Test set: Average loss: 0.0144, Accuracy: 5176/10000 (52%)\n",
      "\n",
      "-3 11 0.5176\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 4537/10000 (45%)\n",
      "\n",
      "-3 12 0.4537\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 3825/10000 (38%)\n",
      "\n",
      "-3 13 0.3825\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 3268/10000 (33%)\n",
      "\n",
      "-3 14 0.3268\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2729/10000 (27%)\n",
      "\n",
      "-3 15 0.2729\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 2367/10000 (24%)\n",
      "\n",
      "-3 16 0.2367\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 2049/10000 (20%)\n",
      "\n",
      "-3 17 0.2049\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1784/10000 (18%)\n",
      "\n",
      "-3 18 0.1784\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1639/10000 (16%)\n",
      "\n",
      "-3 19 0.1639\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1490/10000 (15%)\n",
      "\n",
      "-3 20 0.149\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1379/10000 (14%)\n",
      "\n",
      "-3 21 0.1379\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 775/10000 (8%)\n",
      "\n",
      "-3 22 0.0775\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1241/10000 (12%)\n",
      "\n",
      "-3 23 0.1241\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1189/10000 (12%)\n",
      "\n",
      "-3 24 0.1189\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1146/10000 (11%)\n",
      "\n",
      "-3 25 0.1146\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-3 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-3 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-2 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-2 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-2 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "-2 -24 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1163/10000 (12%)\n",
      "\n",
      "-2 -23 0.1163\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1224/10000 (12%)\n",
      "\n",
      "-2 -22 0.1224\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1325/10000 (13%)\n",
      "\n",
      "-2 -21 0.1325\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1505/10000 (15%)\n",
      "\n",
      "-2 -20 0.1505\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1734/10000 (17%)\n",
      "\n",
      "-2 -19 0.1734\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 2131/10000 (21%)\n",
      "\n",
      "-2 -18 0.2131\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 2596/10000 (26%)\n",
      "\n",
      "-2 -17 0.2596\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 3240/10000 (32%)\n",
      "\n",
      "-2 -16 0.324\n",
      "\n",
      "Test set: Average loss: 0.0189, Accuracy: 3638/10000 (36%)\n",
      "\n",
      "-2 -15 0.3638\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 4147/10000 (41%)\n",
      "\n",
      "-2 -14 0.4147\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 4469/10000 (45%)\n",
      "\n",
      "-2 -13 0.4469\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4871/10000 (49%)\n",
      "\n",
      "-2 -12 0.4871\n",
      "\n",
      "Test set: Average loss: 0.0142, Accuracy: 5272/10000 (53%)\n",
      "\n",
      "-2 -11 0.5272\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 5798/10000 (58%)\n",
      "\n",
      "-2 -10 0.5798\n",
      "\n",
      "Test set: Average loss: 0.0119, Accuracy: 6252/10000 (63%)\n",
      "\n",
      "-2 -9 0.6252\n",
      "\n",
      "Test set: Average loss: 0.0104, Accuracy: 6847/10000 (68%)\n",
      "\n",
      "-2 -8 0.6847\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 7070/10000 (71%)\n",
      "\n",
      "-2 -7 0.707\n",
      "\n",
      "Test set: Average loss: 0.0088, Accuracy: 7394/10000 (74%)\n",
      "\n",
      "-2 -6 0.7394\n",
      "\n",
      "Test set: Average loss: 0.0083, Accuracy: 7639/10000 (76%)\n",
      "\n",
      "-2 -5 0.7639\n",
      "\n",
      "Test set: Average loss: 0.0075, Accuracy: 7818/10000 (78%)\n",
      "\n",
      "-2 -4 0.7818\n",
      "\n",
      "Test set: Average loss: 0.0074, Accuracy: 7961/10000 (80%)\n",
      "\n",
      "-2 -3 0.7961\n",
      "\n",
      "Test set: Average loss: 0.0070, Accuracy: 8065/10000 (81%)\n",
      "\n",
      "-2 -2 0.8065\n",
      "\n",
      "Test set: Average loss: 0.0067, Accuracy: 8149/10000 (81%)\n",
      "\n",
      "-2 -1 0.8149\n",
      "\n",
      "Test set: Average loss: 0.0070, Accuracy: 8096/10000 (81%)\n",
      "\n",
      "-2 0 0.8096\n",
      "\n",
      "Test set: Average loss: 0.0070, Accuracy: 8121/10000 (81%)\n",
      "\n",
      "-2 1 0.8121\n",
      "\n",
      "Test set: Average loss: 0.0074, Accuracy: 8010/10000 (80%)\n",
      "\n",
      "-2 2 0.801\n",
      "\n",
      "Test set: Average loss: 0.0080, Accuracy: 7780/10000 (78%)\n",
      "\n",
      "-2 3 0.778\n",
      "\n",
      "Test set: Average loss: 0.0085, Accuracy: 7575/10000 (76%)\n",
      "\n",
      "-2 4 0.7575\n",
      "\n",
      "Test set: Average loss: 0.0086, Accuracy: 7421/10000 (74%)\n",
      "\n",
      "-2 5 0.7421\n",
      "\n",
      "Test set: Average loss: 0.0093, Accuracy: 7186/10000 (72%)\n",
      "\n",
      "-2 6 0.7186\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 6922/10000 (69%)\n",
      "\n",
      "-2 7 0.6922\n",
      "\n",
      "Test set: Average loss: 0.0104, Accuracy: 6704/10000 (67%)\n",
      "\n",
      "-2 8 0.6704\n",
      "\n",
      "Test set: Average loss: 0.0111, Accuracy: 6376/10000 (64%)\n",
      "\n",
      "-2 9 0.6376\n",
      "\n",
      "Test set: Average loss: 0.0125, Accuracy: 5911/10000 (59%)\n",
      "\n",
      "-2 10 0.5911\n",
      "\n",
      "Test set: Average loss: 0.0141, Accuracy: 5332/10000 (53%)\n",
      "\n",
      "-2 11 0.5332\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4679/10000 (47%)\n",
      "\n",
      "-2 12 0.4679\n",
      "\n",
      "Test set: Average loss: 0.0177, Accuracy: 4084/10000 (41%)\n",
      "\n",
      "-2 13 0.4084\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 3473/10000 (35%)\n",
      "\n",
      "-2 14 0.3473\n",
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 3088/10000 (31%)\n",
      "\n",
      "-2 15 0.3088\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2582/10000 (26%)\n",
      "\n",
      "-2 16 0.2582\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 2222/10000 (22%)\n",
      "\n",
      "-2 17 0.2222\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1906/10000 (19%)\n",
      "\n",
      "-2 18 0.1906\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1709/10000 (17%)\n",
      "\n",
      "-2 19 0.1709\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1521/10000 (15%)\n",
      "\n",
      "-2 20 0.1521\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1386/10000 (14%)\n",
      "\n",
      "-2 21 0.1386\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1306/10000 (13%)\n",
      "\n",
      "-2 22 0.1306\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1218/10000 (12%)\n",
      "\n",
      "-2 23 0.1218\n",
      "\n",
      "Test set: Average loss: 0.0242, Accuracy: 964/10000 (10%)\n",
      "\n",
      "-2 24 0.0964\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1148/10000 (11%)\n",
      "\n",
      "-2 25 0.1148\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "-2 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-2 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-1 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-1 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "-1 -25 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1026/10000 (10%)\n",
      "\n",
      "-1 -24 0.1026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1171/10000 (12%)\n",
      "\n",
      "-1 -23 0.1171\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1228/10000 (12%)\n",
      "\n",
      "-1 -22 0.1228\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1368/10000 (14%)\n",
      "\n",
      "-1 -21 0.1368\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1507/10000 (15%)\n",
      "\n",
      "-1 -20 0.1507\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1849/10000 (18%)\n",
      "\n",
      "-1 -19 0.1849\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 2197/10000 (22%)\n",
      "\n",
      "-1 -18 0.2197\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2747/10000 (27%)\n",
      "\n",
      "-1 -17 0.2747\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 3292/10000 (33%)\n",
      "\n",
      "-1 -16 0.3292\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 3856/10000 (39%)\n",
      "\n",
      "-1 -15 0.3856\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 4359/10000 (44%)\n",
      "\n",
      "-1 -14 0.4359\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4650/10000 (46%)\n",
      "\n",
      "-1 -13 0.465\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 5034/10000 (50%)\n",
      "\n",
      "-1 -12 0.5034\n",
      "\n",
      "Test set: Average loss: 0.0142, Accuracy: 5395/10000 (54%)\n",
      "\n",
      "-1 -11 0.5395\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 5802/10000 (58%)\n",
      "\n",
      "-1 -10 0.5802\n",
      "\n",
      "Test set: Average loss: 0.0118, Accuracy: 6311/10000 (63%)\n",
      "\n",
      "-1 -9 0.6311\n",
      "\n",
      "Test set: Average loss: 0.0105, Accuracy: 6756/10000 (68%)\n",
      "\n",
      "-1 -8 0.6756\n",
      "\n",
      "Test set: Average loss: 0.0093, Accuracy: 7236/10000 (72%)\n",
      "\n",
      "-1 -7 0.7236\n",
      "\n",
      "Test set: Average loss: 0.0083, Accuracy: 7519/10000 (75%)\n",
      "\n",
      "-1 -6 0.7519\n",
      "\n",
      "Test set: Average loss: 0.0077, Accuracy: 7767/10000 (78%)\n",
      "\n",
      "-1 -5 0.7767\n",
      "\n",
      "Test set: Average loss: 0.0070, Accuracy: 8034/10000 (80%)\n",
      "\n",
      "-1 -4 0.8034\n",
      "\n",
      "Test set: Average loss: 0.0071, Accuracy: 8042/10000 (80%)\n",
      "\n",
      "-1 -3 0.8042\n",
      "\n",
      "Test set: Average loss: 0.0067, Accuracy: 8263/10000 (83%)\n",
      "\n",
      "-1 -2 0.8263\n",
      "\n",
      "Test set: Average loss: 0.0064, Accuracy: 8288/10000 (83%)\n",
      "\n",
      "-1 -1 0.8288\n",
      "\n",
      "Test set: Average loss: 0.0067, Accuracy: 8264/10000 (83%)\n",
      "\n",
      "-1 0 0.8264\n",
      "\n",
      "Test set: Average loss: 0.0067, Accuracy: 8233/10000 (82%)\n",
      "\n",
      "-1 1 0.8233\n",
      "\n",
      "Test set: Average loss: 0.0067, Accuracy: 8126/10000 (81%)\n",
      "\n",
      "-1 2 0.8126\n",
      "\n",
      "Test set: Average loss: 0.0075, Accuracy: 7959/10000 (80%)\n",
      "\n",
      "-1 3 0.7959\n",
      "\n",
      "Test set: Average loss: 0.0081, Accuracy: 7672/10000 (77%)\n",
      "\n",
      "-1 4 0.7672\n",
      "\n",
      "Test set: Average loss: 0.0084, Accuracy: 7595/10000 (76%)\n",
      "\n",
      "-1 5 0.7595\n",
      "\n",
      "Test set: Average loss: 0.0088, Accuracy: 7316/10000 (73%)\n",
      "\n",
      "-1 6 0.7316\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 7077/10000 (71%)\n",
      "\n",
      "-1 7 0.7077\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 6896/10000 (69%)\n",
      "\n",
      "-1 8 0.6896\n",
      "\n",
      "Test set: Average loss: 0.0108, Accuracy: 6512/10000 (65%)\n",
      "\n",
      "-1 9 0.6512\n",
      "\n",
      "Test set: Average loss: 0.0119, Accuracy: 6111/10000 (61%)\n",
      "\n",
      "-1 10 0.6111\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5530/10000 (55%)\n",
      "\n",
      "-1 11 0.553\n",
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 4872/10000 (49%)\n",
      "\n",
      "-1 12 0.4872\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 4309/10000 (43%)\n",
      "\n",
      "-1 13 0.4309\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3824/10000 (38%)\n",
      "\n",
      "-1 14 0.3824\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 3149/10000 (31%)\n",
      "\n",
      "-1 15 0.3149\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2775/10000 (28%)\n",
      "\n",
      "-1 16 0.2775\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2260/10000 (23%)\n",
      "\n",
      "-1 17 0.226\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1943/10000 (19%)\n",
      "\n",
      "-1 18 0.1943\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1739/10000 (17%)\n",
      "\n",
      "-1 19 0.1739\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1554/10000 (16%)\n",
      "\n",
      "-1 20 0.1554\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1399/10000 (14%)\n",
      "\n",
      "-1 21 0.1399\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1318/10000 (13%)\n",
      "\n",
      "-1 22 0.1318\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1252/10000 (13%)\n",
      "\n",
      "-1 23 0.1252\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1194/10000 (12%)\n",
      "\n",
      "-1 24 0.1194\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "-1 25 0.115\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "-1 26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "-1 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "0 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "0 -26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "0 -25 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "0 -24 0.115\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1182/10000 (12%)\n",
      "\n",
      "0 -23 0.1182\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1248/10000 (12%)\n",
      "\n",
      "0 -22 0.1248\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1335/10000 (13%)\n",
      "\n",
      "0 -21 0.1335\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1588/10000 (16%)\n",
      "\n",
      "0 -20 0.1588\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1845/10000 (18%)\n",
      "\n",
      "0 -19 0.1845\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 2216/10000 (22%)\n",
      "\n",
      "0 -18 0.2216\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2515/10000 (25%)\n",
      "\n",
      "0 -17 0.2515\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 3391/10000 (34%)\n",
      "\n",
      "0 -16 0.3391\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3913/10000 (39%)\n",
      "\n",
      "0 -15 0.3913\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 4286/10000 (43%)\n",
      "\n",
      "0 -14 0.4286\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 4620/10000 (46%)\n",
      "\n",
      "0 -13 0.462\n",
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 4917/10000 (49%)\n",
      "\n",
      "0 -12 0.4917\n",
      "\n",
      "Test set: Average loss: 0.0146, Accuracy: 5362/10000 (54%)\n",
      "\n",
      "0 -11 0.5362\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 5782/10000 (58%)\n",
      "\n",
      "0 -10 0.5782\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 6267/10000 (63%)\n",
      "\n",
      "0 -9 0.6267\n",
      "\n",
      "Test set: Average loss: 0.0104, Accuracy: 6922/10000 (69%)\n",
      "\n",
      "0 -8 0.6922\n",
      "\n",
      "Test set: Average loss: 0.0092, Accuracy: 7293/10000 (73%)\n",
      "\n",
      "0 -7 0.7293\n",
      "\n",
      "Test set: Average loss: 0.0082, Accuracy: 7603/10000 (76%)\n",
      "\n",
      "0 -6 0.7603\n",
      "\n",
      "Test set: Average loss: 0.0072, Accuracy: 7918/10000 (79%)\n",
      "\n",
      "0 -5 0.7918\n",
      "\n",
      "Test set: Average loss: 0.0066, Accuracy: 8157/10000 (82%)\n",
      "\n",
      "0 -4 0.8157\n",
      "\n",
      "Test set: Average loss: 0.0066, Accuracy: 8173/10000 (82%)\n",
      "\n",
      "0 -3 0.8173\n",
      "\n",
      "Test set: Average loss: 0.0065, Accuracy: 8299/10000 (83%)\n",
      "\n",
      "0 -2 0.8299\n",
      "\n",
      "Test set: Average loss: 0.0062, Accuracy: 8398/10000 (84%)\n",
      "\n",
      "0 -1 0.8398\n",
      "\n",
      "Test set: Average loss: 0.0062, Accuracy: 8447/10000 (84%)\n",
      "\n",
      "0 0 0.8447\n",
      "\n",
      "Test set: Average loss: 0.0065, Accuracy: 8280/10000 (83%)\n",
      "\n",
      "0 1 0.828\n",
      "\n",
      "Test set: Average loss: 0.0067, Accuracy: 8178/10000 (82%)\n",
      "\n",
      "0 2 0.8178\n",
      "\n",
      "Test set: Average loss: 0.0075, Accuracy: 7991/10000 (80%)\n",
      "\n",
      "0 3 0.7991\n",
      "\n",
      "Test set: Average loss: 0.0078, Accuracy: 7771/10000 (78%)\n",
      "\n",
      "0 4 0.7771\n",
      "\n",
      "Test set: Average loss: 0.0087, Accuracy: 7486/10000 (75%)\n",
      "\n",
      "0 5 0.7486\n",
      "\n",
      "Test set: Average loss: 0.0091, Accuracy: 7289/10000 (73%)\n",
      "\n",
      "0 6 0.7289\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 7070/10000 (71%)\n",
      "\n",
      "0 7 0.707\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 6904/10000 (69%)\n",
      "\n",
      "0 8 0.6904\n",
      "\n",
      "Test set: Average loss: 0.0105, Accuracy: 6638/10000 (66%)\n",
      "\n",
      "0 9 0.6638\n",
      "\n",
      "Test set: Average loss: 0.0116, Accuracy: 6208/10000 (62%)\n",
      "\n",
      "0 10 0.6208\n",
      "\n",
      "Test set: Average loss: 0.0131, Accuracy: 5678/10000 (57%)\n",
      "\n",
      "0 11 0.5678\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 5122/10000 (51%)\n",
      "\n",
      "0 12 0.5122\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 4461/10000 (45%)\n",
      "\n",
      "0 13 0.4461\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 3874/10000 (39%)\n",
      "\n",
      "0 14 0.3874\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 3227/10000 (32%)\n",
      "\n",
      "0 15 0.3227\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2766/10000 (28%)\n",
      "\n",
      "0 16 0.2766\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2352/10000 (24%)\n",
      "\n",
      "0 17 0.2352\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 2011/10000 (20%)\n",
      "\n",
      "0 18 0.2011\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1693/10000 (17%)\n",
      "\n",
      "0 19 0.1693\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1563/10000 (16%)\n",
      "\n",
      "0 20 0.1563\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1449/10000 (14%)\n",
      "\n",
      "0 21 0.1449\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 737/10000 (7%)\n",
      "\n",
      "0 22 0.0737\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1244/10000 (12%)\n",
      "\n",
      "0 23 0.1244\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 899/10000 (9%)\n",
      "\n",
      "0 24 0.0899\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "0 25 0.115\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "0 26 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "0 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "1 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "1 -26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "1 -25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1156/10000 (12%)\n",
      "\n",
      "1 -24 0.1156\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1204/10000 (12%)\n",
      "\n",
      "1 -23 0.1204\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1268/10000 (13%)\n",
      "\n",
      "1 -22 0.1268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1401/10000 (14%)\n",
      "\n",
      "1 -21 0.1401\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1598/10000 (16%)\n",
      "\n",
      "1 -20 0.1598\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1837/10000 (18%)\n",
      "\n",
      "1 -19 0.1837\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1682/10000 (17%)\n",
      "\n",
      "1 -18 0.1682\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 2707/10000 (27%)\n",
      "\n",
      "1 -17 0.2707\n",
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 3270/10000 (33%)\n",
      "\n",
      "1 -16 0.327\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 3789/10000 (38%)\n",
      "\n",
      "1 -15 0.3789\n",
      "\n",
      "Test set: Average loss: 0.0177, Accuracy: 4144/10000 (41%)\n",
      "\n",
      "1 -14 0.4144\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 4522/10000 (45%)\n",
      "\n",
      "1 -13 0.4522\n",
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 4843/10000 (48%)\n",
      "\n",
      "1 -12 0.4843\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 5268/10000 (53%)\n",
      "\n",
      "1 -11 0.5268\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 5707/10000 (57%)\n",
      "\n",
      "1 -10 0.5707\n",
      "\n",
      "Test set: Average loss: 0.0123, Accuracy: 6262/10000 (63%)\n",
      "\n",
      "1 -9 0.6262\n",
      "\n",
      "Test set: Average loss: 0.0107, Accuracy: 6827/10000 (68%)\n",
      "\n",
      "1 -8 0.6827\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 7220/10000 (72%)\n",
      "\n",
      "1 -7 0.722\n",
      "\n",
      "Test set: Average loss: 0.0083, Accuracy: 7643/10000 (76%)\n",
      "\n",
      "1 -6 0.7643\n",
      "\n",
      "Test set: Average loss: 0.0072, Accuracy: 7896/10000 (79%)\n",
      "\n",
      "1 -5 0.7896\n",
      "\n",
      "Test set: Average loss: 0.0069, Accuracy: 8071/10000 (81%)\n",
      "\n",
      "1 -4 0.8071\n",
      "\n",
      "Test set: Average loss: 0.0066, Accuracy: 8233/10000 (82%)\n",
      "\n",
      "1 -3 0.8233\n",
      "\n",
      "Test set: Average loss: 0.0064, Accuracy: 8304/10000 (83%)\n",
      "\n",
      "1 -2 0.8304\n",
      "\n",
      "Test set: Average loss: 0.0060, Accuracy: 8428/10000 (84%)\n",
      "\n",
      "1 -1 0.8428\n",
      "\n",
      "Test set: Average loss: 0.0060, Accuracy: 8478/10000 (85%)\n",
      "\n",
      "1 0 0.8478\n",
      "\n",
      "Test set: Average loss: 0.0064, Accuracy: 8329/10000 (83%)\n",
      "\n",
      "1 1 0.8329\n",
      "\n",
      "Test set: Average loss: 0.0070, Accuracy: 8163/10000 (82%)\n",
      "\n",
      "1 2 0.8163\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7884/10000 (79%)\n",
      "\n",
      "1 3 0.7884\n",
      "\n",
      "Test set: Average loss: 0.0086, Accuracy: 7634/10000 (76%)\n",
      "\n",
      "1 4 0.7634\n",
      "\n",
      "Test set: Average loss: 0.0088, Accuracy: 7446/10000 (74%)\n",
      "\n",
      "1 5 0.7446\n",
      "\n",
      "Test set: Average loss: 0.0093, Accuracy: 7215/10000 (72%)\n",
      "\n",
      "1 6 0.7215\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 6981/10000 (70%)\n",
      "\n",
      "1 7 0.6981\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 6912/10000 (69%)\n",
      "\n",
      "1 8 0.6912\n",
      "\n",
      "Test set: Average loss: 0.0107, Accuracy: 6568/10000 (66%)\n",
      "\n",
      "1 9 0.6568\n",
      "\n",
      "Test set: Average loss: 0.0118, Accuracy: 6188/10000 (62%)\n",
      "\n",
      "1 10 0.6188\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 5628/10000 (56%)\n",
      "\n",
      "1 11 0.5628\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 5098/10000 (51%)\n",
      "\n",
      "1 12 0.5098\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 4628/10000 (46%)\n",
      "\n",
      "1 13 0.4628\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 3879/10000 (39%)\n",
      "\n",
      "1 14 0.3879\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 3256/10000 (33%)\n",
      "\n",
      "1 15 0.3256\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2759/10000 (28%)\n",
      "\n",
      "1 16 0.2759\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 2313/10000 (23%)\n",
      "\n",
      "1 17 0.2313\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1997/10000 (20%)\n",
      "\n",
      "1 18 0.1997\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1707/10000 (17%)\n",
      "\n",
      "1 19 0.1707\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1512/10000 (15%)\n",
      "\n",
      "1 20 0.1512\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1403/10000 (14%)\n",
      "\n",
      "1 21 0.1403\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1328/10000 (13%)\n",
      "\n",
      "1 22 0.1328\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1244/10000 (12%)\n",
      "\n",
      "1 23 0.1244\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1186/10000 (12%)\n",
      "\n",
      "1 24 0.1186\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1151/10000 (12%)\n",
      "\n",
      "1 25 0.1151\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "1 26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "1 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "2 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "2 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "2 -25 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "2 -24 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1201/10000 (12%)\n",
      "\n",
      "2 -23 0.1201\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1262/10000 (13%)\n",
      "\n",
      "2 -22 0.1262\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1391/10000 (14%)\n",
      "\n",
      "2 -21 0.1391\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1565/10000 (16%)\n",
      "\n",
      "2 -20 0.1565\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1846/10000 (18%)\n",
      "\n",
      "2 -19 0.1846\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 2202/10000 (22%)\n",
      "\n",
      "2 -18 0.2202\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2635/10000 (26%)\n",
      "\n",
      "2 -17 0.2635\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 3058/10000 (31%)\n",
      "\n",
      "2 -16 0.3058\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 3612/10000 (36%)\n",
      "\n",
      "2 -15 0.3612\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 3987/10000 (40%)\n",
      "\n",
      "2 -14 0.3987\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 4310/10000 (43%)\n",
      "\n",
      "2 -13 0.431\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4718/10000 (47%)\n",
      "\n",
      "2 -12 0.4718\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 5222/10000 (52%)\n",
      "\n",
      "2 -11 0.5222\n",
      "\n",
      "Test set: Average loss: 0.0138, Accuracy: 5682/10000 (57%)\n",
      "\n",
      "2 -10 0.5682\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 6117/10000 (61%)\n",
      "\n",
      "2 -9 0.6117\n",
      "\n",
      "Test set: Average loss: 0.0112, Accuracy: 6645/10000 (66%)\n",
      "\n",
      "2 -8 0.6645\n",
      "\n",
      "Test set: Average loss: 0.0101, Accuracy: 7101/10000 (71%)\n",
      "\n",
      "2 -7 0.7101\n",
      "\n",
      "Test set: Average loss: 0.0089, Accuracy: 7434/10000 (74%)\n",
      "\n",
      "2 -6 0.7434\n",
      "\n",
      "Test set: Average loss: 0.0080, Accuracy: 7784/10000 (78%)\n",
      "\n",
      "2 -5 0.7784\n",
      "\n",
      "Test set: Average loss: 0.0071, Accuracy: 8052/10000 (81%)\n",
      "\n",
      "2 -4 0.8052\n",
      "\n",
      "Test set: Average loss: 0.0070, Accuracy: 8138/10000 (81%)\n",
      "\n",
      "2 -3 0.8138\n",
      "\n",
      "Test set: Average loss: 0.0067, Accuracy: 8231/10000 (82%)\n",
      "\n",
      "2 -2 0.8231\n",
      "\n",
      "Test set: Average loss: 0.0063, Accuracy: 8350/10000 (84%)\n",
      "\n",
      "2 -1 0.835\n",
      "\n",
      "Test set: Average loss: 0.0061, Accuracy: 8372/10000 (84%)\n",
      "\n",
      "2 0 0.8372\n",
      "\n",
      "Test set: Average loss: 0.0069, Accuracy: 8219/10000 (82%)\n",
      "\n",
      "2 1 0.8219\n",
      "\n",
      "Test set: Average loss: 0.0073, Accuracy: 8018/10000 (80%)\n",
      "\n",
      "2 2 0.8018\n",
      "\n",
      "Test set: Average loss: 0.0084, Accuracy: 7741/10000 (77%)\n",
      "\n",
      "2 3 0.7741\n",
      "\n",
      "Test set: Average loss: 0.0091, Accuracy: 7422/10000 (74%)\n",
      "\n",
      "2 4 0.7422\n",
      "\n",
      "Test set: Average loss: 0.0092, Accuracy: 7274/10000 (73%)\n",
      "\n",
      "2 5 0.7274\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 6954/10000 (70%)\n",
      "\n",
      "2 6 0.6954\n",
      "\n",
      "Test set: Average loss: 0.0102, Accuracy: 6783/10000 (68%)\n",
      "\n",
      "2 7 0.6783\n",
      "\n",
      "Test set: Average loss: 0.0108, Accuracy: 6575/10000 (66%)\n",
      "\n",
      "2 8 0.6575\n",
      "\n",
      "Test set: Average loss: 0.0113, Accuracy: 6369/10000 (64%)\n",
      "\n",
      "2 9 0.6369\n",
      "\n",
      "Test set: Average loss: 0.0124, Accuracy: 5990/10000 (60%)\n",
      "\n",
      "2 10 0.599\n",
      "\n",
      "Test set: Average loss: 0.0137, Accuracy: 5528/10000 (55%)\n",
      "\n",
      "2 11 0.5528\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 5088/10000 (51%)\n",
      "\n",
      "2 12 0.5088\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 4419/10000 (44%)\n",
      "\n",
      "2 13 0.4419\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3776/10000 (38%)\n",
      "\n",
      "2 14 0.3776\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 3166/10000 (32%)\n",
      "\n",
      "2 15 0.3166\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2625/10000 (26%)\n",
      "\n",
      "2 16 0.2625\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2254/10000 (23%)\n",
      "\n",
      "2 17 0.2254\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1879/10000 (19%)\n",
      "\n",
      "2 18 0.1879\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1700/10000 (17%)\n",
      "\n",
      "2 19 0.17\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1481/10000 (15%)\n",
      "\n",
      "2 20 0.1481\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1397/10000 (14%)\n",
      "\n",
      "2 21 0.1397\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1290/10000 (13%)\n",
      "\n",
      "2 22 0.129\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1225/10000 (12%)\n",
      "\n",
      "2 23 0.1225\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1187/10000 (12%)\n",
      "\n",
      "2 24 0.1187\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1151/10000 (12%)\n",
      "\n",
      "2 25 0.1151\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "2 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "2 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0247, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "3 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "3 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "3 -25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1163/10000 (12%)\n",
      "\n",
      "3 -24 0.1163\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1189/10000 (12%)\n",
      "\n",
      "3 -23 0.1189\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 948/10000 (9%)\n",
      "\n",
      "3 -22 0.0948\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1388/10000 (14%)\n",
      "\n",
      "3 -21 0.1388\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1569/10000 (16%)\n",
      "\n",
      "3 -20 0.1569\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1853/10000 (19%)\n",
      "\n",
      "3 -19 0.1853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 2121/10000 (21%)\n",
      "\n",
      "3 -18 0.2121\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2518/10000 (25%)\n",
      "\n",
      "3 -17 0.2518\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2953/10000 (30%)\n",
      "\n",
      "3 -16 0.2953\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 3335/10000 (33%)\n",
      "\n",
      "3 -15 0.3335\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3891/10000 (39%)\n",
      "\n",
      "3 -14 0.3891\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 4253/10000 (43%)\n",
      "\n",
      "3 -13 0.4253\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 4732/10000 (47%)\n",
      "\n",
      "3 -12 0.4732\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 5173/10000 (52%)\n",
      "\n",
      "3 -11 0.5173\n",
      "\n",
      "Test set: Average loss: 0.0144, Accuracy: 5530/10000 (55%)\n",
      "\n",
      "3 -10 0.553\n",
      "\n",
      "Test set: Average loss: 0.0135, Accuracy: 5926/10000 (59%)\n",
      "\n",
      "3 -9 0.5926\n",
      "\n",
      "Test set: Average loss: 0.0121, Accuracy: 6425/10000 (64%)\n",
      "\n",
      "3 -8 0.6425\n",
      "\n",
      "Test set: Average loss: 0.0111, Accuracy: 6851/10000 (69%)\n",
      "\n",
      "3 -7 0.6851\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 7273/10000 (73%)\n",
      "\n",
      "3 -6 0.7273\n",
      "\n",
      "Test set: Average loss: 0.0087, Accuracy: 7574/10000 (76%)\n",
      "\n",
      "3 -5 0.7574\n",
      "\n",
      "Test set: Average loss: 0.0080, Accuracy: 7769/10000 (78%)\n",
      "\n",
      "3 -4 0.7769\n",
      "\n",
      "Test set: Average loss: 0.0074, Accuracy: 7937/10000 (79%)\n",
      "\n",
      "3 -3 0.7937\n",
      "\n",
      "Test set: Average loss: 0.0071, Accuracy: 8066/10000 (81%)\n",
      "\n",
      "3 -2 0.8066\n",
      "\n",
      "Test set: Average loss: 0.0071, Accuracy: 8084/10000 (81%)\n",
      "\n",
      "3 -1 0.8084\n",
      "\n",
      "Test set: Average loss: 0.0069, Accuracy: 8184/10000 (82%)\n",
      "\n",
      "3 0 0.8184\n",
      "\n",
      "Test set: Average loss: 0.0073, Accuracy: 8065/10000 (81%)\n",
      "\n",
      "3 1 0.8065\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7827/10000 (78%)\n",
      "\n",
      "3 2 0.7827\n",
      "\n",
      "Test set: Average loss: 0.0087, Accuracy: 7572/10000 (76%)\n",
      "\n",
      "3 3 0.7572\n",
      "\n",
      "Test set: Average loss: 0.0094, Accuracy: 7300/10000 (73%)\n",
      "\n",
      "3 4 0.73\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 7048/10000 (70%)\n",
      "\n",
      "3 5 0.7048\n",
      "\n",
      "Test set: Average loss: 0.0102, Accuracy: 6921/10000 (69%)\n",
      "\n",
      "3 6 0.6921\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6662/10000 (67%)\n",
      "\n",
      "3 7 0.6662\n",
      "\n",
      "Test set: Average loss: 0.0111, Accuracy: 6474/10000 (65%)\n",
      "\n",
      "3 8 0.6474\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 6097/10000 (61%)\n",
      "\n",
      "3 9 0.6097\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 5775/10000 (58%)\n",
      "\n",
      "3 10 0.5775\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 5328/10000 (53%)\n",
      "\n",
      "3 11 0.5328\n",
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 4823/10000 (48%)\n",
      "\n",
      "3 12 0.4823\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 4209/10000 (42%)\n",
      "\n",
      "3 13 0.4209\n",
      "\n",
      "Test set: Average loss: 0.0189, Accuracy: 3592/10000 (36%)\n",
      "\n",
      "3 14 0.3592\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 3069/10000 (31%)\n",
      "\n",
      "3 15 0.3069\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2464/10000 (25%)\n",
      "\n",
      "3 16 0.2464\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 2109/10000 (21%)\n",
      "\n",
      "3 17 0.2109\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1852/10000 (19%)\n",
      "\n",
      "3 18 0.1852\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1580/10000 (16%)\n",
      "\n",
      "3 19 0.158\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1466/10000 (15%)\n",
      "\n",
      "3 20 0.1466\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1344/10000 (13%)\n",
      "\n",
      "3 21 0.1344\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1294/10000 (13%)\n",
      "\n",
      "3 22 0.1294\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1231/10000 (12%)\n",
      "\n",
      "3 23 0.1231\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1169/10000 (12%)\n",
      "\n",
      "3 24 0.1169\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "3 25 0.115\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "3 26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "3 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0242, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "4 -27 0.101\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "4 -26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "4 -25 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1157/10000 (12%)\n",
      "\n",
      "4 -24 0.1157\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1200/10000 (12%)\n",
      "\n",
      "4 -23 0.12\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1282/10000 (13%)\n",
      "\n",
      "4 -22 0.1282\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1416/10000 (14%)\n",
      "\n",
      "4 -21 0.1416\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1588/10000 (16%)\n",
      "\n",
      "4 -20 0.1588\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1827/10000 (18%)\n",
      "\n",
      "4 -19 0.1827\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 2069/10000 (21%)\n",
      "\n",
      "4 -18 0.2069\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 2337/10000 (23%)\n",
      "\n",
      "4 -17 0.2337\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 2692/10000 (27%)\n",
      "\n",
      "4 -16 0.2692\n",
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 3144/10000 (31%)\n",
      "\n",
      "4 -15 0.3144\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 3627/10000 (36%)\n",
      "\n",
      "4 -14 0.3627\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 4028/10000 (40%)\n",
      "\n",
      "4 -13 0.4028\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 4457/10000 (45%)\n",
      "\n",
      "4 -12 0.4457\n",
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 4842/10000 (48%)\n",
      "\n",
      "4 -11 0.4842\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 5222/10000 (52%)\n",
      "\n",
      "4 -10 0.5222\n",
      "\n",
      "Test set: Average loss: 0.0142, Accuracy: 5587/10000 (56%)\n",
      "\n",
      "4 -9 0.5587\n",
      "\n",
      "Test set: Average loss: 0.0127, Accuracy: 6156/10000 (62%)\n",
      "\n",
      "4 -8 0.6156\n",
      "\n",
      "Test set: Average loss: 0.0115, Accuracy: 6576/10000 (66%)\n",
      "\n",
      "4 -7 0.6576\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 7003/10000 (70%)\n",
      "\n",
      "4 -6 0.7003\n",
      "\n",
      "Test set: Average loss: 0.0093, Accuracy: 7297/10000 (73%)\n",
      "\n",
      "4 -5 0.7297\n",
      "\n",
      "Test set: Average loss: 0.0088, Accuracy: 7496/10000 (75%)\n",
      "\n",
      "4 -4 0.7496\n",
      "\n",
      "Test set: Average loss: 0.0083, Accuracy: 7693/10000 (77%)\n",
      "\n",
      "4 -3 0.7693\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7769/10000 (78%)\n",
      "\n",
      "4 -2 0.7769\n",
      "\n",
      "Test set: Average loss: 0.0078, Accuracy: 7862/10000 (79%)\n",
      "\n",
      "4 -1 0.7862\n",
      "\n",
      "Test set: Average loss: 0.0078, Accuracy: 7924/10000 (79%)\n",
      "\n",
      "4 0 0.7924\n",
      "\n",
      "Test set: Average loss: 0.0079, Accuracy: 7845/10000 (78%)\n",
      "\n",
      "4 1 0.7845\n",
      "\n",
      "Test set: Average loss: 0.0081, Accuracy: 7701/10000 (77%)\n",
      "\n",
      "4 2 0.7701\n",
      "\n",
      "Test set: Average loss: 0.0091, Accuracy: 7397/10000 (74%)\n",
      "\n",
      "4 3 0.7397\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 7161/10000 (72%)\n",
      "\n",
      "4 4 0.7161\n",
      "\n",
      "Test set: Average loss: 0.0102, Accuracy: 6942/10000 (69%)\n",
      "\n",
      "4 5 0.6942\n",
      "\n",
      "Test set: Average loss: 0.0108, Accuracy: 6679/10000 (67%)\n",
      "\n",
      "4 6 0.6679\n",
      "\n",
      "Test set: Average loss: 0.0112, Accuracy: 6454/10000 (65%)\n",
      "\n",
      "4 7 0.6454\n",
      "\n",
      "Test set: Average loss: 0.0119, Accuracy: 6139/10000 (61%)\n",
      "\n",
      "4 8 0.6139\n",
      "\n",
      "Test set: Average loss: 0.0127, Accuracy: 5849/10000 (58%)\n",
      "\n",
      "4 9 0.5849\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 5412/10000 (54%)\n",
      "\n",
      "4 10 0.5412\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4931/10000 (49%)\n",
      "\n",
      "4 11 0.4931\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 4463/10000 (45%)\n",
      "\n",
      "4 12 0.4463\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 3827/10000 (38%)\n",
      "\n",
      "4 13 0.3827\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 3403/10000 (34%)\n",
      "\n",
      "4 14 0.3403\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2926/10000 (29%)\n",
      "\n",
      "4 15 0.2926\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 2458/10000 (25%)\n",
      "\n",
      "4 16 0.2458\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 2088/10000 (21%)\n",
      "\n",
      "4 17 0.2088\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1741/10000 (17%)\n",
      "\n",
      "4 18 0.1741\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1585/10000 (16%)\n",
      "\n",
      "4 19 0.1585\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1420/10000 (14%)\n",
      "\n",
      "4 20 0.142\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1339/10000 (13%)\n",
      "\n",
      "4 21 0.1339\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1266/10000 (13%)\n",
      "\n",
      "4 22 0.1266\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1207/10000 (12%)\n",
      "\n",
      "4 23 0.1207\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1166/10000 (12%)\n",
      "\n",
      "4 24 0.1166\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1146/10000 (11%)\n",
      "\n",
      "4 25 0.1146\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "4 26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "4 27 0.101\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "5 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "5 -26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "5 -25 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1154/10000 (12%)\n",
      "\n",
      "5 -24 0.1154\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1180/10000 (12%)\n",
      "\n",
      "5 -23 0.118\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1276/10000 (13%)\n",
      "\n",
      "5 -22 0.1276\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1406/10000 (14%)\n",
      "\n",
      "5 -21 0.1406\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1528/10000 (15%)\n",
      "\n",
      "5 -20 0.1528\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1772/10000 (18%)\n",
      "\n",
      "5 -19 0.1772\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1969/10000 (20%)\n",
      "\n",
      "5 -18 0.1969\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 2302/10000 (23%)\n",
      "\n",
      "5 -17 0.2302\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2601/10000 (26%)\n",
      "\n",
      "5 -16 0.2601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 3087/10000 (31%)\n",
      "\n",
      "5 -15 0.3087\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 3439/10000 (34%)\n",
      "\n",
      "5 -14 0.3439\n",
      "\n",
      "Test set: Average loss: 0.0182, Accuracy: 3823/10000 (38%)\n",
      "\n",
      "5 -13 0.3823\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 4244/10000 (42%)\n",
      "\n",
      "5 -12 0.4244\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4718/10000 (47%)\n",
      "\n",
      "5 -11 0.4718\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 5057/10000 (51%)\n",
      "\n",
      "5 -10 0.5057\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 5518/10000 (55%)\n",
      "\n",
      "5 -9 0.5518\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 5941/10000 (59%)\n",
      "\n",
      "5 -8 0.5941\n",
      "\n",
      "Test set: Average loss: 0.0119, Accuracy: 6420/10000 (64%)\n",
      "\n",
      "5 -7 0.642\n",
      "\n",
      "Test set: Average loss: 0.0110, Accuracy: 6796/10000 (68%)\n",
      "\n",
      "5 -6 0.6796\n",
      "\n",
      "Test set: Average loss: 0.0104, Accuracy: 6979/10000 (70%)\n",
      "\n",
      "5 -5 0.6979\n",
      "\n",
      "Test set: Average loss: 0.0096, Accuracy: 7230/10000 (72%)\n",
      "\n",
      "5 -4 0.723\n",
      "\n",
      "Test set: Average loss: 0.0090, Accuracy: 7469/10000 (75%)\n",
      "\n",
      "5 -3 0.7469\n",
      "\n",
      "Test set: Average loss: 0.0090, Accuracy: 7460/10000 (75%)\n",
      "\n",
      "5 -2 0.746\n",
      "\n",
      "Test set: Average loss: 0.0088, Accuracy: 7516/10000 (75%)\n",
      "\n",
      "5 -1 0.7516\n",
      "\n",
      "Test set: Average loss: 0.0085, Accuracy: 7596/10000 (76%)\n",
      "\n",
      "5 0 0.7596\n",
      "\n",
      "Test set: Average loss: 0.0086, Accuracy: 7531/10000 (75%)\n",
      "\n",
      "5 1 0.7531\n",
      "\n",
      "Test set: Average loss: 0.0091, Accuracy: 7331/10000 (73%)\n",
      "\n",
      "5 2 0.7331\n",
      "\n",
      "Test set: Average loss: 0.0098, Accuracy: 7173/10000 (72%)\n",
      "\n",
      "5 3 0.7173\n",
      "\n",
      "Test set: Average loss: 0.0104, Accuracy: 6899/10000 (69%)\n",
      "\n",
      "5 4 0.6899\n",
      "\n",
      "Test set: Average loss: 0.0107, Accuracy: 6740/10000 (67%)\n",
      "\n",
      "5 5 0.674\n",
      "\n",
      "Test set: Average loss: 0.0113, Accuracy: 6505/10000 (65%)\n",
      "\n",
      "5 6 0.6505\n",
      "\n",
      "Test set: Average loss: 0.0116, Accuracy: 6227/10000 (62%)\n",
      "\n",
      "5 7 0.6227\n",
      "\n",
      "Test set: Average loss: 0.0126, Accuracy: 5932/10000 (59%)\n",
      "\n",
      "5 8 0.5932\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5499/10000 (55%)\n",
      "\n",
      "5 9 0.5499\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 5027/10000 (50%)\n",
      "\n",
      "5 10 0.5027\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 4598/10000 (46%)\n",
      "\n",
      "5 11 0.4598\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 4197/10000 (42%)\n",
      "\n",
      "5 12 0.4197\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 3653/10000 (37%)\n",
      "\n",
      "5 13 0.3653\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 3231/10000 (32%)\n",
      "\n",
      "5 14 0.3231\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2785/10000 (28%)\n",
      "\n",
      "5 15 0.2785\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 2410/10000 (24%)\n",
      "\n",
      "5 16 0.241\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1454/10000 (15%)\n",
      "\n",
      "5 17 0.1454\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1746/10000 (17%)\n",
      "\n",
      "5 18 0.1746\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1540/10000 (15%)\n",
      "\n",
      "5 19 0.154\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1383/10000 (14%)\n",
      "\n",
      "5 20 0.1383\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1297/10000 (13%)\n",
      "\n",
      "5 21 0.1297\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1243/10000 (12%)\n",
      "\n",
      "5 22 0.1243\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1211/10000 (12%)\n",
      "\n",
      "5 23 0.1211\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1163/10000 (12%)\n",
      "\n",
      "5 24 0.1163\n",
      "\n",
      "Test set: Average loss: 0.0239, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "5 25 0.114\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "5 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "5 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "6 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "6 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "6 -25 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1160/10000 (12%)\n",
      "\n",
      "6 -24 0.116\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1184/10000 (12%)\n",
      "\n",
      "6 -23 0.1184\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1265/10000 (13%)\n",
      "\n",
      "6 -22 0.1265\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1375/10000 (14%)\n",
      "\n",
      "6 -21 0.1375\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1494/10000 (15%)\n",
      "\n",
      "6 -20 0.1494\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1087/10000 (11%)\n",
      "\n",
      "6 -19 0.1087\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 2033/10000 (20%)\n",
      "\n",
      "6 -18 0.2033\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 2294/10000 (23%)\n",
      "\n",
      "6 -17 0.2294\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2609/10000 (26%)\n",
      "\n",
      "6 -16 0.2609\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2891/10000 (29%)\n",
      "\n",
      "6 -15 0.2891\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 3268/10000 (33%)\n",
      "\n",
      "6 -14 0.3268\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 3564/10000 (36%)\n",
      "\n",
      "6 -13 0.3564\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 4053/10000 (41%)\n",
      "\n",
      "6 -12 0.4053\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 4405/10000 (44%)\n",
      "\n",
      "6 -11 0.4405\n",
      "\n",
      "Test set: Average loss: 0.0156, Accuracy: 4894/10000 (49%)\n",
      "\n",
      "6 -10 0.4894\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 5320/10000 (53%)\n",
      "\n",
      "6 -9 0.532\n",
      "\n",
      "Test set: Average loss: 0.0133, Accuracy: 5850/10000 (58%)\n",
      "\n",
      "6 -8 0.585\n",
      "\n",
      "Test set: Average loss: 0.0125, Accuracy: 6183/10000 (62%)\n",
      "\n",
      "6 -7 0.6183\n",
      "\n",
      "Test set: Average loss: 0.0114, Accuracy: 6554/10000 (66%)\n",
      "\n",
      "6 -6 0.6554\n",
      "\n",
      "Test set: Average loss: 0.0110, Accuracy: 6751/10000 (68%)\n",
      "\n",
      "6 -5 0.6751\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6873/10000 (69%)\n",
      "\n",
      "6 -4 0.6873\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 7057/10000 (71%)\n",
      "\n",
      "6 -3 0.7057\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 7150/10000 (72%)\n",
      "\n",
      "6 -2 0.715\n",
      "\n",
      "Test set: Average loss: 0.0094, Accuracy: 7258/10000 (73%)\n",
      "\n",
      "6 -1 0.7258\n",
      "\n",
      "Test set: Average loss: 0.0095, Accuracy: 7213/10000 (72%)\n",
      "\n",
      "6 0 0.7213\n",
      "\n",
      "Test set: Average loss: 0.0097, Accuracy: 7113/10000 (71%)\n",
      "\n",
      "6 1 0.7113\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 7015/10000 (70%)\n",
      "\n",
      "6 2 0.7015\n",
      "\n",
      "Test set: Average loss: 0.0105, Accuracy: 6879/10000 (69%)\n",
      "\n",
      "6 3 0.6879\n",
      "\n",
      "Test set: Average loss: 0.0111, Accuracy: 6589/10000 (66%)\n",
      "\n",
      "6 4 0.6589\n",
      "\n",
      "Test set: Average loss: 0.0116, Accuracy: 6340/10000 (63%)\n",
      "\n",
      "6 5 0.634\n",
      "\n",
      "Test set: Average loss: 0.0119, Accuracy: 6131/10000 (61%)\n",
      "\n",
      "6 6 0.6131\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 5803/10000 (58%)\n",
      "\n",
      "6 7 0.5803\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5485/10000 (55%)\n",
      "\n",
      "6 8 0.5485\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 5087/10000 (51%)\n",
      "\n",
      "6 9 0.5087\n",
      "\n",
      "Test set: Average loss: 0.0156, Accuracy: 4707/10000 (47%)\n",
      "\n",
      "6 10 0.4707\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 4286/10000 (43%)\n",
      "\n",
      "6 11 0.4286\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 4028/10000 (40%)\n",
      "\n",
      "6 12 0.4028\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 3662/10000 (37%)\n",
      "\n",
      "6 13 0.3662\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 3182/10000 (32%)\n",
      "\n",
      "6 14 0.3182\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2743/10000 (27%)\n",
      "\n",
      "6 15 0.2743\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 2308/10000 (23%)\n",
      "\n",
      "6 16 0.2308\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1984/10000 (20%)\n",
      "\n",
      "6 17 0.1984\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1742/10000 (17%)\n",
      "\n",
      "6 18 0.1742\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1500/10000 (15%)\n",
      "\n",
      "6 19 0.15\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1385/10000 (14%)\n",
      "\n",
      "6 20 0.1385\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1284/10000 (13%)\n",
      "\n",
      "6 21 0.1284\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1252/10000 (13%)\n",
      "\n",
      "6 22 0.1252\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1199/10000 (12%)\n",
      "\n",
      "6 23 0.1199\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1169/10000 (12%)\n",
      "\n",
      "6 24 0.1169\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "6 25 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "6 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "6 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "7 -27 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "7 -26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "7 -25 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "7 -24 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1188/10000 (12%)\n",
      "\n",
      "7 -23 0.1188\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1231/10000 (12%)\n",
      "\n",
      "7 -22 0.1231\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1335/10000 (13%)\n",
      "\n",
      "7 -21 0.1335\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1535/10000 (15%)\n",
      "\n",
      "7 -20 0.1535\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1748/10000 (17%)\n",
      "\n",
      "7 -19 0.1748\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1947/10000 (19%)\n",
      "\n",
      "7 -18 0.1947\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 2257/10000 (23%)\n",
      "\n",
      "7 -17 0.2257\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2565/10000 (26%)\n",
      "\n",
      "7 -16 0.2565\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2804/10000 (28%)\n",
      "\n",
      "7 -15 0.2804\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 3107/10000 (31%)\n",
      "\n",
      "7 -14 0.3107\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 3252/10000 (33%)\n",
      "\n",
      "7 -13 0.3252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3673/10000 (37%)\n",
      "\n",
      "7 -12 0.3673\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 4144/10000 (41%)\n",
      "\n",
      "7 -11 0.4144\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4648/10000 (46%)\n",
      "\n",
      "7 -10 0.4648\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 5193/10000 (52%)\n",
      "\n",
      "7 -9 0.5193\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5650/10000 (56%)\n",
      "\n",
      "7 -8 0.565\n",
      "\n",
      "Test set: Average loss: 0.0131, Accuracy: 5889/10000 (59%)\n",
      "\n",
      "7 -7 0.5889\n",
      "\n",
      "Test set: Average loss: 0.0123, Accuracy: 6175/10000 (62%)\n",
      "\n",
      "7 -6 0.6175\n",
      "\n",
      "Test set: Average loss: 0.0118, Accuracy: 6445/10000 (64%)\n",
      "\n",
      "7 -5 0.6445\n",
      "\n",
      "Test set: Average loss: 0.0113, Accuracy: 6630/10000 (66%)\n",
      "\n",
      "7 -4 0.663\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6778/10000 (68%)\n",
      "\n",
      "7 -3 0.6778\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 6939/10000 (69%)\n",
      "\n",
      "7 -2 0.6939\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 6998/10000 (70%)\n",
      "\n",
      "7 -1 0.6998\n",
      "\n",
      "Test set: Average loss: 0.0099, Accuracy: 6937/10000 (69%)\n",
      "\n",
      "7 0 0.6937\n",
      "\n",
      "Test set: Average loss: 0.0101, Accuracy: 6915/10000 (69%)\n",
      "\n",
      "7 1 0.6915\n",
      "\n",
      "Test set: Average loss: 0.0102, Accuracy: 6836/10000 (68%)\n",
      "\n",
      "7 2 0.6836\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6610/10000 (66%)\n",
      "\n",
      "7 3 0.661\n",
      "\n",
      "Test set: Average loss: 0.0114, Accuracy: 6362/10000 (64%)\n",
      "\n",
      "7 4 0.6362\n",
      "\n",
      "Test set: Average loss: 0.0118, Accuracy: 6209/10000 (62%)\n",
      "\n",
      "7 5 0.6209\n",
      "\n",
      "Test set: Average loss: 0.0123, Accuracy: 5832/10000 (58%)\n",
      "\n",
      "7 6 0.5832\n",
      "\n",
      "Test set: Average loss: 0.0133, Accuracy: 5544/10000 (55%)\n",
      "\n",
      "7 7 0.5544\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 5201/10000 (52%)\n",
      "\n",
      "7 8 0.5201\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4774/10000 (48%)\n",
      "\n",
      "7 9 0.4774\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 4548/10000 (45%)\n",
      "\n",
      "7 10 0.4548\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 4191/10000 (42%)\n",
      "\n",
      "7 11 0.4191\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3949/10000 (39%)\n",
      "\n",
      "7 12 0.3949\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 3530/10000 (35%)\n",
      "\n",
      "7 13 0.353\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 3096/10000 (31%)\n",
      "\n",
      "7 14 0.3096\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2619/10000 (26%)\n",
      "\n",
      "7 15 0.2619\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2315/10000 (23%)\n",
      "\n",
      "7 16 0.2315\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1940/10000 (19%)\n",
      "\n",
      "7 17 0.194\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1713/10000 (17%)\n",
      "\n",
      "7 18 0.1713\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1506/10000 (15%)\n",
      "\n",
      "7 19 0.1506\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1399/10000 (14%)\n",
      "\n",
      "7 20 0.1399\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1308/10000 (13%)\n",
      "\n",
      "7 21 0.1308\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1234/10000 (12%)\n",
      "\n",
      "7 22 0.1234\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1203/10000 (12%)\n",
      "\n",
      "7 23 0.1203\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1158/10000 (12%)\n",
      "\n",
      "7 24 0.1158\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "7 25 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "7 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "7 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "8 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "8 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "8 -25 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0240, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "8 -24 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1174/10000 (12%)\n",
      "\n",
      "8 -23 0.1174\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1231/10000 (12%)\n",
      "\n",
      "8 -22 0.1231\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1297/10000 (13%)\n",
      "\n",
      "8 -21 0.1297\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1425/10000 (14%)\n",
      "\n",
      "8 -20 0.1425\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 988/10000 (10%)\n",
      "\n",
      "8 -19 0.0988\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1913/10000 (19%)\n",
      "\n",
      "8 -18 0.1913\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 2220/10000 (22%)\n",
      "\n",
      "8 -17 0.222\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 2513/10000 (25%)\n",
      "\n",
      "8 -16 0.2513\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2690/10000 (27%)\n",
      "\n",
      "8 -15 0.269\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2934/10000 (29%)\n",
      "\n",
      "8 -14 0.2934\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 3242/10000 (32%)\n",
      "\n",
      "8 -13 0.3242\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 3465/10000 (35%)\n",
      "\n",
      "8 -12 0.3465\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3824/10000 (38%)\n",
      "\n",
      "8 -11 0.3824\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 4338/10000 (43%)\n",
      "\n",
      "8 -10 0.4338\n",
      "\n",
      "Test set: Average loss: 0.0155, Accuracy: 4837/10000 (48%)\n",
      "\n",
      "8 -9 0.4837\n",
      "\n",
      "Test set: Average loss: 0.0147, Accuracy: 5186/10000 (52%)\n",
      "\n",
      "8 -8 0.5186\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 5538/10000 (55%)\n",
      "\n",
      "8 -7 0.5538\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 5795/10000 (58%)\n",
      "\n",
      "8 -6 0.5795\n",
      "\n",
      "Test set: Average loss: 0.0125, Accuracy: 6055/10000 (61%)\n",
      "\n",
      "8 -5 0.6055\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 6310/10000 (63%)\n",
      "\n",
      "8 -4 0.631\n",
      "\n",
      "Test set: Average loss: 0.0109, Accuracy: 6619/10000 (66%)\n",
      "\n",
      "8 -3 0.6619\n",
      "\n",
      "Test set: Average loss: 0.0105, Accuracy: 6690/10000 (67%)\n",
      "\n",
      "8 -2 0.669\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 6754/10000 (68%)\n",
      "\n",
      "8 -1 0.6754\n",
      "\n",
      "Test set: Average loss: 0.0102, Accuracy: 6828/10000 (68%)\n",
      "\n",
      "8 0 0.6828\n",
      "\n",
      "Test set: Average loss: 0.0102, Accuracy: 6762/10000 (68%)\n",
      "\n",
      "8 1 0.6762\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6535/10000 (65%)\n",
      "\n",
      "8 2 0.6535\n",
      "\n",
      "Test set: Average loss: 0.0111, Accuracy: 6379/10000 (64%)\n",
      "\n",
      "8 3 0.6379\n",
      "\n",
      "Test set: Average loss: 0.0115, Accuracy: 6146/10000 (61%)\n",
      "\n",
      "8 4 0.6146\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 5878/10000 (59%)\n",
      "\n",
      "8 5 0.5878\n",
      "\n",
      "Test set: Average loss: 0.0130, Accuracy: 5580/10000 (56%)\n",
      "\n",
      "8 6 0.558\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 5191/10000 (52%)\n",
      "\n",
      "8 7 0.5191\n",
      "\n",
      "Test set: Average loss: 0.0149, Accuracy: 4842/10000 (48%)\n",
      "\n",
      "8 8 0.4842\n",
      "\n",
      "Test set: Average loss: 0.0157, Accuracy: 4655/10000 (47%)\n",
      "\n",
      "8 9 0.4655\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 4357/10000 (44%)\n",
      "\n",
      "8 10 0.4357\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 4141/10000 (41%)\n",
      "\n",
      "8 11 0.4141\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3716/10000 (37%)\n",
      "\n",
      "8 12 0.3716\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 3381/10000 (34%)\n",
      "\n",
      "8 13 0.3381\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2929/10000 (29%)\n",
      "\n",
      "8 14 0.2929\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2490/10000 (25%)\n",
      "\n",
      "8 15 0.249\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2230/10000 (22%)\n",
      "\n",
      "8 16 0.223\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1935/10000 (19%)\n",
      "\n",
      "8 17 0.1935\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1713/10000 (17%)\n",
      "\n",
      "8 18 0.1713\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1519/10000 (15%)\n",
      "\n",
      "8 19 0.1519\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1396/10000 (14%)\n",
      "\n",
      "8 20 0.1396\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1305/10000 (13%)\n",
      "\n",
      "8 21 0.1305\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1240/10000 (12%)\n",
      "\n",
      "8 22 0.124\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1189/10000 (12%)\n",
      "\n",
      "8 23 0.1189\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1154/10000 (12%)\n",
      "\n",
      "8 24 0.1154\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "8 25 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "8 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "8 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "9 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "9 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "9 -25 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "9 -24 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1170/10000 (12%)\n",
      "\n",
      "9 -23 0.117\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1202/10000 (12%)\n",
      "\n",
      "9 -22 0.1202\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1277/10000 (13%)\n",
      "\n",
      "9 -21 0.1277\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1389/10000 (14%)\n",
      "\n",
      "9 -20 0.1389\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1583/10000 (16%)\n",
      "\n",
      "9 -19 0.1583\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1839/10000 (18%)\n",
      "\n",
      "9 -18 0.1839\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 2126/10000 (21%)\n",
      "\n",
      "9 -17 0.2126\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2376/10000 (24%)\n",
      "\n",
      "9 -16 0.2376\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 2635/10000 (26%)\n",
      "\n",
      "9 -15 0.2635\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2811/10000 (28%)\n",
      "\n",
      "9 -14 0.2811\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2999/10000 (30%)\n",
      "\n",
      "9 -13 0.2999\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 3264/10000 (33%)\n",
      "\n",
      "9 -12 0.3264\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3636/10000 (36%)\n",
      "\n",
      "9 -11 0.3636\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 4097/10000 (41%)\n",
      "\n",
      "9 -10 0.4097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 4501/10000 (45%)\n",
      "\n",
      "9 -9 0.4501\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4877/10000 (49%)\n",
      "\n",
      "9 -8 0.4877\n",
      "\n",
      "Test set: Average loss: 0.0144, Accuracy: 5211/10000 (52%)\n",
      "\n",
      "9 -7 0.5211\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5543/10000 (55%)\n",
      "\n",
      "9 -6 0.5543\n",
      "\n",
      "Test set: Average loss: 0.0128, Accuracy: 5817/10000 (58%)\n",
      "\n",
      "9 -5 0.5817\n",
      "\n",
      "Test set: Average loss: 0.0120, Accuracy: 6127/10000 (61%)\n",
      "\n",
      "9 -4 0.6127\n",
      "\n",
      "Test set: Average loss: 0.0113, Accuracy: 6328/10000 (63%)\n",
      "\n",
      "9 -3 0.6328\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6569/10000 (66%)\n",
      "\n",
      "9 -2 0.6569\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6539/10000 (65%)\n",
      "\n",
      "9 -1 0.6539\n",
      "\n",
      "Test set: Average loss: 0.0106, Accuracy: 6567/10000 (66%)\n",
      "\n",
      "9 0 0.6567\n",
      "\n",
      "Test set: Average loss: 0.0109, Accuracy: 6431/10000 (64%)\n",
      "\n",
      "9 1 0.6431\n",
      "\n",
      "Test set: Average loss: 0.0113, Accuracy: 6276/10000 (63%)\n",
      "\n",
      "9 2 0.6276\n",
      "\n",
      "Test set: Average loss: 0.0118, Accuracy: 6029/10000 (60%)\n",
      "\n",
      "9 3 0.6029\n",
      "\n",
      "Test set: Average loss: 0.0121, Accuracy: 5890/10000 (59%)\n",
      "\n",
      "9 4 0.589\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 5567/10000 (56%)\n",
      "\n",
      "9 5 0.5567\n",
      "\n",
      "Test set: Average loss: 0.0137, Accuracy: 5245/10000 (52%)\n",
      "\n",
      "9 6 0.5245\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 4943/10000 (49%)\n",
      "\n",
      "9 7 0.4943\n",
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 4662/10000 (47%)\n",
      "\n",
      "9 8 0.4662\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4399/10000 (44%)\n",
      "\n",
      "9 9 0.4399\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 4193/10000 (42%)\n",
      "\n",
      "9 10 0.4193\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 3957/10000 (40%)\n",
      "\n",
      "9 11 0.3957\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3598/10000 (36%)\n",
      "\n",
      "9 12 0.3598\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 3130/10000 (31%)\n",
      "\n",
      "9 13 0.313\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2828/10000 (28%)\n",
      "\n",
      "9 14 0.2828\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2436/10000 (24%)\n",
      "\n",
      "9 15 0.2436\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2172/10000 (22%)\n",
      "\n",
      "9 16 0.2172\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1879/10000 (19%)\n",
      "\n",
      "9 17 0.1879\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1693/10000 (17%)\n",
      "\n",
      "9 18 0.1693\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1526/10000 (15%)\n",
      "\n",
      "9 19 0.1526\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1420/10000 (14%)\n",
      "\n",
      "9 20 0.142\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1313/10000 (13%)\n",
      "\n",
      "9 21 0.1313\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1253/10000 (13%)\n",
      "\n",
      "9 22 0.1253\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1196/10000 (12%)\n",
      "\n",
      "9 23 0.1196\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1153/10000 (12%)\n",
      "\n",
      "9 24 0.1153\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "9 25 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "9 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "9 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "10 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "10 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "10 -25 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "10 -24 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1153/10000 (12%)\n",
      "\n",
      "10 -23 0.1153\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1197/10000 (12%)\n",
      "\n",
      "10 -22 0.1197\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1263/10000 (13%)\n",
      "\n",
      "10 -21 0.1263\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1342/10000 (13%)\n",
      "\n",
      "10 -20 0.1342\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1519/10000 (15%)\n",
      "\n",
      "10 -19 0.1519\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1752/10000 (18%)\n",
      "\n",
      "10 -18 0.1752\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1991/10000 (20%)\n",
      "\n",
      "10 -17 0.1991\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 2332/10000 (23%)\n",
      "\n",
      "10 -16 0.2332\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 2547/10000 (25%)\n",
      "\n",
      "10 -15 0.2547\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2653/10000 (27%)\n",
      "\n",
      "10 -14 0.2653\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2807/10000 (28%)\n",
      "\n",
      "10 -13 0.2807\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 3031/10000 (30%)\n",
      "\n",
      "10 -12 0.3031\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3389/10000 (34%)\n",
      "\n",
      "10 -11 0.3389\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 3740/10000 (37%)\n",
      "\n",
      "10 -10 0.374\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 4095/10000 (41%)\n",
      "\n",
      "10 -9 0.4095\n",
      "\n",
      "Test set: Average loss: 0.0156, Accuracy: 4680/10000 (47%)\n",
      "\n",
      "10 -8 0.468\n",
      "\n",
      "Test set: Average loss: 0.0147, Accuracy: 4980/10000 (50%)\n",
      "\n",
      "10 -7 0.498\n",
      "\n",
      "Test set: Average loss: 0.0137, Accuracy: 5422/10000 (54%)\n",
      "\n",
      "10 -6 0.5422\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 5711/10000 (57%)\n",
      "\n",
      "10 -5 0.5711\n",
      "\n",
      "Test set: Average loss: 0.0121, Accuracy: 5980/10000 (60%)\n",
      "\n",
      "10 -4 0.598\n",
      "\n",
      "Test set: Average loss: 0.0118, Accuracy: 6054/10000 (61%)\n",
      "\n",
      "10 -3 0.6054\n",
      "\n",
      "Test set: Average loss: 0.0114, Accuracy: 6217/10000 (62%)\n",
      "\n",
      "10 -2 0.6217\n",
      "\n",
      "Test set: Average loss: 0.0115, Accuracy: 6236/10000 (62%)\n",
      "\n",
      "10 -1 0.6236\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 6172/10000 (62%)\n",
      "\n",
      "10 0 0.6172\n",
      "\n",
      "Test set: Average loss: 0.0118, Accuracy: 6120/10000 (61%)\n",
      "\n",
      "10 1 0.612\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 5861/10000 (59%)\n",
      "\n",
      "10 2 0.5861\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 5668/10000 (57%)\n",
      "\n",
      "10 3 0.5668\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 5494/10000 (55%)\n",
      "\n",
      "10 4 0.5494\n",
      "\n",
      "Test set: Average loss: 0.0138, Accuracy: 5260/10000 (53%)\n",
      "\n",
      "10 5 0.526\n",
      "\n",
      "Test set: Average loss: 0.0144, Accuracy: 4996/10000 (50%)\n",
      "\n",
      "10 6 0.4996\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4669/10000 (47%)\n",
      "\n",
      "10 7 0.4669\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4475/10000 (45%)\n",
      "\n",
      "10 8 0.4475\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 4224/10000 (42%)\n",
      "\n",
      "10 9 0.4224\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 4070/10000 (41%)\n",
      "\n",
      "10 10 0.407\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 3731/10000 (37%)\n",
      "\n",
      "10 11 0.3731\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 3400/10000 (34%)\n",
      "\n",
      "10 12 0.34\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 3052/10000 (31%)\n",
      "\n",
      "10 13 0.3052\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2644/10000 (26%)\n",
      "\n",
      "10 14 0.2644\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2282/10000 (23%)\n",
      "\n",
      "10 15 0.2282\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 2131/10000 (21%)\n",
      "\n",
      "10 16 0.2131\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1849/10000 (18%)\n",
      "\n",
      "10 17 0.1849\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1674/10000 (17%)\n",
      "\n",
      "10 18 0.1674\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1546/10000 (15%)\n",
      "\n",
      "10 19 0.1546\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 719/10000 (7%)\n",
      "\n",
      "10 20 0.0719\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1299/10000 (13%)\n",
      "\n",
      "10 21 0.1299\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1225/10000 (12%)\n",
      "\n",
      "10 22 0.1225\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 890/10000 (9%)\n",
      "\n",
      "10 23 0.089\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1156/10000 (12%)\n",
      "\n",
      "10 24 0.1156\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "10 25 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "10 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "10 27 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "11 -27 0.101\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "11 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "11 -25 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "11 -24 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1157/10000 (12%)\n",
      "\n",
      "11 -23 0.1157\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1171/10000 (12%)\n",
      "\n",
      "11 -22 0.1171\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1222/10000 (12%)\n",
      "\n",
      "11 -21 0.1222\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1325/10000 (13%)\n",
      "\n",
      "11 -20 0.1325\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1444/10000 (14%)\n",
      "\n",
      "11 -19 0.1444\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1054/10000 (11%)\n",
      "\n",
      "11 -18 0.1054\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1883/10000 (19%)\n",
      "\n",
      "11 -17 0.1883\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 2092/10000 (21%)\n",
      "\n",
      "11 -16 0.2092\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2370/10000 (24%)\n",
      "\n",
      "11 -15 0.237\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2568/10000 (26%)\n",
      "\n",
      "11 -14 0.2568\n",
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 2717/10000 (27%)\n",
      "\n",
      "11 -13 0.2717\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2894/10000 (29%)\n",
      "\n",
      "11 -12 0.2894\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 3123/10000 (31%)\n",
      "\n",
      "11 -11 0.3123\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3526/10000 (35%)\n",
      "\n",
      "11 -10 0.3526\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 3864/10000 (39%)\n",
      "\n",
      "11 -9 0.3864\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 4314/10000 (43%)\n",
      "\n",
      "11 -8 0.4314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4764/10000 (48%)\n",
      "\n",
      "11 -7 0.4764\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 5095/10000 (51%)\n",
      "\n",
      "11 -6 0.5095\n",
      "\n",
      "Test set: Average loss: 0.0138, Accuracy: 5314/10000 (53%)\n",
      "\n",
      "11 -5 0.5314\n",
      "\n",
      "Test set: Average loss: 0.0133, Accuracy: 5523/10000 (55%)\n",
      "\n",
      "11 -4 0.5523\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 5621/10000 (56%)\n",
      "\n",
      "11 -3 0.5621\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 5736/10000 (57%)\n",
      "\n",
      "11 -2 0.5736\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 5700/10000 (57%)\n",
      "\n",
      "11 -1 0.57\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 5622/10000 (56%)\n",
      "\n",
      "11 0 0.5622\n",
      "\n",
      "Test set: Average loss: 0.0132, Accuracy: 5576/10000 (56%)\n",
      "\n",
      "11 1 0.5576\n",
      "\n",
      "Test set: Average loss: 0.0136, Accuracy: 5359/10000 (54%)\n",
      "\n",
      "11 2 0.5359\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 5203/10000 (52%)\n",
      "\n",
      "11 3 0.5203\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 5007/10000 (50%)\n",
      "\n",
      "11 4 0.5007\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 4822/10000 (48%)\n",
      "\n",
      "11 5 0.4822\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4583/10000 (46%)\n",
      "\n",
      "11 6 0.4583\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4261/10000 (43%)\n",
      "\n",
      "11 7 0.4261\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 4148/10000 (41%)\n",
      "\n",
      "11 8 0.4148\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 3909/10000 (39%)\n",
      "\n",
      "11 9 0.3909\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3678/10000 (37%)\n",
      "\n",
      "11 10 0.3678\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3373/10000 (34%)\n",
      "\n",
      "11 11 0.3373\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 3117/10000 (31%)\n",
      "\n",
      "11 12 0.3117\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2759/10000 (28%)\n",
      "\n",
      "11 13 0.2759\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2414/10000 (24%)\n",
      "\n",
      "11 14 0.2414\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2075/10000 (21%)\n",
      "\n",
      "11 15 0.2075\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1934/10000 (19%)\n",
      "\n",
      "11 16 0.1934\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1813/10000 (18%)\n",
      "\n",
      "11 17 0.1813\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1642/10000 (16%)\n",
      "\n",
      "11 18 0.1642\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1515/10000 (15%)\n",
      "\n",
      "11 19 0.1515\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1403/10000 (14%)\n",
      "\n",
      "11 20 0.1403\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1298/10000 (13%)\n",
      "\n",
      "11 21 0.1298\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1251/10000 (13%)\n",
      "\n",
      "11 22 0.1251\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1192/10000 (12%)\n",
      "\n",
      "11 23 0.1192\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1151/10000 (12%)\n",
      "\n",
      "11 24 0.1151\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "11 25 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "11 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "11 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "12 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "12 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "12 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "12 -24 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "12 -23 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1171/10000 (12%)\n",
      "\n",
      "12 -22 0.1171\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1205/10000 (12%)\n",
      "\n",
      "12 -21 0.1205\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1266/10000 (13%)\n",
      "\n",
      "12 -20 0.1266\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1365/10000 (14%)\n",
      "\n",
      "12 -19 0.1365\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1544/10000 (15%)\n",
      "\n",
      "12 -18 0.1544\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1778/10000 (18%)\n",
      "\n",
      "12 -17 0.1778\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1990/10000 (20%)\n",
      "\n",
      "12 -16 0.199\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2214/10000 (22%)\n",
      "\n",
      "12 -15 0.2214\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2427/10000 (24%)\n",
      "\n",
      "12 -14 0.2427\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2601/10000 (26%)\n",
      "\n",
      "12 -13 0.2601\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2642/10000 (26%)\n",
      "\n",
      "12 -12 0.2642\n",
      "\n",
      "Test set: Average loss: 0.0194, Accuracy: 2894/10000 (29%)\n",
      "\n",
      "12 -11 0.2894\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 3160/10000 (32%)\n",
      "\n",
      "12 -10 0.316\n",
      "\n",
      "Test set: Average loss: 0.0179, Accuracy: 3586/10000 (36%)\n",
      "\n",
      "12 -9 0.3586\n",
      "\n",
      "Test set: Average loss: 0.0170, Accuracy: 3992/10000 (40%)\n",
      "\n",
      "12 -8 0.3992\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 4427/10000 (44%)\n",
      "\n",
      "12 -7 0.4427\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4593/10000 (46%)\n",
      "\n",
      "12 -6 0.4593\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4860/10000 (49%)\n",
      "\n",
      "12 -5 0.486\n",
      "\n",
      "Test set: Average loss: 0.0147, Accuracy: 5006/10000 (50%)\n",
      "\n",
      "12 -4 0.5006\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 5064/10000 (51%)\n",
      "\n",
      "12 -3 0.5064\n",
      "\n",
      "Test set: Average loss: 0.0142, Accuracy: 5128/10000 (51%)\n",
      "\n",
      "12 -2 0.5128\n",
      "\n",
      "Test set: Average loss: 0.0142, Accuracy: 5123/10000 (51%)\n",
      "\n",
      "12 -1 0.5123\n",
      "\n",
      "Test set: Average loss: 0.0142, Accuracy: 5184/10000 (52%)\n",
      "\n",
      "12 0 0.5184\n",
      "\n",
      "Test set: Average loss: 0.0143, Accuracy: 5063/10000 (51%)\n",
      "\n",
      "12 1 0.5063\n",
      "\n",
      "Test set: Average loss: 0.0145, Accuracy: 4954/10000 (50%)\n",
      "\n",
      "12 2 0.4954\n",
      "\n",
      "Test set: Average loss: 0.0150, Accuracy: 4725/10000 (47%)\n",
      "\n",
      "12 3 0.4725\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4611/10000 (46%)\n",
      "\n",
      "12 4 0.4611\n",
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 4397/10000 (44%)\n",
      "\n",
      "12 5 0.4397\n",
      "\n",
      "Test set: Average loss: 0.0164, Accuracy: 4127/10000 (41%)\n",
      "\n",
      "12 6 0.4127\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 3934/10000 (39%)\n",
      "\n",
      "12 7 0.3934\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 3639/10000 (36%)\n",
      "\n",
      "12 8 0.3639\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 3463/10000 (35%)\n",
      "\n",
      "12 9 0.3463\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 3255/10000 (33%)\n",
      "\n",
      "12 10 0.3255\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 3003/10000 (30%)\n",
      "\n",
      "12 11 0.3003\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 2854/10000 (29%)\n",
      "\n",
      "12 12 0.2854\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2512/10000 (25%)\n",
      "\n",
      "12 13 0.2512\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2251/10000 (23%)\n",
      "\n",
      "12 14 0.2251\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1980/10000 (20%)\n",
      "\n",
      "12 15 0.198\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1855/10000 (19%)\n",
      "\n",
      "12 16 0.1855\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1712/10000 (17%)\n",
      "\n",
      "12 17 0.1712\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1586/10000 (16%)\n",
      "\n",
      "12 18 0.1586\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1467/10000 (15%)\n",
      "\n",
      "12 19 0.1467\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 465/10000 (5%)\n",
      "\n",
      "12 20 0.0465\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1270/10000 (13%)\n",
      "\n",
      "12 21 0.127\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1231/10000 (12%)\n",
      "\n",
      "12 22 0.1231\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1188/10000 (12%)\n",
      "\n",
      "12 23 0.1188\n",
      "\n",
      "Test set: Average loss: 0.0238, Accuracy: 1157/10000 (12%)\n",
      "\n",
      "12 24 0.1157\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "12 25 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "12 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "12 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "13 -27 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "13 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "13 -25 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "13 -24 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "13 -23 0.115\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1164/10000 (12%)\n",
      "\n",
      "13 -22 0.1164\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1188/10000 (12%)\n",
      "\n",
      "13 -21 0.1188\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1244/10000 (12%)\n",
      "\n",
      "13 -20 0.1244\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1345/10000 (13%)\n",
      "\n",
      "13 -19 0.1345\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1416/10000 (14%)\n",
      "\n",
      "13 -18 0.1416\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1617/10000 (16%)\n",
      "\n",
      "13 -17 0.1617\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1865/10000 (19%)\n",
      "\n",
      "13 -16 0.1865\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 2057/10000 (21%)\n",
      "\n",
      "13 -15 0.2057\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 2260/10000 (23%)\n",
      "\n",
      "13 -14 0.226\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2384/10000 (24%)\n",
      "\n",
      "13 -13 0.2384\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2559/10000 (26%)\n",
      "\n",
      "13 -12 0.2559\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 2753/10000 (28%)\n",
      "\n",
      "13 -11 0.2753\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 2971/10000 (30%)\n",
      "\n",
      "13 -10 0.2971\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 3265/10000 (33%)\n",
      "\n",
      "13 -9 0.3265\n",
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3581/10000 (36%)\n",
      "\n",
      "13 -8 0.3581\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 3981/10000 (40%)\n",
      "\n",
      "13 -7 0.3981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 4137/10000 (41%)\n",
      "\n",
      "13 -6 0.4137\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4362/10000 (44%)\n",
      "\n",
      "13 -5 0.4362\n",
      "\n",
      "Test set: Average loss: 0.0161, Accuracy: 4324/10000 (43%)\n",
      "\n",
      "13 -4 0.4324\n",
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 4581/10000 (46%)\n",
      "\n",
      "13 -3 0.4581\n",
      "\n",
      "Test set: Average loss: 0.0154, Accuracy: 4582/10000 (46%)\n",
      "\n",
      "13 -2 0.4582\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4645/10000 (46%)\n",
      "\n",
      "13 -1 0.4645\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4698/10000 (47%)\n",
      "\n",
      "13 0 0.4698\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 4660/10000 (47%)\n",
      "\n",
      "13 1 0.466\n",
      "\n",
      "Test set: Average loss: 0.0153, Accuracy: 4622/10000 (46%)\n",
      "\n",
      "13 2 0.4622\n",
      "\n",
      "Test set: Average loss: 0.0157, Accuracy: 4484/10000 (45%)\n",
      "\n",
      "13 3 0.4484\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 4266/10000 (43%)\n",
      "\n",
      "13 4 0.4266\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 4038/10000 (40%)\n",
      "\n",
      "13 5 0.4038\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 3773/10000 (38%)\n",
      "\n",
      "13 6 0.3773\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 3484/10000 (35%)\n",
      "\n",
      "13 7 0.3484\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3326/10000 (33%)\n",
      "\n",
      "13 8 0.3326\n",
      "\n",
      "Test set: Average loss: 0.0187, Accuracy: 3134/10000 (31%)\n",
      "\n",
      "13 9 0.3134\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2905/10000 (29%)\n",
      "\n",
      "13 10 0.2905\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2792/10000 (28%)\n",
      "\n",
      "13 11 0.2792\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2608/10000 (26%)\n",
      "\n",
      "13 12 0.2608\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2343/10000 (23%)\n",
      "\n",
      "13 13 0.2343\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 2159/10000 (22%)\n",
      "\n",
      "13 14 0.2159\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1970/10000 (20%)\n",
      "\n",
      "13 15 0.197\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1823/10000 (18%)\n",
      "\n",
      "13 16 0.1823\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1704/10000 (17%)\n",
      "\n",
      "13 17 0.1704\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1571/10000 (16%)\n",
      "\n",
      "13 18 0.1571\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1472/10000 (15%)\n",
      "\n",
      "13 19 0.1472\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1359/10000 (14%)\n",
      "\n",
      "13 20 0.1359\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1283/10000 (13%)\n",
      "\n",
      "13 21 0.1283\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1218/10000 (12%)\n",
      "\n",
      "13 22 0.1218\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1180/10000 (12%)\n",
      "\n",
      "13 23 0.118\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "13 24 0.115\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "13 25 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "13 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "13 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "14 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "14 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1011/10000 (10%)\n",
      "\n",
      "14 -25 0.1011\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "14 -24 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1146/10000 (11%)\n",
      "\n",
      "14 -23 0.1146\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1166/10000 (12%)\n",
      "\n",
      "14 -22 0.1166\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1187/10000 (12%)\n",
      "\n",
      "14 -21 0.1187\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1223/10000 (12%)\n",
      "\n",
      "14 -20 0.1223\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1288/10000 (13%)\n",
      "\n",
      "14 -19 0.1288\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1388/10000 (14%)\n",
      "\n",
      "14 -18 0.1388\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1509/10000 (15%)\n",
      "\n",
      "14 -17 0.1509\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1764/10000 (18%)\n",
      "\n",
      "14 -16 0.1764\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1944/10000 (19%)\n",
      "\n",
      "14 -15 0.1944\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 2175/10000 (22%)\n",
      "\n",
      "14 -14 0.2175\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2295/10000 (23%)\n",
      "\n",
      "14 -13 0.2295\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2421/10000 (24%)\n",
      "\n",
      "14 -12 0.2421\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2523/10000 (25%)\n",
      "\n",
      "14 -11 0.2523\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2684/10000 (27%)\n",
      "\n",
      "14 -10 0.2684\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 2923/10000 (29%)\n",
      "\n",
      "14 -9 0.2923\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 3155/10000 (32%)\n",
      "\n",
      "14 -8 0.3155\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 3390/10000 (34%)\n",
      "\n",
      "14 -7 0.339\n",
      "\n",
      "Test set: Average loss: 0.0177, Accuracy: 3561/10000 (36%)\n",
      "\n",
      "14 -6 0.3561\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 3767/10000 (38%)\n",
      "\n",
      "14 -5 0.3767\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 3969/10000 (40%)\n",
      "\n",
      "14 -4 0.3969\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 4062/10000 (41%)\n",
      "\n",
      "14 -3 0.4062\n",
      "\n",
      "Test set: Average loss: 0.0162, Accuracy: 4135/10000 (41%)\n",
      "\n",
      "14 -2 0.4135\n",
      "\n",
      "Test set: Average loss: 0.0159, Accuracy: 4242/10000 (42%)\n",
      "\n",
      "14 -1 0.4242\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 4336/10000 (43%)\n",
      "\n",
      "14 0 0.4336\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 4291/10000 (43%)\n",
      "\n",
      "14 1 0.4291\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy: 4127/10000 (41%)\n",
      "\n",
      "14 2 0.4127\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 4030/10000 (40%)\n",
      "\n",
      "14 3 0.403\n",
      "\n",
      "Test set: Average loss: 0.0172, Accuracy: 3771/10000 (38%)\n",
      "\n",
      "14 4 0.3771\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 3578/10000 (36%)\n",
      "\n",
      "14 5 0.3578\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3416/10000 (34%)\n",
      "\n",
      "14 6 0.3416\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 3107/10000 (31%)\n",
      "\n",
      "14 7 0.3107\n",
      "\n",
      "Test set: Average loss: 0.0189, Accuracy: 3000/10000 (30%)\n",
      "\n",
      "14 8 0.3\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2863/10000 (29%)\n",
      "\n",
      "14 9 0.2863\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 2732/10000 (27%)\n",
      "\n",
      "14 10 0.2732\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2602/10000 (26%)\n",
      "\n",
      "14 11 0.2602\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2416/10000 (24%)\n",
      "\n",
      "14 12 0.2416\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2282/10000 (23%)\n",
      "\n",
      "14 13 0.2282\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2049/10000 (20%)\n",
      "\n",
      "14 14 0.2049\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1874/10000 (19%)\n",
      "\n",
      "14 15 0.1874\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 884/10000 (9%)\n",
      "\n",
      "14 16 0.0884\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1674/10000 (17%)\n",
      "\n",
      "14 17 0.1674\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1554/10000 (16%)\n",
      "\n",
      "14 18 0.1554\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1444/10000 (14%)\n",
      "\n",
      "14 19 0.1444\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1341/10000 (13%)\n",
      "\n",
      "14 20 0.1341\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1268/10000 (13%)\n",
      "\n",
      "14 21 0.1268\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1207/10000 (12%)\n",
      "\n",
      "14 22 0.1207\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1168/10000 (12%)\n",
      "\n",
      "14 23 0.1168\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1154/10000 (12%)\n",
      "\n",
      "14 24 0.1154\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "14 25 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "14 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "14 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "15 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "15 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "15 -25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "15 -24 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1146/10000 (11%)\n",
      "\n",
      "15 -23 0.1146\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1163/10000 (12%)\n",
      "\n",
      "15 -22 0.1163\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1168/10000 (12%)\n",
      "\n",
      "15 -21 0.1168\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1217/10000 (12%)\n",
      "\n",
      "15 -20 0.1217\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 796/10000 (8%)\n",
      "\n",
      "15 -19 0.0796\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1305/10000 (13%)\n",
      "\n",
      "15 -18 0.1305\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1417/10000 (14%)\n",
      "\n",
      "15 -17 0.1417\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1666/10000 (17%)\n",
      "\n",
      "15 -16 0.1666\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1880/10000 (19%)\n",
      "\n",
      "15 -15 0.188\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 2028/10000 (20%)\n",
      "\n",
      "15 -14 0.2028\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2160/10000 (22%)\n",
      "\n",
      "15 -13 0.216\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2216/10000 (22%)\n",
      "\n",
      "15 -12 0.2216\n",
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 2422/10000 (24%)\n",
      "\n",
      "15 -11 0.2422\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2526/10000 (25%)\n",
      "\n",
      "15 -10 0.2526\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2618/10000 (26%)\n",
      "\n",
      "15 -9 0.2618\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 2869/10000 (29%)\n",
      "\n",
      "15 -8 0.2869\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 3104/10000 (31%)\n",
      "\n",
      "15 -7 0.3104\n",
      "\n",
      "Test set: Average loss: 0.0181, Accuracy: 3222/10000 (32%)\n",
      "\n",
      "15 -6 0.3222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0178, Accuracy: 3372/10000 (34%)\n",
      "\n",
      "15 -5 0.3372\n",
      "\n",
      "Test set: Average loss: 0.0174, Accuracy: 3530/10000 (35%)\n",
      "\n",
      "15 -4 0.353\n",
      "\n",
      "Test set: Average loss: 0.0169, Accuracy: 3770/10000 (38%)\n",
      "\n",
      "15 -3 0.377\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 3853/10000 (39%)\n",
      "\n",
      "15 -2 0.3853\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 3998/10000 (40%)\n",
      "\n",
      "15 -1 0.3998\n",
      "\n",
      "Test set: Average loss: 0.0167, Accuracy: 3944/10000 (39%)\n",
      "\n",
      "15 0 0.3944\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 3894/10000 (39%)\n",
      "\n",
      "15 1 0.3894\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 3726/10000 (37%)\n",
      "\n",
      "15 2 0.3726\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 3559/10000 (36%)\n",
      "\n",
      "15 3 0.3559\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3392/10000 (34%)\n",
      "\n",
      "15 4 0.3392\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3207/10000 (32%)\n",
      "\n",
      "15 5 0.3207\n",
      "\n",
      "Test set: Average loss: 0.0188, Accuracy: 3088/10000 (31%)\n",
      "\n",
      "15 6 0.3088\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2910/10000 (29%)\n",
      "\n",
      "15 7 0.291\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2740/10000 (27%)\n",
      "\n",
      "15 8 0.274\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2660/10000 (27%)\n",
      "\n",
      "15 9 0.266\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2541/10000 (25%)\n",
      "\n",
      "15 10 0.2541\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2393/10000 (24%)\n",
      "\n",
      "15 11 0.2393\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2223/10000 (22%)\n",
      "\n",
      "15 12 0.2223\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2094/10000 (21%)\n",
      "\n",
      "15 13 0.2094\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1942/10000 (19%)\n",
      "\n",
      "15 14 0.1942\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1195/10000 (12%)\n",
      "\n",
      "15 15 0.1195\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1707/10000 (17%)\n",
      "\n",
      "15 16 0.1707\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1609/10000 (16%)\n",
      "\n",
      "15 17 0.1609\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1487/10000 (15%)\n",
      "\n",
      "15 18 0.1487\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1378/10000 (14%)\n",
      "\n",
      "15 19 0.1378\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1321/10000 (13%)\n",
      "\n",
      "15 20 0.1321\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1252/10000 (13%)\n",
      "\n",
      "15 21 0.1252\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1207/10000 (12%)\n",
      "\n",
      "15 22 0.1207\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1158/10000 (12%)\n",
      "\n",
      "15 23 0.1158\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "15 24 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "15 25 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "15 26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "15 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "16 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "16 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "16 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "16 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "16 -23 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1153/10000 (12%)\n",
      "\n",
      "16 -22 0.1153\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1172/10000 (12%)\n",
      "\n",
      "16 -21 0.1172\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1180/10000 (12%)\n",
      "\n",
      "16 -20 0.118\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1239/10000 (12%)\n",
      "\n",
      "16 -19 0.1239\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1278/10000 (13%)\n",
      "\n",
      "16 -18 0.1278\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1347/10000 (13%)\n",
      "\n",
      "16 -17 0.1347\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1461/10000 (15%)\n",
      "\n",
      "16 -16 0.1461\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1679/10000 (17%)\n",
      "\n",
      "16 -15 0.1679\n",
      "\n",
      "Test set: Average loss: 0.0220, Accuracy: 1890/10000 (19%)\n",
      "\n",
      "16 -14 0.189\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 2010/10000 (20%)\n",
      "\n",
      "16 -13 0.201\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 2040/10000 (20%)\n",
      "\n",
      "16 -12 0.204\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2250/10000 (22%)\n",
      "\n",
      "16 -11 0.225\n",
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 2393/10000 (24%)\n",
      "\n",
      "16 -10 0.2393\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2455/10000 (25%)\n",
      "\n",
      "16 -9 0.2455\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2657/10000 (27%)\n",
      "\n",
      "16 -8 0.2657\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2802/10000 (28%)\n",
      "\n",
      "16 -7 0.2802\n",
      "\n",
      "Test set: Average loss: 0.0189, Accuracy: 2888/10000 (29%)\n",
      "\n",
      "16 -6 0.2888\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 3028/10000 (30%)\n",
      "\n",
      "16 -5 0.3028\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3295/10000 (33%)\n",
      "\n",
      "16 -4 0.3295\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 3481/10000 (35%)\n",
      "\n",
      "16 -3 0.3481\n",
      "\n",
      "Test set: Average loss: 0.0175, Accuracy: 3554/10000 (36%)\n",
      "\n",
      "16 -2 0.3554\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 3625/10000 (36%)\n",
      "\n",
      "16 -1 0.3625\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 3636/10000 (36%)\n",
      "\n",
      "16 0 0.3636\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy: 3504/10000 (35%)\n",
      "\n",
      "16 1 0.3504\n",
      "\n",
      "Test set: Average loss: 0.0180, Accuracy: 3354/10000 (34%)\n",
      "\n",
      "16 2 0.3354\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 3150/10000 (32%)\n",
      "\n",
      "16 3 0.315\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 2891/10000 (29%)\n",
      "\n",
      "16 4 0.2891\n",
      "\n",
      "Test set: Average loss: 0.0193, Accuracy: 2774/10000 (28%)\n",
      "\n",
      "16 5 0.2774\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2713/10000 (27%)\n",
      "\n",
      "16 6 0.2713\n",
      "\n",
      "Test set: Average loss: 0.0201, Accuracy: 2584/10000 (26%)\n",
      "\n",
      "16 7 0.2584\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2514/10000 (25%)\n",
      "\n",
      "16 8 0.2514\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2286/10000 (23%)\n",
      "\n",
      "16 9 0.2286\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2266/10000 (23%)\n",
      "\n",
      "16 10 0.2266\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 2151/10000 (22%)\n",
      "\n",
      "16 11 0.2151\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2073/10000 (21%)\n",
      "\n",
      "16 12 0.2073\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1901/10000 (19%)\n",
      "\n",
      "16 13 0.1901\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1778/10000 (18%)\n",
      "\n",
      "16 14 0.1778\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1662/10000 (17%)\n",
      "\n",
      "16 15 0.1662\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1601/10000 (16%)\n",
      "\n",
      "16 16 0.1601\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1505/10000 (15%)\n",
      "\n",
      "16 17 0.1505\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1421/10000 (14%)\n",
      "\n",
      "16 18 0.1421\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1339/10000 (13%)\n",
      "\n",
      "16 19 0.1339\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 750/10000 (8%)\n",
      "\n",
      "16 20 0.075\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1226/10000 (12%)\n",
      "\n",
      "16 21 0.1226\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1194/10000 (12%)\n",
      "\n",
      "16 22 0.1194\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1164/10000 (12%)\n",
      "\n",
      "16 23 0.1164\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "16 24 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "16 25 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "16 26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "16 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "17 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "17 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0239, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "17 -25 0.101\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "17 -24 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "17 -23 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "17 -22 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1169/10000 (12%)\n",
      "\n",
      "17 -21 0.1169\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1171/10000 (12%)\n",
      "\n",
      "17 -20 0.1171\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1192/10000 (12%)\n",
      "\n",
      "17 -19 0.1192\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1245/10000 (12%)\n",
      "\n",
      "17 -18 0.1245\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1302/10000 (13%)\n",
      "\n",
      "17 -17 0.1302\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1444/10000 (14%)\n",
      "\n",
      "17 -16 0.1444\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1617/10000 (16%)\n",
      "\n",
      "17 -15 0.1617\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1742/10000 (17%)\n",
      "\n",
      "17 -14 0.1742\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1841/10000 (18%)\n",
      "\n",
      "17 -13 0.1841\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 2008/10000 (20%)\n",
      "\n",
      "17 -12 0.2008\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 2055/10000 (21%)\n",
      "\n",
      "17 -11 0.2055\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2187/10000 (22%)\n",
      "\n",
      "17 -10 0.2187\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2249/10000 (22%)\n",
      "\n",
      "17 -9 0.2249\n",
      "\n",
      "Test set: Average loss: 0.0202, Accuracy: 2410/10000 (24%)\n",
      "\n",
      "17 -8 0.241\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2537/10000 (25%)\n",
      "\n",
      "17 -7 0.2537\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 2654/10000 (27%)\n",
      "\n",
      "17 -6 0.2654\n",
      "\n",
      "Test set: Average loss: 0.0192, Accuracy: 2762/10000 (28%)\n",
      "\n",
      "17 -5 0.2762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 2899/10000 (29%)\n",
      "\n",
      "17 -4 0.2899\n",
      "\n",
      "Test set: Average loss: 0.0186, Accuracy: 3003/10000 (30%)\n",
      "\n",
      "17 -3 0.3003\n",
      "\n",
      "Test set: Average loss: 0.0184, Accuracy: 3069/10000 (31%)\n",
      "\n",
      "17 -2 0.3069\n",
      "\n",
      "Test set: Average loss: 0.0183, Accuracy: 3178/10000 (32%)\n",
      "\n",
      "17 -1 0.3178\n",
      "\n",
      "Test set: Average loss: 0.0185, Accuracy: 3027/10000 (30%)\n",
      "\n",
      "17 0 0.3027\n",
      "\n",
      "Test set: Average loss: 0.0187, Accuracy: 2954/10000 (30%)\n",
      "\n",
      "17 1 0.2954\n",
      "\n",
      "Test set: Average loss: 0.0191, Accuracy: 2794/10000 (28%)\n",
      "\n",
      "17 2 0.2794\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2596/10000 (26%)\n",
      "\n",
      "17 3 0.2596\n",
      "\n",
      "Test set: Average loss: 0.0199, Accuracy: 2482/10000 (25%)\n",
      "\n",
      "17 4 0.2482\n",
      "\n",
      "Test set: Average loss: 0.0203, Accuracy: 2343/10000 (23%)\n",
      "\n",
      "17 5 0.2343\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2305/10000 (23%)\n",
      "\n",
      "17 6 0.2305\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2208/10000 (22%)\n",
      "\n",
      "17 7 0.2208\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2167/10000 (22%)\n",
      "\n",
      "17 8 0.2167\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 2014/10000 (20%)\n",
      "\n",
      "17 9 0.2014\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 1957/10000 (20%)\n",
      "\n",
      "17 10 0.1957\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1904/10000 (19%)\n",
      "\n",
      "17 11 0.1904\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1789/10000 (18%)\n",
      "\n",
      "17 12 0.1789\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1673/10000 (17%)\n",
      "\n",
      "17 13 0.1673\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1613/10000 (16%)\n",
      "\n",
      "17 14 0.1613\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1539/10000 (15%)\n",
      "\n",
      "17 15 0.1539\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1462/10000 (15%)\n",
      "\n",
      "17 16 0.1462\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1416/10000 (14%)\n",
      "\n",
      "17 17 0.1416\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1326/10000 (13%)\n",
      "\n",
      "17 18 0.1326\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1299/10000 (13%)\n",
      "\n",
      "17 19 0.1299\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1252/10000 (13%)\n",
      "\n",
      "17 20 0.1252\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1205/10000 (12%)\n",
      "\n",
      "17 21 0.1205\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1177/10000 (12%)\n",
      "\n",
      "17 22 0.1177\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1156/10000 (12%)\n",
      "\n",
      "17 23 0.1156\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "17 24 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "17 25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "17 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "17 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "18 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "18 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "18 -25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "18 -24 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "18 -23 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "18 -22 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1160/10000 (12%)\n",
      "\n",
      "18 -21 0.116\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1166/10000 (12%)\n",
      "\n",
      "18 -20 0.1166\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1170/10000 (12%)\n",
      "\n",
      "18 -19 0.117\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1197/10000 (12%)\n",
      "\n",
      "18 -18 0.1197\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1264/10000 (13%)\n",
      "\n",
      "18 -17 0.1264\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1362/10000 (14%)\n",
      "\n",
      "18 -16 0.1362\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1530/10000 (15%)\n",
      "\n",
      "18 -15 0.153\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1639/10000 (16%)\n",
      "\n",
      "18 -14 0.1639\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1763/10000 (18%)\n",
      "\n",
      "18 -13 0.1763\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1787/10000 (18%)\n",
      "\n",
      "18 -12 0.1787\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1879/10000 (19%)\n",
      "\n",
      "18 -11 0.1879\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 1934/10000 (19%)\n",
      "\n",
      "18 -10 0.1934\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 1998/10000 (20%)\n",
      "\n",
      "18 -9 0.1998\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2073/10000 (21%)\n",
      "\n",
      "18 -8 0.2073\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 2258/10000 (23%)\n",
      "\n",
      "18 -7 0.2258\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2278/10000 (23%)\n",
      "\n",
      "18 -6 0.2278\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2399/10000 (24%)\n",
      "\n",
      "18 -5 0.2399\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 2542/10000 (25%)\n",
      "\n",
      "18 -4 0.2542\n",
      "\n",
      "Test set: Average loss: 0.0197, Accuracy: 2559/10000 (26%)\n",
      "\n",
      "18 -3 0.2559\n",
      "\n",
      "Test set: Average loss: 0.0195, Accuracy: 2587/10000 (26%)\n",
      "\n",
      "18 -2 0.2587\n",
      "\n",
      "Test set: Average loss: 0.0196, Accuracy: 2570/10000 (26%)\n",
      "\n",
      "18 -1 0.257\n",
      "\n",
      "Test set: Average loss: 0.0198, Accuracy: 2426/10000 (24%)\n",
      "\n",
      "18 0 0.2426\n",
      "\n",
      "Test set: Average loss: 0.0200, Accuracy: 2309/10000 (23%)\n",
      "\n",
      "18 1 0.2309\n",
      "\n",
      "Test set: Average loss: 0.0204, Accuracy: 2151/10000 (22%)\n",
      "\n",
      "18 2 0.2151\n",
      "\n",
      "Test set: Average loss: 0.0205, Accuracy: 2111/10000 (21%)\n",
      "\n",
      "18 3 0.2111\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 1977/10000 (20%)\n",
      "\n",
      "18 4 0.1977\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 1948/10000 (19%)\n",
      "\n",
      "18 5 0.1948\n",
      "\n",
      "Test set: Average loss: 0.0212, Accuracy: 1924/10000 (19%)\n",
      "\n",
      "18 6 0.1924\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 1853/10000 (19%)\n",
      "\n",
      "18 7 0.1853\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1793/10000 (18%)\n",
      "\n",
      "18 8 0.1793\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1786/10000 (18%)\n",
      "\n",
      "18 9 0.1786\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1721/10000 (17%)\n",
      "\n",
      "18 10 0.1721\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1642/10000 (16%)\n",
      "\n",
      "18 11 0.1642\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1613/10000 (16%)\n",
      "\n",
      "18 12 0.1613\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1544/10000 (15%)\n",
      "\n",
      "18 13 0.1544\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1472/10000 (15%)\n",
      "\n",
      "18 14 0.1472\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1459/10000 (15%)\n",
      "\n",
      "18 15 0.1459\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1399/10000 (14%)\n",
      "\n",
      "18 16 0.1399\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1361/10000 (14%)\n",
      "\n",
      "18 17 0.1361\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1289/10000 (13%)\n",
      "\n",
      "18 18 0.1289\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1298/10000 (13%)\n",
      "\n",
      "18 19 0.1298\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1223/10000 (12%)\n",
      "\n",
      "18 20 0.1223\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1187/10000 (12%)\n",
      "\n",
      "18 21 0.1187\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1157/10000 (12%)\n",
      "\n",
      "18 22 0.1157\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1152/10000 (12%)\n",
      "\n",
      "18 23 0.1152\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "18 24 0.114\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "18 25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1008/10000 (10%)\n",
      "\n",
      "18 26 0.1008\n",
      "\n",
      "Test set: Average loss: 0.0244, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "18 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "19 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "19 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "19 -25 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "19 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "19 -23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "19 -22 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "19 -21 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1166/10000 (12%)\n",
      "\n",
      "19 -20 0.1166\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1166/10000 (12%)\n",
      "\n",
      "19 -19 0.1166\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1179/10000 (12%)\n",
      "\n",
      "19 -18 0.1179\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1222/10000 (12%)\n",
      "\n",
      "19 -17 0.1222\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1278/10000 (13%)\n",
      "\n",
      "19 -16 0.1278\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1380/10000 (14%)\n",
      "\n",
      "19 -15 0.138\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1483/10000 (15%)\n",
      "\n",
      "19 -14 0.1483\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1539/10000 (15%)\n",
      "\n",
      "19 -13 0.1539\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1581/10000 (16%)\n",
      "\n",
      "19 -12 0.1581\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1634/10000 (16%)\n",
      "\n",
      "19 -11 0.1634\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1728/10000 (17%)\n",
      "\n",
      "19 -10 0.1728\n",
      "\n",
      "Test set: Average loss: 0.0215, Accuracy: 1791/10000 (18%)\n",
      "\n",
      "19 -9 0.1791\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 1830/10000 (18%)\n",
      "\n",
      "19 -8 0.183\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 1957/10000 (20%)\n",
      "\n",
      "19 -7 0.1957\n",
      "\n",
      "Test set: Average loss: 0.0210, Accuracy: 2016/10000 (20%)\n",
      "\n",
      "19 -6 0.2016\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 2047/10000 (20%)\n",
      "\n",
      "19 -5 0.2047\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 2133/10000 (21%)\n",
      "\n",
      "19 -4 0.2133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2131/10000 (21%)\n",
      "\n",
      "19 -3 0.2131\n",
      "\n",
      "Test set: Average loss: 0.0207, Accuracy: 2058/10000 (21%)\n",
      "\n",
      "19 -2 0.2058\n",
      "\n",
      "Test set: Average loss: 0.0208, Accuracy: 1953/10000 (20%)\n",
      "\n",
      "19 -1 0.1953\n",
      "\n",
      "Test set: Average loss: 0.0209, Accuracy: 1918/10000 (19%)\n",
      "\n",
      "19 0 0.1918\n",
      "\n",
      "Test set: Average loss: 0.0211, Accuracy: 1803/10000 (18%)\n",
      "\n",
      "19 1 0.1803\n",
      "\n",
      "Test set: Average loss: 0.0213, Accuracy: 1719/10000 (17%)\n",
      "\n",
      "19 2 0.1719\n",
      "\n",
      "Test set: Average loss: 0.0214, Accuracy: 1700/10000 (17%)\n",
      "\n",
      "19 3 0.17\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1686/10000 (17%)\n",
      "\n",
      "19 4 0.1686\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1671/10000 (17%)\n",
      "\n",
      "19 5 0.1671\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1702/10000 (17%)\n",
      "\n",
      "19 6 0.1702\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1692/10000 (17%)\n",
      "\n",
      "19 7 0.1692\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1639/10000 (16%)\n",
      "\n",
      "19 8 0.1639\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1664/10000 (17%)\n",
      "\n",
      "19 9 0.1664\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1608/10000 (16%)\n",
      "\n",
      "19 10 0.1608\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1567/10000 (16%)\n",
      "\n",
      "19 11 0.1567\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1521/10000 (15%)\n",
      "\n",
      "19 12 0.1521\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1498/10000 (15%)\n",
      "\n",
      "19 13 0.1498\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1452/10000 (15%)\n",
      "\n",
      "19 14 0.1452\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1421/10000 (14%)\n",
      "\n",
      "19 15 0.1421\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1381/10000 (14%)\n",
      "\n",
      "19 16 0.1381\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1350/10000 (14%)\n",
      "\n",
      "19 17 0.135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1270/10000 (13%)\n",
      "\n",
      "19 18 0.127\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1239/10000 (12%)\n",
      "\n",
      "19 19 0.1239\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1199/10000 (12%)\n",
      "\n",
      "19 20 0.1199\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1176/10000 (12%)\n",
      "\n",
      "19 21 0.1176\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "19 22 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "19 23 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "19 24 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "19 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "19 26 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "19 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "20 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "20 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "20 -25 0.101\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "20 -24 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "20 -23 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "20 -22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "20 -21 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "20 -20 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1133/10000 (11%)\n",
      "\n",
      "20 -19 0.1133\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1146/10000 (11%)\n",
      "\n",
      "20 -18 0.1146\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1170/10000 (12%)\n",
      "\n",
      "20 -17 0.117\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1181/10000 (12%)\n",
      "\n",
      "20 -16 0.1181\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1280/10000 (13%)\n",
      "\n",
      "20 -15 0.128\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1337/10000 (13%)\n",
      "\n",
      "20 -14 0.1337\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1348/10000 (13%)\n",
      "\n",
      "20 -13 0.1348\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1419/10000 (14%)\n",
      "\n",
      "20 -12 0.1419\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1492/10000 (15%)\n",
      "\n",
      "20 -11 0.1492\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1446/10000 (14%)\n",
      "\n",
      "20 -10 0.1446\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1512/10000 (15%)\n",
      "\n",
      "20 -9 0.1512\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1639/10000 (16%)\n",
      "\n",
      "20 -8 0.1639\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1648/10000 (16%)\n",
      "\n",
      "20 -7 0.1648\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1713/10000 (17%)\n",
      "\n",
      "20 -6 0.1713\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1711/10000 (17%)\n",
      "\n",
      "20 -5 0.1711\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 1763/10000 (18%)\n",
      "\n",
      "20 -4 0.1763\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1622/10000 (16%)\n",
      "\n",
      "20 -3 0.1622\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 1623/10000 (16%)\n",
      "\n",
      "20 -2 0.1623\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1587/10000 (16%)\n",
      "\n",
      "20 -1 0.1587\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1486/10000 (15%)\n",
      "\n",
      "20 0 0.1486\n",
      "\n",
      "Test set: Average loss: 0.0218, Accuracy: 1485/10000 (15%)\n",
      "\n",
      "20 1 0.1485\n",
      "\n",
      "Test set: Average loss: 0.0219, Accuracy: 1476/10000 (15%)\n",
      "\n",
      "20 2 0.1476\n",
      "\n",
      "Test set: Average loss: 0.0221, Accuracy: 1498/10000 (15%)\n",
      "\n",
      "20 3 0.1498\n",
      "\n",
      "Test set: Average loss: 0.0222, Accuracy: 1512/10000 (15%)\n",
      "\n",
      "20 4 0.1512\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1508/10000 (15%)\n",
      "\n",
      "20 5 0.1508\n",
      "\n",
      "Test set: Average loss: 0.0223, Accuracy: 1572/10000 (16%)\n",
      "\n",
      "20 6 0.1572\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1619/10000 (16%)\n",
      "\n",
      "20 7 0.1619\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1584/10000 (16%)\n",
      "\n",
      "20 8 0.1584\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1610/10000 (16%)\n",
      "\n",
      "20 9 0.161\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1554/10000 (16%)\n",
      "\n",
      "20 10 0.1554\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1491/10000 (15%)\n",
      "\n",
      "20 11 0.1491\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1517/10000 (15%)\n",
      "\n",
      "20 12 0.1517\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1463/10000 (15%)\n",
      "\n",
      "20 13 0.1463\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1436/10000 (14%)\n",
      "\n",
      "20 14 0.1436\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1442/10000 (14%)\n",
      "\n",
      "20 15 0.1442\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1362/10000 (14%)\n",
      "\n",
      "20 16 0.1362\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1298/10000 (13%)\n",
      "\n",
      "20 17 0.1298\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1265/10000 (13%)\n",
      "\n",
      "20 18 0.1265\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1209/10000 (12%)\n",
      "\n",
      "20 19 0.1209\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1185/10000 (12%)\n",
      "\n",
      "20 20 0.1185\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1163/10000 (12%)\n",
      "\n",
      "20 21 0.1163\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "20 22 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "20 23 0.114\n",
      "\n",
      "Test set: Average loss: 0.0245, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "20 24 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "20 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "20 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "20 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "21 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "21 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "21 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "21 -24 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "21 -23 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "21 -22 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "21 -21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "21 -20 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1132/10000 (11%)\n",
      "\n",
      "21 -19 0.1132\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1120/10000 (11%)\n",
      "\n",
      "21 -18 0.112\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1128/10000 (11%)\n",
      "\n",
      "21 -17 0.1128\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1133/10000 (11%)\n",
      "\n",
      "21 -16 0.1133\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "21 -15 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1199/10000 (12%)\n",
      "\n",
      "21 -14 0.1199\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1160/10000 (12%)\n",
      "\n",
      "21 -13 0.116\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1211/10000 (12%)\n",
      "\n",
      "21 -12 0.1211\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1214/10000 (12%)\n",
      "\n",
      "21 -11 0.1214\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1317/10000 (13%)\n",
      "\n",
      "21 -10 0.1317\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1272/10000 (13%)\n",
      "\n",
      "21 -9 0.1272\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1360/10000 (14%)\n",
      "\n",
      "21 -8 0.136\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1327/10000 (13%)\n",
      "\n",
      "21 -7 0.1327\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1326/10000 (13%)\n",
      "\n",
      "21 -6 0.1326\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1378/10000 (14%)\n",
      "\n",
      "21 -5 0.1378\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1396/10000 (14%)\n",
      "\n",
      "21 -4 0.1396\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1353/10000 (14%)\n",
      "\n",
      "21 -3 0.1353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1336/10000 (13%)\n",
      "\n",
      "21 -2 0.1336\n",
      "\n",
      "Test set: Average loss: 0.0225, Accuracy: 1324/10000 (13%)\n",
      "\n",
      "21 -1 0.1324\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1343/10000 (13%)\n",
      "\n",
      "21 0 0.1343\n",
      "\n",
      "Test set: Average loss: 0.0224, Accuracy: 1313/10000 (13%)\n",
      "\n",
      "21 1 0.1313\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1324/10000 (13%)\n",
      "\n",
      "21 2 0.1324\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1393/10000 (14%)\n",
      "\n",
      "21 3 0.1393\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1437/10000 (14%)\n",
      "\n",
      "21 4 0.1437\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 1433/10000 (14%)\n",
      "\n",
      "21 5 0.1433\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1438/10000 (14%)\n",
      "\n",
      "21 6 0.1438\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1484/10000 (15%)\n",
      "\n",
      "21 7 0.1484\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1451/10000 (15%)\n",
      "\n",
      "21 8 0.1451\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1438/10000 (14%)\n",
      "\n",
      "21 9 0.1438\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1439/10000 (14%)\n",
      "\n",
      "21 10 0.1439\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1408/10000 (14%)\n",
      "\n",
      "21 11 0.1408\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1409/10000 (14%)\n",
      "\n",
      "21 12 0.1409\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1385/10000 (14%)\n",
      "\n",
      "21 13 0.1385\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1335/10000 (13%)\n",
      "\n",
      "21 14 0.1335\n",
      "\n",
      "Test set: Average loss: 0.0227, Accuracy: 1307/10000 (13%)\n",
      "\n",
      "21 15 0.1307\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1270/10000 (13%)\n",
      "\n",
      "21 16 0.127\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 329/10000 (3%)\n",
      "\n",
      "21 17 0.0329\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1202/10000 (12%)\n",
      "\n",
      "21 18 0.1202\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1174/10000 (12%)\n",
      "\n",
      "21 19 0.1174\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1169/10000 (12%)\n",
      "\n",
      "21 20 0.1169\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1155/10000 (12%)\n",
      "\n",
      "21 21 0.1155\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 891/10000 (9%)\n",
      "\n",
      "21 22 0.0891\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "21 23 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "21 24 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "21 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "21 26 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "21 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "22 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0241, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "22 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "22 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "22 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "22 -23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "22 -22 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "22 -21 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "22 -20 0.114\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1131/10000 (11%)\n",
      "\n",
      "22 -19 0.1131\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1125/10000 (11%)\n",
      "\n",
      "22 -18 0.1125\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1093/10000 (11%)\n",
      "\n",
      "22 -17 0.1093\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1122/10000 (11%)\n",
      "\n",
      "22 -16 0.1122\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1082/10000 (11%)\n",
      "\n",
      "22 -15 0.1082\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1107/10000 (11%)\n",
      "\n",
      "22 -14 0.1107\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1111/10000 (11%)\n",
      "\n",
      "22 -13 0.1111\n",
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 1071/10000 (11%)\n",
      "\n",
      "22 -12 0.1071\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "22 -11 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1131/10000 (11%)\n",
      "\n",
      "22 -10 0.1131\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1168/10000 (12%)\n",
      "\n",
      "22 -9 0.1168\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1198/10000 (12%)\n",
      "\n",
      "22 -8 0.1198\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1195/10000 (12%)\n",
      "\n",
      "22 -7 0.1195\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1227/10000 (12%)\n",
      "\n",
      "22 -6 0.1227\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1194/10000 (12%)\n",
      "\n",
      "22 -5 0.1194\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1180/10000 (12%)\n",
      "\n",
      "22 -4 0.118\n",
      "\n",
      "Test set: Average loss: 0.0226, Accuracy: 2122/10000 (21%)\n",
      "\n",
      "22 -3 0.2122\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1190/10000 (12%)\n",
      "\n",
      "22 -2 0.119\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1194/10000 (12%)\n",
      "\n",
      "22 -1 0.1194\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1219/10000 (12%)\n",
      "\n",
      "22 0 0.1219\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1203/10000 (12%)\n",
      "\n",
      "22 1 0.1203\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "22 2 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1188/10000 (12%)\n",
      "\n",
      "22 3 0.1188\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1196/10000 (12%)\n",
      "\n",
      "22 4 0.1196\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1186/10000 (12%)\n",
      "\n",
      "22 5 0.1186\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1216/10000 (12%)\n",
      "\n",
      "22 6 0.1216\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1209/10000 (12%)\n",
      "\n",
      "22 7 0.1209\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1238/10000 (12%)\n",
      "\n",
      "22 8 0.1238\n",
      "\n",
      "Test set: Average loss: 0.0229, Accuracy: 1245/10000 (12%)\n",
      "\n",
      "22 9 0.1245\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1253/10000 (13%)\n",
      "\n",
      "22 10 0.1253\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1245/10000 (12%)\n",
      "\n",
      "22 11 0.1245\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1219/10000 (12%)\n",
      "\n",
      "22 12 0.1219\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 801/10000 (8%)\n",
      "\n",
      "22 13 0.0801\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 967/10000 (10%)\n",
      "\n",
      "22 14 0.0967\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1196/10000 (12%)\n",
      "\n",
      "22 15 0.1196\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1176/10000 (12%)\n",
      "\n",
      "22 16 0.1176\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1175/10000 (12%)\n",
      "\n",
      "22 17 0.1175\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1159/10000 (12%)\n",
      "\n",
      "22 18 0.1159\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "22 19 0.115\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "22 20 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "22 21 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "22 22 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "22 23 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "22 24 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "22 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "22 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "22 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "23 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "23 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "23 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "23 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1133/10000 (11%)\n",
      "\n",
      "23 -23 0.1133\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "23 -22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1132/10000 (11%)\n",
      "\n",
      "23 -21 0.1132\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1131/10000 (11%)\n",
      "\n",
      "23 -20 0.1131\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1131/10000 (11%)\n",
      "\n",
      "23 -19 0.1131\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "23 -18 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1126/10000 (11%)\n",
      "\n",
      "23 -17 0.1126\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1125/10000 (11%)\n",
      "\n",
      "23 -16 0.1125\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1131/10000 (11%)\n",
      "\n",
      "23 -15 0.1131\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1129/10000 (11%)\n",
      "\n",
      "23 -14 0.1129\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1126/10000 (11%)\n",
      "\n",
      "23 -13 0.1126\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1128/10000 (11%)\n",
      "\n",
      "23 -12 0.1128\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1131/10000 (11%)\n",
      "\n",
      "23 -11 0.1131\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1117/10000 (11%)\n",
      "\n",
      "23 -10 0.1117\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "23 -9 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1121/10000 (11%)\n",
      "\n",
      "23 -8 0.1121\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "23 -7 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1126/10000 (11%)\n",
      "\n",
      "23 -6 0.1126\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1145/10000 (11%)\n",
      "\n",
      "23 -5 0.1145\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "23 -4 0.115\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1128/10000 (11%)\n",
      "\n",
      "23 -3 0.1128\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1132/10000 (11%)\n",
      "\n",
      "23 -2 0.1132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1149/10000 (11%)\n",
      "\n",
      "23 -1 0.1149\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1146/10000 (11%)\n",
      "\n",
      "23 0 0.1146\n",
      "\n",
      "Test set: Average loss: 0.0228, Accuracy: 1133/10000 (11%)\n",
      "\n",
      "23 1 0.1133\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1147/10000 (11%)\n",
      "\n",
      "23 2 0.1147\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "23 3 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "23 4 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1133/10000 (11%)\n",
      "\n",
      "23 5 0.1133\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1125/10000 (11%)\n",
      "\n",
      "23 6 0.1125\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1146/10000 (11%)\n",
      "\n",
      "23 7 0.1146\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1133/10000 (11%)\n",
      "\n",
      "23 8 0.1133\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1148/10000 (11%)\n",
      "\n",
      "23 9 0.1148\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "23 10 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "23 11 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1130/10000 (11%)\n",
      "\n",
      "23 12 0.113\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "23 13 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "23 14 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "23 15 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1150/10000 (12%)\n",
      "\n",
      "23 16 0.115\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "23 17 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1143/10000 (11%)\n",
      "\n",
      "23 18 0.1143\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "23 19 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1144/10000 (11%)\n",
      "\n",
      "23 20 0.1144\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "23 21 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "23 22 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "23 23 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "23 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "23 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "23 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "23 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 -23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 -22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 -21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 -20 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "24 -19 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "24 -18 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "24 -17 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1134/10000 (11%)\n",
      "\n",
      "24 -16 0.1134\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "24 -15 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "24 -14 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "24 -13 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "24 -12 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "24 -11 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "24 -10 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "24 -9 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "24 -8 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "24 -7 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "24 -6 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "24 -5 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "24 -4 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "24 -3 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "24 -2 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0238, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "24 -1 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "24 0 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "24 1 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "24 2 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "24 3 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "24 4 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1142/10000 (11%)\n",
      "\n",
      "24 5 0.1142\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "24 6 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "24 7 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "24 8 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "24 9 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "24 10 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1141/10000 (11%)\n",
      "\n",
      "24 11 0.1141\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1140/10000 (11%)\n",
      "\n",
      "24 12 0.114\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "24 13 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "24 14 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1139/10000 (11%)\n",
      "\n",
      "24 15 0.1139\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "24 16 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "24 17 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 18 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 19 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "24 20 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "24 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -20 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -19 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -18 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -17 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1029/10000 (10%)\n",
      "\n",
      "25 -16 0.1029\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -15 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "25 -14 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "25 -13 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -12 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -11 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "25 -10 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -9 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -8 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "25 -7 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -6 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 -5 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1137/10000 (11%)\n",
      "\n",
      "25 -4 0.1137\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "25 -3 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "25 -2 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "25 -1 0.1136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 0 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1138/10000 (11%)\n",
      "\n",
      "25 1 0.1138\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 2 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 3 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "25 4 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 5 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 6 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 7 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 8 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 9 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 10 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1133/10000 (11%)\n",
      "\n",
      "25 11 0.1133\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "25 12 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "25 13 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "25 14 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "25 15 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0234, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 16 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 17 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0238, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 18 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "25 19 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 20 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "25 27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -20 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -19 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -18 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -17 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -16 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -15 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -14 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -13 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -12 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -11 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "26 -10 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -9 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -8 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -7 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -6 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "26 -5 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -4 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -3 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "26 -2 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 -1 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 0 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "26 1 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 2 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 3 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 4 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 5 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1136/10000 (11%)\n",
      "\n",
      "26 6 0.1136\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 7 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 8 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 9 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 10 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 11 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 12 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 13 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 14 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 15 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0236, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 16 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 17 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 18 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 19 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 982/10000 (10%)\n",
      "\n",
      "26 20 0.0982\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "26 23 0.101\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "26 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "26 27 0.101\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -27 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -20 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0237, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -19 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -18 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -17 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -16 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -15 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -14 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -13 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -12 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -11 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -10 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -9 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -8 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -7 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -6 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -5 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -4 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -3 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -2 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 -1 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 0 0.1135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1010/10000 (10%)\n",
      "\n",
      "27 1 0.101\n",
      "\n",
      "Test set: Average loss: 0.0235, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 2 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1028/10000 (10%)\n",
      "\n",
      "27 3 0.1028\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 4 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 5 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 6 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 7 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 8 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 9 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 10 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 11 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 12 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 13 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 14 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0233, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 15 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 16 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 17 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0232, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 18 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 19 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 20 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 21 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 22 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 23 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 24 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0231, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 25 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 26 0.1135\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "27 27 0.1135\n"
     ]
    }
   ],
   "source": [
    "map_path = \"../data/MNIST_accuracy_{}.npy\".format(suffix)\n",
    "\n",
    "if not os.path.isfile(map_path):\n",
    "    acc_map = np.zeros((55, 55))\n",
    "    seed = 0\n",
    "    for i_offset in range(-27,28):\n",
    "        for j_offset in range(-27,28):\n",
    "            transform=transforms.Compose([\n",
    "                                   WhatShift(args, i_offset=i_offset, j_offset=j_offset),\n",
    "                                   WhatBackground(contrast = args.contrast,\n",
    "                                                  noise=args.noise, \n",
    "                                                  sf_0=args.sf_0, \n",
    "                                                  B_sf=args.B_sf,\n",
    "                                                  seed = seed),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   #transforms.Normalize((args.mean,), (args.std,))\n",
    "                               ])\n",
    "            dataset_test = MNIST('../data',\n",
    "                            train=False,\n",
    "                            download=True,\n",
    "                            transform=transform,\n",
    "                            )\n",
    "            test_loader = torch.utils.data.DataLoader(dataset_test,\n",
    "                                             batch_size=args.minibatch_size,\n",
    "                                             shuffle=True)\n",
    "            whatTrainer = WhatTrainer(args, model = what_model, test_loader = test_loader, seed = seed)\n",
    "            acc = whatTrainer.test()\n",
    "            print(i_offset, j_offset, acc)\n",
    "            acc_map[i_offset + 27, j_offset + 27] = acc\n",
    "            seed += 1\n",
    "    np.save(map_path, acc_map)        \n",
    "else:\n",
    "    acc_map = np.load(map_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage Accuracy map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "for i in range(55):\n",
    "    for j in range(55):\n",
    "        acc_map[i,j] = max(acc_map[i,j], 0.1)\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "X = np.arange(-27, 28)\n",
    "Y = np.arange(-27, 28)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "surf = ax.plot_surface(X, Y, acc_map, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=True, alpha=0.5)\n",
    "\n",
    "#ax.plot_surface(X, Y, Z, rstride=8, cstride=8, alpha=0.3)\n",
    "cset = ax.contour(X, Y, acc_map, [0.2, 0.3, 0.4, 0.5, 0.6, 0.7], zdir='z', offset=0, cmap=cm.coolwarm, alpha = 1)\n",
    "cset = ax.contour(X, Y, acc_map, [-20, -10, 0, 10, 20], zdir='x', offset=-27.5, cmap = 'gray')\n",
    "cset = ax.contour(X, Y, acc_map,  [-20, -10, 0, 10, 20], zdir='y', offset=27.5, cmap = 'gray')\n",
    "\n",
    "\n",
    "# Customize the z axis.\n",
    "ax.set_xlim(-27.5, 27.5)\n",
    "ax.set_zlim(-27.5, 27.5)\n",
    "ax.set_zlim(0, 0.8)\n",
    "ax.zaxis.set_major_locator(LinearLocator(9))\n",
    "ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "ax.set_title('Classification accuracy', size=15)\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "cbar = fig.colorbar(surf, shrink=0.5, aspect=5, ticks=[0.2,0.3,0.4,0.5,0.6,0.7,0.8])\n",
    "\n",
    "figname = '../figures/what_map'\n",
    "fig.savefig(figname + '.png', bbox_inches='tight', pad_inches=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
