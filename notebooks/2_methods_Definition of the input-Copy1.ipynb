{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n",
      "This notebook introduces the problem addressed in this paper:\n",
      "\n",
      " - localizating an object in a large image\n",
      " - foveation\n",
      " - action (saccade)\n",
      "       \n",
      "      \n",
      "{'w': 28, 'minibatch_size': 100, 'train_batch_size': 50000, 'test_batch_size': 10000, 'noise_batch_size': 1000, 'mean': 0.1307, 'std': 0.3081, 'what_offset_std': 15, 'what_offset_max': 25, 'N_pic': 128, 'offset_std': 30, 'offset_max': 34, 'noise': 0.75, 'contrast': 0.7, 'sf_0': 0.1, 'B_sf': 0.1, 'do_mask': True, 'N_theta': 6, 'N_azimuth': 24, 'N_eccentricity': 10, 'N_phase': 2, 'rho': 1.41, 'bias_deconv': True, 'p_dropout': 0.0, 'dim1': 1000, 'dim2': 1000, 'lr': 0.005, 'do_adam': True, 'bn1_bn_momentum': 0.5, 'bn2_bn_momentum': 0.5, 'momentum': 0.3, 'epochs': 60, 'num_processes': 1, 'no_cuda': False, 'log_interval': 100, 'verbose': 1, 'filename': '../data/2020-07-01', 'seed': 2019, 'N_cv': 10, 'do_compute': True, 'save_model': True}\n",
      "Overwriting train.py\n",
      "2020-06-30T09:51:09+00:00\n",
      "\n",
      "CPython 3.6.9\n",
      "IPython 7.9.0\n",
      "\n",
      "numpy 1.19.0\n",
      "matplotlib 3.1.2\n",
      "torch 1.5.1\n",
      "\n",
      "compiler   : GCC 8.4.0\n",
      "system     : Linux\n",
      "release    : 4.15.0-108-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "host name  : inv-ope-de06\n",
      "Git hash   : dcdca09e8930f5d817ad813dd32a8c0fd7bfcad4\n",
      "Git repo   : https://github.com/laurentperrinet/WhereIsMyMNIST\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "%run 0_parameters.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "figname = '../figures/fig_methods_sup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w': 28,\n",
       " 'minibatch_size': 100,\n",
       " 'train_batch_size': 50000,\n",
       " 'test_batch_size': 10000,\n",
       " 'noise_batch_size': 1000,\n",
       " 'mean': 0.1307,\n",
       " 'std': 0.3081,\n",
       " 'what_offset_std': 15,\n",
       " 'what_offset_max': 25,\n",
       " 'N_pic': 128,\n",
       " 'offset_std': 30,\n",
       " 'offset_max': 34,\n",
       " 'noise': 0.75,\n",
       " 'contrast': 0.7,\n",
       " 'sf_0': 0.1,\n",
       " 'B_sf': 0.1,\n",
       " 'do_mask': True,\n",
       " 'N_theta': 6,\n",
       " 'N_azimuth': 24,\n",
       " 'N_eccentricity': 10,\n",
       " 'N_phase': 2,\n",
       " 'rho': 1.41,\n",
       " 'bias_deconv': True,\n",
       " 'p_dropout': 0.0,\n",
       " 'dim1': 1000,\n",
       " 'dim2': 1000,\n",
       " 'lr': 0.005,\n",
       " 'do_adam': True,\n",
       " 'bn1_bn_momentum': 0.5,\n",
       " 'bn2_bn_momentum': 0.5,\n",
       " 'momentum': 0.3,\n",
       " 'epochs': 60,\n",
       " 'num_processes': 1,\n",
       " 'no_cuda': False,\n",
       " 'log_interval': 100,\n",
       " 'verbose': 1,\n",
       " 'filename': '../data/2020-07-01',\n",
       " 'seed': 2019,\n",
       " 'N_cv': 10,\n",
       " 'do_compute': True,\n",
       " 'save_model': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the accuracy of the classifier (What) wrt to spatial shifts\n",
    "\n",
    "On commence par la fonction de base apprise de la librairie torch, cf https://raw.githubusercontent.com/pytorch/examples/master/mnist/main.py :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable        Type        Data/Info\n",
      "-------------------------------------\n",
      "args            EasyDict    {'w': 28, 'minibatch_size<...>True, 'save_model': True}\n",
      "code            QRCode      QRCode(content=b'https://<...>version=6, mode='binary')\n",
      "dpi_export      int         600\n",
      "fig_width_pt    int         1024\n",
      "figname         str         ../figures/fig_methods_sup\n",
      "figwidth        float       14.169088141690882\n",
      "inches_per_pt   float       0.013837000138370002\n",
      "init            function    <function init at 0x7f7b8ef36d90>\n",
      "np              module      <module 'numpy' from '/ho<...>kages/numpy/__init__.py'>\n",
      "os              module      <module 'os' from '/usr/lib/python3.6/os.py'>\n",
      "phi             float64     1.618033988749895\n",
      "plt             module      <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
      "ppi             float       72.27\n",
      "pq              module      <module 'pyqrcode' from '<...>es/pyqrcode/__init__.py'>\n",
      "torch           module      <module 'torch' from '/ho<...>kages/torch/__init__.py'>\n",
      "tqdm            function    <function tqdm_notebook at 0x7f7b8ef36a60>\n",
      "url             str         https://github.com/lauren<...>tperrinet/WhereIsMyMNIST/\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from what import WhatNet\n",
    "model = WhatNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On apprend une matrice de poids qui est fixée dans la suite et que nous allons utiliser pour la classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:35.317080Z",
     "start_time": "2018-02-16T19:37:35.297625Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path = \"../data/MNIST_cnn.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '../data/MNIST_cnn.pt': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "%ls -ltr {model_path}\n",
    "#%rm -f {model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:35.317080Z",
     "start_time": "2018-02-16T19:37:35.297625Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning\n",
      "use_cuda True\n",
      "Training the What model\n",
      "Train Epoch: 1/60 [0/60000 (0%)]\tLoss: 2.302170\n",
      "Train Epoch: 1/60 [10000/60000 (17%)]\tLoss: 2.302622\n",
      "Train Epoch: 1/60 [20000/60000 (33%)]\tLoss: 2.297431\n",
      "Train Epoch: 1/60 [30000/60000 (50%)]\tLoss: 2.303493\n",
      "Train Epoch: 1/60 [40000/60000 (67%)]\tLoss: 2.292274\n",
      "Train Epoch: 1/60 [50000/60000 (83%)]\tLoss: 2.302521\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 2/60 [0/60000 (0%)]\tLoss: 2.291935\n",
      "Train Epoch: 2/60 [10000/60000 (17%)]\tLoss: 2.293992\n",
      "Train Epoch: 2/60 [20000/60000 (33%)]\tLoss: 2.296294\n",
      "Train Epoch: 2/60 [30000/60000 (50%)]\tLoss: 2.296739\n",
      "Train Epoch: 2/60 [40000/60000 (67%)]\tLoss: 2.306677\n",
      "Train Epoch: 2/60 [50000/60000 (83%)]\tLoss: 2.305442\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 3/60 [0/60000 (0%)]\tLoss: 2.294444\n",
      "Train Epoch: 3/60 [10000/60000 (17%)]\tLoss: 2.297145\n",
      "Train Epoch: 3/60 [20000/60000 (33%)]\tLoss: 2.302402\n",
      "Train Epoch: 3/60 [30000/60000 (50%)]\tLoss: 2.306619\n",
      "Train Epoch: 3/60 [40000/60000 (67%)]\tLoss: 2.311404\n",
      "Train Epoch: 3/60 [50000/60000 (83%)]\tLoss: 2.299656\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 4/60 [0/60000 (0%)]\tLoss: 2.299441\n",
      "Train Epoch: 4/60 [10000/60000 (17%)]\tLoss: 2.313113\n",
      "Train Epoch: 4/60 [20000/60000 (33%)]\tLoss: 2.296300\n",
      "Train Epoch: 4/60 [30000/60000 (50%)]\tLoss: 2.305544\n",
      "Train Epoch: 4/60 [40000/60000 (67%)]\tLoss: 2.300251\n",
      "Train Epoch: 4/60 [50000/60000 (83%)]\tLoss: 2.301724\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 5/60 [0/60000 (0%)]\tLoss: 2.292831\n",
      "Train Epoch: 5/60 [10000/60000 (17%)]\tLoss: 2.293259\n",
      "Train Epoch: 5/60 [20000/60000 (33%)]\tLoss: 2.301229\n",
      "Train Epoch: 5/60 [30000/60000 (50%)]\tLoss: 2.305738\n",
      "Train Epoch: 5/60 [40000/60000 (67%)]\tLoss: 2.301269\n",
      "Train Epoch: 5/60 [50000/60000 (83%)]\tLoss: 2.291744\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 6/60 [0/60000 (0%)]\tLoss: 2.298245\n",
      "Train Epoch: 6/60 [10000/60000 (17%)]\tLoss: 2.311902\n",
      "Train Epoch: 6/60 [20000/60000 (33%)]\tLoss: 2.306968\n",
      "Train Epoch: 6/60 [30000/60000 (50%)]\tLoss: 2.296989\n",
      "Train Epoch: 6/60 [40000/60000 (67%)]\tLoss: 2.310636\n",
      "Train Epoch: 6/60 [50000/60000 (83%)]\tLoss: 2.304579\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 7/60 [0/60000 (0%)]\tLoss: 2.292933\n",
      "Train Epoch: 7/60 [10000/60000 (17%)]\tLoss: 2.301055\n",
      "Train Epoch: 7/60 [20000/60000 (33%)]\tLoss: 2.302297\n",
      "Train Epoch: 7/60 [30000/60000 (50%)]\tLoss: 2.295755\n",
      "Train Epoch: 7/60 [40000/60000 (67%)]\tLoss: 2.299679\n",
      "Train Epoch: 7/60 [50000/60000 (83%)]\tLoss: 2.300771\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1028/10000 (10%)\n",
      "\n",
      "Train Epoch: 8/60 [0/60000 (0%)]\tLoss: 2.303116\n",
      "Train Epoch: 8/60 [10000/60000 (17%)]\tLoss: 2.293061\n",
      "Train Epoch: 8/60 [20000/60000 (33%)]\tLoss: 2.295948\n",
      "Train Epoch: 8/60 [30000/60000 (50%)]\tLoss: 2.302579\n",
      "Train Epoch: 8/60 [40000/60000 (67%)]\tLoss: 2.305673\n",
      "Train Epoch: 8/60 [50000/60000 (83%)]\tLoss: 2.309774\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 9/60 [0/60000 (0%)]\tLoss: 2.303767\n",
      "Train Epoch: 9/60 [10000/60000 (17%)]\tLoss: 2.303232\n",
      "Train Epoch: 9/60 [20000/60000 (33%)]\tLoss: 2.302728\n",
      "Train Epoch: 9/60 [30000/60000 (50%)]\tLoss: 2.296794\n",
      "Train Epoch: 9/60 [40000/60000 (67%)]\tLoss: 2.298907\n",
      "Train Epoch: 9/60 [50000/60000 (83%)]\tLoss: 2.302363\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 10/60 [0/60000 (0%)]\tLoss: 2.308477\n",
      "Train Epoch: 10/60 [10000/60000 (17%)]\tLoss: 2.299305\n",
      "Train Epoch: 10/60 [20000/60000 (33%)]\tLoss: 2.310234\n",
      "Train Epoch: 10/60 [30000/60000 (50%)]\tLoss: 2.304441\n",
      "Train Epoch: 10/60 [40000/60000 (67%)]\tLoss: 2.292053\n",
      "Train Epoch: 10/60 [50000/60000 (83%)]\tLoss: 2.305756\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 11/60 [0/60000 (0%)]\tLoss: 2.302441\n",
      "Train Epoch: 11/60 [10000/60000 (17%)]\tLoss: 2.302311\n",
      "Train Epoch: 11/60 [20000/60000 (33%)]\tLoss: 2.315677\n",
      "Train Epoch: 11/60 [30000/60000 (50%)]\tLoss: 2.290581\n",
      "Train Epoch: 11/60 [40000/60000 (67%)]\tLoss: 2.305585\n",
      "Train Epoch: 11/60 [50000/60000 (83%)]\tLoss: 2.299893\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 12/60 [0/60000 (0%)]\tLoss: 2.294465\n",
      "Train Epoch: 12/60 [10000/60000 (17%)]\tLoss: 2.284240\n",
      "Train Epoch: 12/60 [20000/60000 (33%)]\tLoss: 2.301818\n",
      "Train Epoch: 12/60 [30000/60000 (50%)]\tLoss: 2.310539\n",
      "Train Epoch: 12/60 [40000/60000 (67%)]\tLoss: 2.302171\n",
      "Train Epoch: 12/60 [50000/60000 (83%)]\tLoss: 2.294456\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 13/60 [0/60000 (0%)]\tLoss: 2.302726\n",
      "Train Epoch: 13/60 [10000/60000 (17%)]\tLoss: 2.308930\n",
      "Train Epoch: 13/60 [20000/60000 (33%)]\tLoss: 2.304640\n",
      "Train Epoch: 13/60 [30000/60000 (50%)]\tLoss: 2.309464\n",
      "Train Epoch: 13/60 [40000/60000 (67%)]\tLoss: 2.301328\n",
      "Train Epoch: 13/60 [50000/60000 (83%)]\tLoss: 2.292706\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 14/60 [0/60000 (0%)]\tLoss: 2.310334\n",
      "Train Epoch: 14/60 [10000/60000 (17%)]\tLoss: 2.297662\n",
      "Train Epoch: 14/60 [20000/60000 (33%)]\tLoss: 2.300799\n",
      "Train Epoch: 14/60 [30000/60000 (50%)]\tLoss: 2.308416\n",
      "Train Epoch: 14/60 [40000/60000 (67%)]\tLoss: 2.298797\n",
      "Train Epoch: 14/60 [50000/60000 (83%)]\tLoss: 2.301859\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 15/60 [0/60000 (0%)]\tLoss: 2.311772\n",
      "Train Epoch: 15/60 [10000/60000 (17%)]\tLoss: 2.305984\n",
      "Train Epoch: 15/60 [20000/60000 (33%)]\tLoss: 2.314564\n",
      "Train Epoch: 15/60 [30000/60000 (50%)]\tLoss: 2.305361\n",
      "Train Epoch: 15/60 [40000/60000 (67%)]\tLoss: 2.315123\n",
      "Train Epoch: 15/60 [50000/60000 (83%)]\tLoss: 2.299494\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 16/60 [0/60000 (0%)]\tLoss: 2.307227\n",
      "Train Epoch: 16/60 [10000/60000 (17%)]\tLoss: 2.301142\n",
      "Train Epoch: 16/60 [20000/60000 (33%)]\tLoss: 2.295062\n",
      "Train Epoch: 16/60 [30000/60000 (50%)]\tLoss: 2.300306\n",
      "Train Epoch: 16/60 [40000/60000 (67%)]\tLoss: 2.294961\n",
      "Train Epoch: 16/60 [50000/60000 (83%)]\tLoss: 2.295324\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 17/60 [0/60000 (0%)]\tLoss: 2.291798\n",
      "Train Epoch: 17/60 [10000/60000 (17%)]\tLoss: 2.292331\n",
      "Train Epoch: 17/60 [20000/60000 (33%)]\tLoss: 2.299292\n",
      "Train Epoch: 17/60 [30000/60000 (50%)]\tLoss: 2.291694\n",
      "Train Epoch: 17/60 [40000/60000 (67%)]\tLoss: 2.308158\n",
      "Train Epoch: 17/60 [50000/60000 (83%)]\tLoss: 2.298943\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 18/60 [0/60000 (0%)]\tLoss: 2.293362\n",
      "Train Epoch: 18/60 [10000/60000 (17%)]\tLoss: 2.295037\n",
      "Train Epoch: 18/60 [20000/60000 (33%)]\tLoss: 2.313445\n",
      "Train Epoch: 18/60 [30000/60000 (50%)]\tLoss: 2.300227\n",
      "Train Epoch: 18/60 [40000/60000 (67%)]\tLoss: 2.304648\n",
      "Train Epoch: 18/60 [50000/60000 (83%)]\tLoss: 2.303648\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 19/60 [0/60000 (0%)]\tLoss: 2.300070\n",
      "Train Epoch: 19/60 [10000/60000 (17%)]\tLoss: 2.298706\n",
      "Train Epoch: 19/60 [20000/60000 (33%)]\tLoss: 2.295944\n",
      "Train Epoch: 19/60 [30000/60000 (50%)]\tLoss: 2.297363\n",
      "Train Epoch: 19/60 [40000/60000 (67%)]\tLoss: 2.296178\n",
      "Train Epoch: 19/60 [50000/60000 (83%)]\tLoss: 2.300672\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 20/60 [0/60000 (0%)]\tLoss: 2.301700\n",
      "Train Epoch: 20/60 [10000/60000 (17%)]\tLoss: 2.300332\n",
      "Train Epoch: 20/60 [20000/60000 (33%)]\tLoss: 2.295600\n",
      "Train Epoch: 20/60 [30000/60000 (50%)]\tLoss: 2.297542\n",
      "Train Epoch: 20/60 [40000/60000 (67%)]\tLoss: 2.299893\n",
      "Train Epoch: 20/60 [50000/60000 (83%)]\tLoss: 2.295919\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 21/60 [0/60000 (0%)]\tLoss: 2.311928\n",
      "Train Epoch: 21/60 [10000/60000 (17%)]\tLoss: 2.303350\n",
      "Train Epoch: 21/60 [20000/60000 (33%)]\tLoss: 2.312715\n",
      "Train Epoch: 21/60 [30000/60000 (50%)]\tLoss: 2.302283\n",
      "Train Epoch: 21/60 [40000/60000 (67%)]\tLoss: 2.300709\n",
      "Train Epoch: 21/60 [50000/60000 (83%)]\tLoss: 2.300223\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 22/60 [0/60000 (0%)]\tLoss: 2.309887\n",
      "Train Epoch: 22/60 [10000/60000 (17%)]\tLoss: 2.299864\n",
      "Train Epoch: 22/60 [20000/60000 (33%)]\tLoss: 2.304918\n",
      "Train Epoch: 22/60 [30000/60000 (50%)]\tLoss: 2.299490\n",
      "Train Epoch: 22/60 [40000/60000 (67%)]\tLoss: 2.306799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22/60 [50000/60000 (83%)]\tLoss: 2.302759\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 23/60 [0/60000 (0%)]\tLoss: 2.302987\n",
      "Train Epoch: 23/60 [10000/60000 (17%)]\tLoss: 2.312592\n",
      "Train Epoch: 23/60 [20000/60000 (33%)]\tLoss: 2.304318\n",
      "Train Epoch: 23/60 [30000/60000 (50%)]\tLoss: 2.307711\n",
      "Train Epoch: 23/60 [40000/60000 (67%)]\tLoss: 2.303343\n",
      "Train Epoch: 23/60 [50000/60000 (83%)]\tLoss: 2.296190\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 24/60 [0/60000 (0%)]\tLoss: 2.303475\n",
      "Train Epoch: 24/60 [10000/60000 (17%)]\tLoss: 2.304190\n",
      "Train Epoch: 24/60 [20000/60000 (33%)]\tLoss: 2.299060\n",
      "Train Epoch: 24/60 [30000/60000 (50%)]\tLoss: 2.307139\n",
      "Train Epoch: 24/60 [40000/60000 (67%)]\tLoss: 2.297291\n",
      "Train Epoch: 24/60 [50000/60000 (83%)]\tLoss: 2.299153\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 25/60 [0/60000 (0%)]\tLoss: 2.305438\n",
      "Train Epoch: 25/60 [10000/60000 (17%)]\tLoss: 2.293175\n",
      "Train Epoch: 25/60 [20000/60000 (33%)]\tLoss: 2.293109\n",
      "Train Epoch: 25/60 [30000/60000 (50%)]\tLoss: 2.293635\n",
      "Train Epoch: 25/60 [40000/60000 (67%)]\tLoss: 2.300503\n",
      "Train Epoch: 25/60 [50000/60000 (83%)]\tLoss: 2.305143\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 26/60 [0/60000 (0%)]\tLoss: 2.305515\n",
      "Train Epoch: 26/60 [10000/60000 (17%)]\tLoss: 2.304292\n",
      "Train Epoch: 26/60 [20000/60000 (33%)]\tLoss: 2.286884\n",
      "Train Epoch: 26/60 [30000/60000 (50%)]\tLoss: 2.294157\n",
      "Train Epoch: 26/60 [40000/60000 (67%)]\tLoss: 2.298425\n",
      "Train Epoch: 26/60 [50000/60000 (83%)]\tLoss: 2.306477\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 27/60 [0/60000 (0%)]\tLoss: 2.297483\n",
      "Train Epoch: 27/60 [10000/60000 (17%)]\tLoss: 2.288628\n",
      "Train Epoch: 27/60 [20000/60000 (33%)]\tLoss: 2.295384\n",
      "Train Epoch: 27/60 [30000/60000 (50%)]\tLoss: 2.304539\n",
      "Train Epoch: 27/60 [40000/60000 (67%)]\tLoss: 2.307751\n",
      "Train Epoch: 27/60 [50000/60000 (83%)]\tLoss: 2.294360\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 28/60 [0/60000 (0%)]\tLoss: 2.304235\n",
      "Train Epoch: 28/60 [10000/60000 (17%)]\tLoss: 2.305888\n",
      "Train Epoch: 28/60 [20000/60000 (33%)]\tLoss: 2.304580\n",
      "Train Epoch: 28/60 [30000/60000 (50%)]\tLoss: 2.298859\n",
      "Train Epoch: 28/60 [40000/60000 (67%)]\tLoss: 2.297390\n",
      "Train Epoch: 28/60 [50000/60000 (83%)]\tLoss: 2.301312\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 29/60 [0/60000 (0%)]\tLoss: 2.300928\n",
      "Train Epoch: 29/60 [10000/60000 (17%)]\tLoss: 2.296941\n",
      "Train Epoch: 29/60 [20000/60000 (33%)]\tLoss: 2.309842\n",
      "Train Epoch: 29/60 [30000/60000 (50%)]\tLoss: 2.298752\n",
      "Train Epoch: 29/60 [40000/60000 (67%)]\tLoss: 2.316016\n",
      "Train Epoch: 29/60 [50000/60000 (83%)]\tLoss: 2.307607\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 30/60 [0/60000 (0%)]\tLoss: 2.303263\n",
      "Train Epoch: 30/60 [10000/60000 (17%)]\tLoss: 2.299228\n",
      "Train Epoch: 30/60 [20000/60000 (33%)]\tLoss: 2.291407\n",
      "Train Epoch: 30/60 [30000/60000 (50%)]\tLoss: 2.304714\n",
      "Train Epoch: 30/60 [40000/60000 (67%)]\tLoss: 2.296808\n",
      "Train Epoch: 30/60 [50000/60000 (83%)]\tLoss: 2.306232\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 31/60 [0/60000 (0%)]\tLoss: 2.298907\n",
      "Train Epoch: 31/60 [10000/60000 (17%)]\tLoss: 2.303001\n",
      "Train Epoch: 31/60 [20000/60000 (33%)]\tLoss: 2.298215\n",
      "Train Epoch: 31/60 [30000/60000 (50%)]\tLoss: 2.296535\n",
      "Train Epoch: 31/60 [40000/60000 (67%)]\tLoss: 2.310622\n",
      "Train Epoch: 31/60 [50000/60000 (83%)]\tLoss: 2.306661\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 32/60 [0/60000 (0%)]\tLoss: 2.297530\n",
      "Train Epoch: 32/60 [10000/60000 (17%)]\tLoss: 2.310205\n",
      "Train Epoch: 32/60 [20000/60000 (33%)]\tLoss: 2.306366\n",
      "Train Epoch: 32/60 [30000/60000 (50%)]\tLoss: 2.307263\n",
      "Train Epoch: 32/60 [40000/60000 (67%)]\tLoss: 2.295775\n",
      "Train Epoch: 32/60 [50000/60000 (83%)]\tLoss: 2.314678\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 33/60 [0/60000 (0%)]\tLoss: 2.296033\n",
      "Train Epoch: 33/60 [10000/60000 (17%)]\tLoss: 2.309735\n",
      "Train Epoch: 33/60 [20000/60000 (33%)]\tLoss: 2.296316\n",
      "Train Epoch: 33/60 [30000/60000 (50%)]\tLoss: 2.304875\n",
      "Train Epoch: 33/60 [40000/60000 (67%)]\tLoss: 2.308057\n",
      "Train Epoch: 33/60 [50000/60000 (83%)]\tLoss: 2.291363\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 34/60 [0/60000 (0%)]\tLoss: 2.297669\n",
      "Train Epoch: 34/60 [10000/60000 (17%)]\tLoss: 2.301465\n",
      "Train Epoch: 34/60 [20000/60000 (33%)]\tLoss: 2.304868\n",
      "Train Epoch: 34/60 [30000/60000 (50%)]\tLoss: 2.288537\n",
      "Train Epoch: 34/60 [40000/60000 (67%)]\tLoss: 2.303225\n",
      "Train Epoch: 34/60 [50000/60000 (83%)]\tLoss: 2.312489\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 35/60 [0/60000 (0%)]\tLoss: 2.300847\n",
      "Train Epoch: 35/60 [10000/60000 (17%)]\tLoss: 2.305120\n",
      "Train Epoch: 35/60 [20000/60000 (33%)]\tLoss: 2.289909\n",
      "Train Epoch: 35/60 [30000/60000 (50%)]\tLoss: 2.304022\n",
      "Train Epoch: 35/60 [40000/60000 (67%)]\tLoss: 2.298817\n",
      "Train Epoch: 35/60 [50000/60000 (83%)]\tLoss: 2.310909\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 36/60 [0/60000 (0%)]\tLoss: 2.298161\n",
      "Train Epoch: 36/60 [10000/60000 (17%)]\tLoss: 2.296297\n",
      "Train Epoch: 36/60 [20000/60000 (33%)]\tLoss: 2.290846\n",
      "Train Epoch: 36/60 [30000/60000 (50%)]\tLoss: 2.306669\n",
      "Train Epoch: 36/60 [40000/60000 (67%)]\tLoss: 2.306359\n",
      "Train Epoch: 36/60 [50000/60000 (83%)]\tLoss: 2.303008\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 37/60 [0/60000 (0%)]\tLoss: 2.297893\n",
      "Train Epoch: 37/60 [10000/60000 (17%)]\tLoss: 2.307463\n",
      "Train Epoch: 37/60 [20000/60000 (33%)]\tLoss: 2.301405\n",
      "Train Epoch: 37/60 [30000/60000 (50%)]\tLoss: 2.301208\n",
      "Train Epoch: 37/60 [40000/60000 (67%)]\tLoss: 2.303736\n",
      "Train Epoch: 37/60 [50000/60000 (83%)]\tLoss: 2.302379\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 38/60 [0/60000 (0%)]\tLoss: 2.305446\n",
      "Train Epoch: 38/60 [10000/60000 (17%)]\tLoss: 2.295697\n",
      "Train Epoch: 38/60 [20000/60000 (33%)]\tLoss: 2.299535\n",
      "Train Epoch: 38/60 [30000/60000 (50%)]\tLoss: 2.298881\n",
      "Train Epoch: 38/60 [40000/60000 (67%)]\tLoss: 2.294534\n",
      "Train Epoch: 38/60 [50000/60000 (83%)]\tLoss: 2.305397\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 39/60 [0/60000 (0%)]\tLoss: 2.305337\n",
      "Train Epoch: 39/60 [10000/60000 (17%)]\tLoss: 2.308661\n",
      "Train Epoch: 39/60 [20000/60000 (33%)]\tLoss: 2.299744\n",
      "Train Epoch: 39/60 [30000/60000 (50%)]\tLoss: 2.302859\n",
      "Train Epoch: 39/60 [40000/60000 (67%)]\tLoss: 2.307716\n",
      "Train Epoch: 39/60 [50000/60000 (83%)]\tLoss: 2.291353\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 40/60 [0/60000 (0%)]\tLoss: 2.299744\n",
      "Train Epoch: 40/60 [10000/60000 (17%)]\tLoss: 2.299781\n",
      "Train Epoch: 40/60 [20000/60000 (33%)]\tLoss: 2.299209\n",
      "Train Epoch: 40/60 [30000/60000 (50%)]\tLoss: 2.302909\n",
      "Train Epoch: 40/60 [40000/60000 (67%)]\tLoss: 2.304252\n",
      "Train Epoch: 40/60 [50000/60000 (83%)]\tLoss: 2.301176\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 41/60 [0/60000 (0%)]\tLoss: 2.298155\n",
      "Train Epoch: 41/60 [10000/60000 (17%)]\tLoss: 2.307458\n",
      "Train Epoch: 41/60 [20000/60000 (33%)]\tLoss: 2.307528\n",
      "Train Epoch: 41/60 [30000/60000 (50%)]\tLoss: 2.299710\n",
      "Train Epoch: 41/60 [40000/60000 (67%)]\tLoss: 2.311341\n",
      "Train Epoch: 41/60 [50000/60000 (83%)]\tLoss: 2.301736\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 42/60 [0/60000 (0%)]\tLoss: 2.295823\n",
      "Train Epoch: 42/60 [10000/60000 (17%)]\tLoss: 2.306912\n",
      "Train Epoch: 42/60 [20000/60000 (33%)]\tLoss: 2.306521\n",
      "Train Epoch: 42/60 [30000/60000 (50%)]\tLoss: 2.292384\n",
      "Train Epoch: 42/60 [40000/60000 (67%)]\tLoss: 2.297992\n",
      "Train Epoch: 42/60 [50000/60000 (83%)]\tLoss: 2.306378\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 43/60 [0/60000 (0%)]\tLoss: 2.306842\n",
      "Train Epoch: 43/60 [10000/60000 (17%)]\tLoss: 2.292651\n",
      "Train Epoch: 43/60 [20000/60000 (33%)]\tLoss: 2.300749\n",
      "Train Epoch: 43/60 [30000/60000 (50%)]\tLoss: 2.301513\n",
      "Train Epoch: 43/60 [40000/60000 (67%)]\tLoss: 2.296860\n",
      "Train Epoch: 43/60 [50000/60000 (83%)]\tLoss: 2.307656\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 44/60 [0/60000 (0%)]\tLoss: 2.300693\n",
      "Train Epoch: 44/60 [10000/60000 (17%)]\tLoss: 2.300168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 44/60 [20000/60000 (33%)]\tLoss: 2.302622\n",
      "Train Epoch: 44/60 [30000/60000 (50%)]\tLoss: 2.305707\n",
      "Train Epoch: 44/60 [40000/60000 (67%)]\tLoss: 2.307292\n",
      "Train Epoch: 44/60 [50000/60000 (83%)]\tLoss: 2.300454\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 45/60 [0/60000 (0%)]\tLoss: 2.310520\n",
      "Train Epoch: 45/60 [10000/60000 (17%)]\tLoss: 2.305330\n",
      "Train Epoch: 45/60 [20000/60000 (33%)]\tLoss: 2.304358\n",
      "Train Epoch: 45/60 [30000/60000 (50%)]\tLoss: 2.299617\n",
      "Train Epoch: 45/60 [40000/60000 (67%)]\tLoss: 2.300817\n",
      "Train Epoch: 45/60 [50000/60000 (83%)]\tLoss: 2.302171\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 46/60 [0/60000 (0%)]\tLoss: 2.312762\n",
      "Train Epoch: 46/60 [10000/60000 (17%)]\tLoss: 2.303669\n",
      "Train Epoch: 46/60 [20000/60000 (33%)]\tLoss: 2.304850\n",
      "Train Epoch: 46/60 [30000/60000 (50%)]\tLoss: 2.293423\n",
      "Train Epoch: 46/60 [40000/60000 (67%)]\tLoss: 2.298818\n",
      "Train Epoch: 46/60 [50000/60000 (83%)]\tLoss: 2.307284\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 47/60 [0/60000 (0%)]\tLoss: 2.300170\n",
      "Train Epoch: 47/60 [10000/60000 (17%)]\tLoss: 2.286137\n",
      "Train Epoch: 47/60 [20000/60000 (33%)]\tLoss: 2.308507\n",
      "Train Epoch: 47/60 [30000/60000 (50%)]\tLoss: 2.298356\n",
      "Train Epoch: 47/60 [40000/60000 (67%)]\tLoss: 2.301242\n",
      "Train Epoch: 47/60 [50000/60000 (83%)]\tLoss: 2.307392\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 48/60 [0/60000 (0%)]\tLoss: 2.309413\n",
      "Train Epoch: 48/60 [10000/60000 (17%)]\tLoss: 2.304127\n",
      "Train Epoch: 48/60 [20000/60000 (33%)]\tLoss: 2.308516\n",
      "Train Epoch: 48/60 [30000/60000 (50%)]\tLoss: 2.299868\n",
      "Train Epoch: 48/60 [40000/60000 (67%)]\tLoss: 2.295960\n",
      "Train Epoch: 48/60 [50000/60000 (83%)]\tLoss: 2.310598\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 49/60 [0/60000 (0%)]\tLoss: 2.308917\n",
      "Train Epoch: 49/60 [10000/60000 (17%)]\tLoss: 2.309232\n",
      "Train Epoch: 49/60 [20000/60000 (33%)]\tLoss: 2.311487\n",
      "Train Epoch: 49/60 [30000/60000 (50%)]\tLoss: 2.304365\n",
      "Train Epoch: 49/60 [40000/60000 (67%)]\tLoss: 2.303008\n",
      "Train Epoch: 49/60 [50000/60000 (83%)]\tLoss: 2.305600\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 50/60 [0/60000 (0%)]\tLoss: 2.292333\n",
      "Train Epoch: 50/60 [10000/60000 (17%)]\tLoss: 2.298942\n",
      "Train Epoch: 50/60 [20000/60000 (33%)]\tLoss: 2.300390\n",
      "Train Epoch: 50/60 [30000/60000 (50%)]\tLoss: 2.299755\n",
      "Train Epoch: 50/60 [40000/60000 (67%)]\tLoss: 2.288709\n",
      "Train Epoch: 50/60 [50000/60000 (83%)]\tLoss: 2.302265\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 51/60 [0/60000 (0%)]\tLoss: 2.293509\n",
      "Train Epoch: 51/60 [10000/60000 (17%)]\tLoss: 2.305290\n",
      "Train Epoch: 51/60 [20000/60000 (33%)]\tLoss: 2.307023\n",
      "Train Epoch: 51/60 [30000/60000 (50%)]\tLoss: 2.300394\n",
      "Train Epoch: 51/60 [40000/60000 (67%)]\tLoss: 2.300091\n",
      "Train Epoch: 51/60 [50000/60000 (83%)]\tLoss: 2.296829\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 52/60 [0/60000 (0%)]\tLoss: 2.312041\n",
      "Train Epoch: 52/60 [10000/60000 (17%)]\tLoss: 2.302308\n",
      "Train Epoch: 52/60 [20000/60000 (33%)]\tLoss: 2.303191\n",
      "Train Epoch: 52/60 [30000/60000 (50%)]\tLoss: 2.307892\n",
      "Train Epoch: 52/60 [40000/60000 (67%)]\tLoss: 2.295575\n",
      "Train Epoch: 52/60 [50000/60000 (83%)]\tLoss: 2.297219\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 53/60 [0/60000 (0%)]\tLoss: 2.302829\n",
      "Train Epoch: 53/60 [10000/60000 (17%)]\tLoss: 2.311359\n",
      "Train Epoch: 53/60 [20000/60000 (33%)]\tLoss: 2.297249\n",
      "Train Epoch: 53/60 [30000/60000 (50%)]\tLoss: 2.305912\n",
      "Train Epoch: 53/60 [40000/60000 (67%)]\tLoss: 2.299014\n",
      "Train Epoch: 53/60 [50000/60000 (83%)]\tLoss: 2.296302\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 54/60 [0/60000 (0%)]\tLoss: 2.293742\n",
      "Train Epoch: 54/60 [10000/60000 (17%)]\tLoss: 2.303620\n",
      "Train Epoch: 54/60 [20000/60000 (33%)]\tLoss: 2.317492\n",
      "Train Epoch: 54/60 [30000/60000 (50%)]\tLoss: 2.300898\n",
      "Train Epoch: 54/60 [40000/60000 (67%)]\tLoss: 2.302301\n",
      "Train Epoch: 54/60 [50000/60000 (83%)]\tLoss: 2.308833\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 55/60 [0/60000 (0%)]\tLoss: 2.311629\n",
      "Train Epoch: 55/60 [10000/60000 (17%)]\tLoss: 2.299554\n",
      "Train Epoch: 55/60 [20000/60000 (33%)]\tLoss: 2.306051\n",
      "Train Epoch: 55/60 [30000/60000 (50%)]\tLoss: 2.295820\n",
      "Train Epoch: 55/60 [40000/60000 (67%)]\tLoss: 2.301332\n",
      "Train Epoch: 55/60 [50000/60000 (83%)]\tLoss: 2.293302\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 56/60 [0/60000 (0%)]\tLoss: 2.299275\n",
      "Train Epoch: 56/60 [10000/60000 (17%)]\tLoss: 2.299044\n",
      "Train Epoch: 56/60 [20000/60000 (33%)]\tLoss: 2.300999\n",
      "Train Epoch: 56/60 [30000/60000 (50%)]\tLoss: 2.306569\n",
      "Train Epoch: 56/60 [40000/60000 (67%)]\tLoss: 2.300954\n",
      "Train Epoch: 56/60 [50000/60000 (83%)]\tLoss: 2.294130\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 57/60 [0/60000 (0%)]\tLoss: 2.305801\n",
      "Train Epoch: 57/60 [10000/60000 (17%)]\tLoss: 2.301872\n",
      "Train Epoch: 57/60 [20000/60000 (33%)]\tLoss: 2.298162\n",
      "Train Epoch: 57/60 [30000/60000 (50%)]\tLoss: 2.300572\n",
      "Train Epoch: 57/60 [40000/60000 (67%)]\tLoss: 2.304097\n",
      "Train Epoch: 57/60 [50000/60000 (83%)]\tLoss: 2.303070\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 58/60 [0/60000 (0%)]\tLoss: 2.304662\n",
      "Train Epoch: 58/60 [10000/60000 (17%)]\tLoss: 2.303025\n",
      "Train Epoch: 58/60 [20000/60000 (33%)]\tLoss: 2.302574\n",
      "Train Epoch: 58/60 [30000/60000 (50%)]\tLoss: 2.295155\n",
      "Train Epoch: 58/60 [40000/60000 (67%)]\tLoss: 2.296248\n",
      "Train Epoch: 58/60 [50000/60000 (83%)]\tLoss: 2.311992\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 59/60 [0/60000 (0%)]\tLoss: 2.294147\n",
      "Train Epoch: 59/60 [10000/60000 (17%)]\tLoss: 2.307844\n",
      "Train Epoch: 59/60 [20000/60000 (33%)]\tLoss: 2.293456\n",
      "Train Epoch: 59/60 [30000/60000 (50%)]\tLoss: 2.302904\n",
      "Train Epoch: 59/60 [40000/60000 (67%)]\tLoss: 2.295337\n",
      "Train Epoch: 59/60 [50000/60000 (83%)]\tLoss: 2.297039\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "Train Epoch: 60/60 [0/60000 (0%)]\tLoss: 2.301633\n",
      "Train Epoch: 60/60 [10000/60000 (17%)]\tLoss: 2.303721\n",
      "Train Epoch: 60/60 [20000/60000 (33%)]\tLoss: 2.291802\n",
      "Train Epoch: 60/60 [30000/60000 (50%)]\tLoss: 2.306285\n",
      "Train Epoch: 60/60 [40000/60000 (67%)]\tLoss: 2.293843\n",
      "Train Epoch: 60/60 [50000/60000 (83%)]\tLoss: 2.297698\n",
      "\n",
      "Test set: Average loss: 0.0230, Accuracy: 1135/10000 (11%)\n",
      "\n",
      "../data/MNIST_cnn_0.1_0.1_0.75_0.7_15.pt\n",
      "Done in  3559.0567450523376 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "if os.path.isfile(model_path):\n",
    "    print('Loading')\n",
    "    model = torch.load(model_path)\n",
    "    #model.load_state_dict(torch.load(model_path))\n",
    "else:\n",
    "    print('Learning')\n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    from what import main\n",
    "    #%run what.py --epochs 10 --save-model\n",
    "    main(args)\n",
    "    print('Done in ', time.time() - t0, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.no_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_cuda True\n",
      "Retina vectorizing...\n",
      "ok\n",
      "success\n",
      "Done vectorizing...\n",
      "Inversing retina transform...\n",
      "Done Inversing retina transform...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/MNIST_accuracy.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-116fe637d6f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWhere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwhat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWhatNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mwhere\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/quantic/science/ActiveVision/WhereIsMyMNIST/notebooks/where.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, save, batch_load, force_training, model, train_loader, test_loader, generate_data, what_model, retina, trainer, save_model, acc_map, save_path)\u001b[0m\n\u001b[1;32m    715\u001b[0m                                        \u001b[0mretina\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m                                        \u001b[0macc_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macc_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m                                        save_path=save_path)\n\u001b[0m\u001b[1;32m    718\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/quantic/science/ActiveVision/WhereIsMyMNIST/notebooks/where.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, model, train_loader, test_loader, device, generate_data, retina, acc_map, save_path)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0macc_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/MNIST_accuracy.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/MNIST_accuracy.npy'"
     ]
    }
   ],
   "source": [
    "from main import init\n",
    "#args = init(filename='debug')\n",
    "#args = init(filename='../data/2019-03-19_bis')\n",
    "#args = init()\n",
    "#args = init(filename='../data/2019-04-15_bis', verbose=1)\n",
    "args = init(filename='../data/2020-07-01')\n",
    "\n",
    "from where import Where\n",
    "from what import WhatNet\n",
    "where = Where(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from main import init\n",
    "#args = init(filename='debug')\n",
    "args = init(filename='../data/2020-07-01')\n",
    "\n",
    "from where import Where\n",
    "from what import WhatNet\n",
    "where = Where(args)\n",
    "\n",
    "filename_train = args.filename + '_train.pt'\n",
    "#%ls -lh {filename_train}\n",
    "#%rm {filename_train}\n",
    "#%rm  ../data/debug_train.pt\n",
    "\n",
    "where.train(filename_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the learned classifier in a standalone class\n",
    "\n",
    "Maintenant qu'on a appris les points qui permet une classification d'à peu près 98 % on va utiliser le modèle fead-forward pour faire la classification."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from retina import Display\n",
    "d = Display(args)\n",
    "data, label = next(iter(d.loader_test))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:42.236066Z",
     "start_time": "2018-02-16T19:37:37.902628Z"
    }
   },
   "source": [
    "from what import WhatNet\n",
    "model = WhatNet()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "from what import test\n",
    "accuracy = test(args, model, torch.device(\"cpu\"), d.loader_test)\n",
    "print('accuracy=', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shifting the input images\n",
    "\n",
    "\n",
    "Je vais maintenant générer des données en utilisant les données originales de MNIST translatées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:42.247845Z",
     "start_time": "2018-02-16T19:37:42.240563Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "i_shift, j_shift = 12, 17\n",
    "N_pix = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:42.835649Z",
     "start_time": "2018-02-16T19:37:42.250490Z"
    }
   },
   "outputs": [],
   "source": [
    "from display import Display\n",
    "d = Display(args)\n",
    "data, label = next(iter(d.loader_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:42.835649Z",
     "start_time": "2018-02-16T19:37:42.250490Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(data[0, 0, :, :].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:43.225992Z",
     "start_time": "2018-02-16T19:37:42.839053Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data.numpy()\n",
    "data_translate = data.min() * np.ones((data.shape[0], 1, N_pix*3 - 2, N_pix*3 - 2))\n",
    "print(data_translate.shape)\n",
    "data_translate[:, :, (N_pix-i_shift):(2*N_pix-i_shift), (N_pix-j_shift):(2*N_pix-j_shift)] = data\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(data_translate[0, 0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:43.539188Z",
     "start_time": "2018-02-16T19:37:43.228276Z"
    }
   },
   "outputs": [],
   "source": [
    "data_cropped = data_translate[:, :, (N_pix):(2*N_pix), (N_pix):(2*N_pix)]\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(data_cropped[0, 0, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:43.550455Z",
     "start_time": "2018-02-16T19:37:43.543831Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.arange(-N_pix+1, N_pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:43.960102Z",
     "start_time": "2018-02-16T19:37:43.552774Z"
    }
   },
   "outputs": [],
   "source": [
    "def shift_data(data, i_shift, j_shift):\n",
    "    N_pix = data.shape[-1]\n",
    "    assert(N_pix == data.shape[-2])\n",
    "    import numpy as np\n",
    "    data_translate = data.min() * np.ones((data.shape[0], 1, N_pix*3 - 1, N_pix*3 - 1))\n",
    "    data_translate[:, :, (N_pix+i_shift):(2*N_pix+i_shift), (N_pix+j_shift):(2*N_pix+j_shift)] = data\n",
    "    data_cropped = data_translate[:, :, (N_pix):(2*N_pix), (N_pix):(2*N_pix)]\n",
    "    return data_cropped\n",
    "\n",
    "data_cropped = shift_data(data, i_shift = 12, j_shift = -12)\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(data_cropped[0, 0, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the learned classifier on the shifted data\n",
    "\n",
    "On peut maintenant tester le classifieur sur les images Translatées en calculant la valeur de classification en  fonction de l'erreur de localisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:37:44.165284Z",
     "start_time": "2018-02-16T19:37:43.964216Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_shift(test_loader, i_shift, j_shift, verbose=0):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data_cropped = shift_data(data, i_shift=i_shift, j_shift=j_shift)        \n",
    "        data_cropped = torch.FloatTensor(data_cropped) #transforms.ToTensor()(data_cropped)\n",
    "        data_cropped, target = Variable(data_cropped, volatile=True), Variable(target)\n",
    "        output = model(data_cropped)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data[0] # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    if verbose: print('\\nTest set: at ({}, {}), the  average loss is {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        i_shift, j_shift, test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "path = \"../data/MNIST_accuracy.npy\"\n",
    "\n",
    "import os\n",
    "if os.path.isfile(path):\n",
    "    print('Loading accuracy')\n",
    "    accuracy = np.load(path)\n",
    "else:\n",
    "    print('Computing accuracy')\n",
    "    import time\n",
    "    t0 = time.time()\n",
    "    accuracy = np.zeros((2*N_pix-1, 2*N_pix-1))\n",
    "    from tqdm import tqdm\n",
    "    N_step = 1\n",
    "\n",
    "    with tqdm(total=(2*N_pix-1)**2/N_step**2) as pbar:\n",
    "        for i_shift in np.arange(-N_pix+1, N_pix, N_step):\n",
    "            for j_shift in np.arange(-N_pix+1, N_pix, N_step):\n",
    "                accuracy[i_shift+N_pix-1, j_shift+N_pix-1] = test_shift(test_loader, i_shift, j_shift)\n",
    "                pbar.update()\n",
    "    np.save(path, accuracy)\n",
    "    print('Done in ', time.time() - t0, 'seconds')\n",
    "    \n",
    "print('accuracy=', accuracy)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'avoue que c'est un peu bourrin de calculer la classification sur les 128 × 128 pixels pour 1000 batch multiplié par 10 type d'entrées.... Mais bon on doit faire ça seulement une fois :-) (et sur CPU une classif = environ 300µs ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-16T19:53:37.955718Z",
     "start_time": "2018-02-16T19:53:37.258057Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.5, 5.25))\n",
    "cmap = ax.pcolor(np.arange(-N_pix+1, N_pix+1), np.arange(-N_pix+1, N_pix+1), accuracy, cmap=plt.plasma())\n",
    "ax.axis('equal')\n",
    "fig.colorbar(cmap)\n",
    "fig.savefig('/tmp/panel_C.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction de performance du classifieur  est calculée indépendamment de la forme spécifique du chiffre entre 0 et 9. Elle donne donc la carte de performance qu'on attend Au niveau de la classification/ On va pouvoir maintenant l'utiliser ceomm label pour apprendre de façon supervisée la correspondance entre la carte log-polaire obtenue depuis l'image brute et cette carte de performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retinotopic mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orientation invariant power encoding (colliculus??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from retina import Retina\n",
    "r = Retina(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('r.colliculus.shape=', r.colliculus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('r.colliculus_vector.shape=', r.colliculus_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('r.colliculus_inverse.shape=', r.colliculus_inverse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = (r.retina_transform**2).sum(axis=(0,3)) \n",
    "energy /= energy.sum(axis=-1)[:, :, None]\n",
    "energy_vector = energy.reshape((args.N_azimuth*args.N_eccentricity, args.N_pic**2))\n",
    "energy_plus = np.linalg.pinv(energy_vector)\n",
    "FIG_WIDTH = 5 \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(figwidth/3, figwidth/3))\n",
    "for i_orient in range(args.N_azimuth):\n",
    "    for i_scale in range(args.N_eccentricity):\n",
    "        env = np.sqrt(energy[i_orient, i_scale, :]**2.5).reshape((args.N_pic, args.N_pic))\n",
    "        ax.contour(energy[i_orient, i_scale, :].reshape((args.N_pic, args.N_pic)), levels=[env.max()/2], lw=1,\n",
    "                  colors=[plt.cm.rainbow(i_scale * 1.5/args.N_azimuth)])\n",
    "#fig.suptitle('Tiling of visual space using energy', y=1.02)\n",
    "ax.set_xlabel(r'$Y$')\n",
    "ax.set_ylabel(r'$X$')\n",
    "ax.axis('equal')\n",
    "plt.tight_layout()\n",
    "fig.savefig('/tmp/panel_B.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize = (figwidth, figwidth/3.618))\n",
    "ax_A = plt.subplot(1, 3, 1, projection='3d')\n",
    "\n",
    "fig, ax_A = panel_A(fig, ax_A)\n",
    "#data_retina = where.retina.retina(full[idx]['data_fullfield'])\n",
    "#ax_A = where.retina.show(ax_A, where.retina.retina_invert(data_retina))\n",
    "    \n",
    "\n",
    "ax_B = plt.subplot(1, 3, 2)\n",
    "for i_orient in range(0, args.N_azimuth, 2):\n",
    "    for i_scale in range(1, args.N_eccentricity, 2):\n",
    "        env = np.sqrt(energy[i_orient, i_scale, :]**2.5).reshape((args.N_pic, args.N_pic))\n",
    "        ax_B.contour(energy[i_orient, i_scale, :].reshape((args.N_pic, args.N_pic)), levels=[env.max()/2], lw=.1,\n",
    "                  colors=[plt.cm.rainbow(i_scale * 1.5/args.N_azimuth)])\n",
    "ax_B.set_xlabel(r'$Y$')\n",
    "ax_B.set_ylabel(r'$X$')\n",
    "ax_B.axis('square')\n",
    "\n",
    "ax_C = plt.subplot(1, 3, 3)\n",
    "cmap = ax_C.pcolor(np.arange(-N_pix+1, N_pix+1), np.arange(-N_pix+1, N_pix+1), accuracy, cmap=plt.plasma())\n",
    "ax_C.axis('square')\n",
    "ax_C.set_xlabel(r'$\\Delta Y$')\n",
    "ax_C.set_ylabel(r'$\\Delta X$')\n",
    "fig.colorbar(cmap)\n",
    "\n",
    "\n",
    "#for ax, text, x_offset, y_offset in [[ax_A, 'A', -.35, .95], [ax_B, 'B', -.35, .95], [ax_C, 'C', -.35, .95]]:\n",
    "#    ax.text(x_offset, y_offset, '(' + text + ')', fontsize=24,\n",
    "#              bbox={'facecolor':'white','alpha':1,'edgecolor':'none','pad':1},\n",
    "#              ha='left', va='center', transform=ax.transAxes) \n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(figname + '.pdf', bbox_inches='tight', pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:43:23.248986Z",
     "start_time": "2018-10-08T14:43:22.900226Z"
    }
   },
   "outputs": [],
   "source": [
    "import tikzmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:43:23.266580Z",
     "start_time": "2018-10-08T14:43:23.251008Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tikzmagic"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%tikz \\draw (0,0) rectangle (1,1);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%tikz --save {fname}.pdf\n",
    "\\draw[white, fill=white] (0.\\linewidth,0) rectangle (1.\\linewidth, .382\\linewidth) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls /tmp/panel*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:43:24.719734Z",
     "start_time": "2018-10-08T14:43:23.285861Z"
    }
   },
   "outputs": [],
   "source": [
    "%%tikz -f pdf --save {figname}.pdf\n",
    "\\draw[white, fill=white] (0.\\linewidth,0) rectangle (1.\\linewidth, .382\\linewidth) ;\n",
    "\\draw [anchor=north west] (.0\\linewidth, .382\\linewidth) node {\\includegraphics[width=.33\\linewidth]{/tmp/panel_A.pdf}};\n",
    "\\draw [anchor=north west] (.333\\linewidth, .382\\linewidth) node {\\includegraphics[width=.31\\linewidth]{/tmp/panel_B.pdf}};\n",
    "\\draw [anchor=north west] (.666\\linewidth, .382\\linewidth) node {\\includegraphics[width=.35\\linewidth]{/tmp/panel_C.pdf}};\n",
    "\\begin{scope}[font=\\bf\\sffamily\\large]\n",
    "\\draw [anchor=west,fill=white] (.0\\linewidth, .382\\linewidth) node [above right=-3mm] {$\\mathsf{D}$};\n",
    "\\draw [anchor=west,fill=white] (.36\\linewidth, .382\\linewidth) node [above right=-3mm] {$\\mathsf{E}$};\n",
    "\\draw [anchor=west,fill=white] (.69\\linewidth, .382\\linewidth) node [above right=-3mm] {$\\mathsf{F}$};\n",
    "\\end{scope}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-08T14:43:27.591507Z",
     "start_time": "2018-10-08T14:43:24.722160Z"
    }
   },
   "outputs": [],
   "source": [
    "!convert  -density {dpi_export} {figname}.pdf {figname}.jpg\n",
    "!convert  -density {dpi_export} {figname}.pdf {figname}.png\n",
    "#!convert  -density {dpi_export} -resize 5400  -units pixelsperinch -flatten  -compress lzw  -depth 8 {fname}.pdf {fname}.tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T10:36:00.981927Z",
     "start_time": "2018-07-03T10:36:00.949864Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('{figname}.png'.format(figname=figname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T10:36:00.939193Z",
     "start_time": "2018-07-03T10:36:00.766218Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls  -l {figname}*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
